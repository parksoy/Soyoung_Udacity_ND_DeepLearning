
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Deep\_Q-learning-cart\_DQN\_using\_tensorflow}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{In conda env openAI}\label{in-conda-env-openai}

\section{sudo -H pip install
python=3.5}\label{sudo--h-pip-install-python3.5}

\section{sudo -H pip install
tensorflow==1.3}\label{sudo--h-pip-install-tensorflow1.3}

Also Kernel should be openAI

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PYZpc{}\PYZpc{}bash
        \PY{n+nb}{pwd}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/parksoy/Desktop/Soyoung\_Udacity\_ND\_DeepLearning/6.Deep\_Reinforcement\_Learning/gym

    \end{Verbatim}

    \section{\texorpdfstring{Deep
\(Q\)-learning}{Deep Q-learning}}\label{deep-q-learning}

In this notebook, we'll build a neural network that can learn to play
games through reinforcement learning. More specifically, we'll use
\(Q\)-learning to train an agent to play a game called
\href{https://gym.openai.com/envs/CartPole-v0}{Cart-Pole}. In this game,
a freely swinging pole is attached to a cart. The cart can move to the
left and right, and the goal is to keep the pole upright as long as
possible.

\begin{figure}
\centering
\includegraphics{assets/cart-pole.jpg}
\caption{Cart-Pole}
\end{figure}

We can simulate this game using
\href{https://github.com/openai/gym}{OpenAI Gym}. First, let's check out
how OpenAI Gym works. Then, we'll get into training an agent to play the
Cart-Pole game.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{gym}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{c+c1}{\PYZsh{} Create the Cart\PYZhy{}Pole game environment}
        \PY{n}{env} \PY{o}{=} \PY{n}{gym}\PY{o}{.}\PY{n}{make}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CartPole\PYZhy{}v1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Number of possible actions}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of possible actions:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{n}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\textcolor{ansi-yellow}{WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.}
Number of possible actions: 2

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/Users/parksoy/Desktop/Soyoung\_Udacity\_ND\_DeepLearning/6.Deep\_Reinforcement\_Learning/gym/gym/\_\_init\_\_.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run "import gym.spaces" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.
  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run "import gym.spaces" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')

    \end{Verbatim}

    We interact with the simulation through \texttt{env}. You can see how
many actions are possible from \texttt{env.action\_space.n}, and to get
a random action you can use \texttt{env.action\_space.sample()}. Passing
in an action as an integer to \texttt{env.step} will generate the next
step in the simulation. This is general to all Gym games.

In the Cart-Pole game, there are two possible actions, moving the cart
left or right. So there are two actions we can take, encoded as 0 and 1.

Run the code below to interact with the environment.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{actions} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{} actions that the agent selects}
        \PY{n}{rewards} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{} obtained rewards}
        \PY{n}{state} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}
        
        \PY{k}{while} \PY{k+kc}{True}\PY{p}{:}
            \PY{n}{action} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} choose a random action}
            \PY{n}{state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{action}\PY{p}{)} 
            \PY{n}{rewards}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{reward}\PY{p}{)}
            \PY{n}{actions}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{action}\PY{p}{)}
            \PY{k}{if} \PY{n}{done}\PY{p}{:}
                \PY{k}{break}
\end{Verbatim}


    We can look at the actions and rewards:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Actions:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{actions}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Rewards:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{rewards}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Actions: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]
Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

    \end{Verbatim}

    The game resets after the pole has fallen past a certain angle. For each
step while the game is running, it returns a reward of 1.0. The longer
the game runs, the more reward we get. Then, our network's goal is to
maximize the reward by keeping the pole vertical. It will do this by
moving the cart to the left and the right.

\subsection{\texorpdfstring{\(Q\)-Network}{Q-Network}}\label{q-network}

To keep track of the action values, we'll use a neural network that
accepts a state \(s\) as input. The output will be \(Q\)-values for each
available action \(a\) (i.e., the output is \textbf{all} action values
\(Q(s,a)\) \emph{corresponding to the input state \(s\)}).

For this Cart-Pole game, the state has four values: the position and
velocity of the cart, and the position and velocity of the pole. Thus,
the neural network has \textbf{four inputs}, one for each value in the
state, and \textbf{two outputs}, one for each possible action.

As explored in the lesson, to get the training target, we'll first use
the context provided by the state \(s\) to choose an action \(a\), then
simulate the game using that action. This will get us the next state,
\(s'\), and the reward \(r\). With that, we can calculate
\(\hat{Q}(s,a) = r + \gamma \max_{a'}{Q(s', a')}\). Then we update the
weights by minimizing \((\hat{Q}(s,a) - Q(s,a))^2\).

Below is one implementation of the \(Q\)-network. It uses two fully
connected layers with ReLU activations. Two seems to be good enough,
three might be better. Feel free to try it out.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        
        \PY{k}{class} \PY{n+nc}{QNetwork}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{state\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} 
                         \PY{n}{action\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} 
                         \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{QNetwork}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} state inputs to the Q\PYZhy{}network}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{n}{name}\PY{p}{)}\PY{p}{:}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{inputs\PYZus{}} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{n}{state\PYZus{}size}\PY{p}{]}\PY{p}{,} \PYZbs{}
                                                  \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inputs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    
                    \PY{c+c1}{\PYZsh{} One hot encode the actions to later choose the Q\PYZhy{}value for the action}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{actions\PYZus{}} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{actions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    \PY{n}{one\PYZus{}hot\PYZus{}actions} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{one\PYZus{}hot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{actions\PYZus{}}\PY{p}{,} \PY{n}{action\PYZus{}size}\PY{p}{)}
                    
                    \PY{c+c1}{\PYZsh{} Target Q values for training}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{targetQs\PYZus{}} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                    
                    \PY{c+c1}{\PYZsh{} ReLU hidden layers}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{inputs\PYZus{}}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{p}{)}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc1}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Linear output layer}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fc2}\PY{p}{,} \PY{n}{action\PYZus{}size}\PY{p}{,} 
                                                                    \PY{n}{activation\PYZus{}fn}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
                    
                    \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Train with loss (targetQ \PYZhy{} Q)\PYZca{}2}
                    \PY{c+c1}{\PYZsh{} output has length 2, for two actions. This next line chooses}
                    \PY{c+c1}{\PYZsh{} one value from output (per row) according to the one\PYZhy{}hot encoded actions.}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{Q} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output}\PY{p}{,} \PY{n}{one\PYZus{}hot\PYZus{}actions}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                    
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{targetQs\PYZus{}} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{Q}\PY{p}{)}\PY{p}{)}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{opt} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{p}{)}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)

    \end{Verbatim}

    \subsection{Experience replay}\label{experience-replay}

Reinforcement learning algorithms can have stability issues due to
correlations between states. To reduce correlations when training, we
can store the agent's experiences and later draw a random mini-batch of
those experiences to train on.

Here, we'll create a \texttt{Memory} object that will store our
experiences, our transitions \(<s, a, r, s'>\). This memory will have a
maximum capacity, so we can keep newer experiences in memory while
getting rid of older experiences. Then, we'll sample a random mini-batch
of transitions \(<s, a, r, s'>\) and train on those.

Below, I've implemented a \texttt{Memory} object. If you're unfamiliar
with \texttt{deque}, this is a double-ended queue. You can think of it
like a tube open on both sides. You can put objects in either side of
the tube. But if it's full, adding anything more will push an object out
the other side. This is a great data structure to use for the memory
buffer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{deque}
        
        \PY{k}{class} \PY{n+nc}{Memory}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{max\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{buffer} \PY{o}{=} \PY{n}{deque}\PY{p}{(}\PY{n}{maxlen}\PY{o}{=}\PY{n}{max\PYZus{}size}\PY{p}{)}
            
            \PY{k}{def} \PY{n+nf}{add}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{experience}\PY{p}{)}\PY{p}{:}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{buffer}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{experience}\PY{p}{)}
                    
            \PY{k}{def} \PY{n+nf}{sample}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                \PY{n}{idx} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{buffer}\PY{p}{)}\PY{p}{)}\PY{p}{,} 
                                       \PY{n}{size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{,} 
                                       \PY{n}{replace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
                \PY{k}{return} \PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{buffer}\PY{p}{[}\PY{n}{ii}\PY{p}{]} \PY{k}{for} \PY{n}{ii} \PY{o+ow}{in} \PY{n}{idx}\PY{p}{]}
\end{Verbatim}


    \subsection{\texorpdfstring{\(Q\)-Learning training
algorithm}{Q-Learning training algorithm}}\label{q-learning-training-algorithm}

We will use the below algorithm to train the network. For this game, the
goal is to keep the pole upright for 195 frames. So we can start a new
episode once meeting that goal. The game ends if the pole tilts over too
far, or if the cart moves too far the left or right. When a game ends,
we'll start a new episode. Now, to train the agent:

\begin{itemize}
\tightlist
\item
  Initialize the memory \(D\)
\item
  Initialize the action-value network \(Q\) with random weights
\item
  \textbf{For} episode \(\leftarrow 1\) \textbf{to} \(M\) \textbf{do}
\item
  Observe \(s_0\)
\item
  \textbf{For} \(t \leftarrow 0\) \textbf{to} \(T-1\) \textbf{do}

  \begin{itemize}
  \tightlist
  \item
    With probability \(\epsilon\) select a random action \(a_t\),
    otherwise select \(a_t = \mathrm{argmax}_a Q(s_t,a)\)
  \item
    Execute action \(a_t\) in simulator and observe reward \(r_{t+1}\)
    and new state \(s_{t+1}\)
  \item
    Store transition \(<s_t, a_t, r_{t+1}, s_{t+1}>\) in memory \(D\)
  \item
    Sample random mini-batch from \(D\): \(<s_j, a_j, r_j, s'_j>\)
  \item
    Set \(\hat{Q}_j = r_j\) if the episode ends at \(j+1\), otherwise
    set \(\hat{Q}_j = r_j + \gamma \max_{a'}{Q(s'_j, a')}\)
  \item
    Make a gradient descent step with loss
    \((\hat{Q}_j - Q(s_j, a_j))^2\)
  \end{itemize}
\item
  \textbf{endfor}
\item
  \textbf{endfor}
\end{itemize}

You are welcome (and encouraged!) to take the time to extend this code
to implement some of the improvements that we discussed in the lesson,
to include fixed \(Q\) targets, double DQNs, prioritized replay, and/or
dueling networks.

\subsection{Hyperparameters}\label{hyperparameters}

One of the more difficult aspects of reinforcement learning is the large
number of hyperparameters. Not only are we tuning the network, but we're
tuning the simulation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{train\PYZus{}episodes} \PY{o}{=} \PY{l+m+mi}{1000}          \PY{c+c1}{\PYZsh{} max number of episodes to learn from}
        \PY{n}{max\PYZus{}steps} \PY{o}{=} \PY{l+m+mi}{200}                \PY{c+c1}{\PYZsh{} max steps in an episode}
        \PY{n}{gamma} \PY{o}{=} \PY{l+m+mf}{0.99}                   \PY{c+c1}{\PYZsh{} future reward discount}
        
        \PY{c+c1}{\PYZsh{} Exploration parameters}
        \PY{n}{explore\PYZus{}start} \PY{o}{=} \PY{l+m+mf}{1.0}            \PY{c+c1}{\PYZsh{} exploration probability at start}
        \PY{n}{explore\PYZus{}stop} \PY{o}{=} \PY{l+m+mf}{0.01}            \PY{c+c1}{\PYZsh{} minimum exploration probability }
        \PY{n}{decay\PYZus{}rate} \PY{o}{=} \PY{l+m+mf}{0.0001}            \PY{c+c1}{\PYZsh{} exponential decay rate for exploration prob}
        
        \PY{c+c1}{\PYZsh{} Network parameters}
        \PY{n}{hidden\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{64}               \PY{c+c1}{\PYZsh{} number of units in each Q\PYZhy{}network hidden layer}
        \PY{n}{learning\PYZus{}rate} \PY{o}{=} \PY{l+m+mf}{0.0001}         \PY{c+c1}{\PYZsh{} Q\PYZhy{}network learning rate}
        
        \PY{c+c1}{\PYZsh{} Memory parameters}
        \PY{n}{memory\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{10000}            \PY{c+c1}{\PYZsh{} memory capacity}
        \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{20}                \PY{c+c1}{\PYZsh{} experience mini\PYZhy{}batch size}
        \PY{n}{pretrain\PYZus{}length} \PY{o}{=} \PY{n}{batch\PYZus{}size}   \PY{c+c1}{\PYZsh{} number experiences to pretrain the memory}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{tf}\PY{o}{.}\PY{n}{reset\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}
        \PY{n}{mainQN} \PY{o}{=} \PY{n}{QNetwork}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{main}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{o}{=}\PY{n}{hidden\PYZus{}size}\PY{p}{,} \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{n}{learning\PYZus{}rate}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)

    \end{Verbatim}

    \subsection{Populate the experience
memory}\label{populate-the-experience-memory}

Here we re-initialize the simulation and pre-populate the memory. The
agent is taking random actions and storing the transitions in memory.
This will help the agent with exploring the game.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Initialize the simulation}
        \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Take one random step to get the pole and cart moving}
        \PY{n}{state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{memory} \PY{o}{=} \PY{n}{Memory}\PY{p}{(}\PY{n}{max\PYZus{}size}\PY{o}{=}\PY{n}{memory\PYZus{}size}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Make a bunch of random actions and store the experiences}
        \PY{k}{for} \PY{n}{ii} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{pretrain\PYZus{}length}\PY{p}{)}\PY{p}{:}
        
            \PY{c+c1}{\PYZsh{} Make a random action}
            \PY{n}{action} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}
            \PY{n}{next\PYZus{}state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{action}\PY{p}{)}
        
            \PY{k}{if} \PY{n}{done}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} The simulation fails so no next state}
                \PY{n}{next\PYZus{}state} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{state}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Add experience to memory}
                \PY{n}{memory}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{p}{(}\PY{n}{state}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{next\PYZus{}state}\PY{p}{)}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} Start new episode}
                \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Take one random step to get the pole and cart moving}
                \PY{n}{state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Add experience to memory}
                \PY{n}{memory}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{p}{(}\PY{n}{state}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{next\PYZus{}state}\PY{p}{)}\PY{p}{)}
                \PY{n}{state} \PY{o}{=} \PY{n}{next\PYZus{}state}
\end{Verbatim}


    \subsection{Training}\label{training}

Below we'll train our agent.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Now train with experiences}
         \PY{n}{saver} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{Saver}\PY{p}{(}\PY{p}{)}
         \PY{n}{rewards\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Initialize variables}
             \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{global\PYZus{}variables\PYZus{}initializer}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{step} \PY{o}{=} \PY{l+m+mi}{0}
             \PY{k}{for} \PY{n}{ep} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{train\PYZus{}episodes}\PY{p}{)}\PY{p}{:}
                 \PY{n}{total\PYZus{}reward} \PY{o}{=} \PY{l+m+mi}{0}
                 \PY{n}{t} \PY{o}{=} \PY{l+m+mi}{0}
                 \PY{k}{while} \PY{n}{t} \PY{o}{\PYZlt{}} \PY{n}{max\PYZus{}steps}\PY{p}{:}
                     \PY{n}{step} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                     \PY{c+c1}{\PYZsh{} Uncomment this next line to watch the training}
                     \PY{n}{env}\PY{o}{.}\PY{n}{render}\PY{p}{(}\PY{p}{)} 
                     
                     \PY{c+c1}{\PYZsh{} Explore or Exploit}
                     \PY{n}{explore\PYZus{}p} \PY{o}{=} \PY{n}{explore\PYZus{}stop} \PY{o}{+} \PY{p}{(}\PY{n}{explore\PYZus{}start} \PY{o}{\PYZhy{}} \PY{n}{explore\PYZus{}stop}\PY{p}{)}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{decay\PYZus{}rate}\PY{o}{*}\PY{n}{step}\PY{p}{)} 
                     \PY{k}{if} \PY{n}{explore\PYZus{}p} \PY{o}{\PYZgt{}} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{rand}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                         \PY{c+c1}{\PYZsh{} Make a random action}
                         \PY{n}{action} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}
                     \PY{k}{else}\PY{p}{:}
                         \PY{c+c1}{\PYZsh{} Get action from Q\PYZhy{}network}
                         \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{mainQN}\PY{o}{.}\PY{n}{inputs\PYZus{}}\PY{p}{:} \PY{n}{state}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{*}\PY{n}{state}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
                         \PY{n}{Qs} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{mainQN}\PY{o}{.}\PY{n}{output}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{n}{feed}\PY{p}{)}
                         \PY{n}{action} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Qs}\PY{p}{)}
                     
                     \PY{c+c1}{\PYZsh{} Take action, get new state and reward}
                     \PY{n}{next\PYZus{}state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{action}\PY{p}{)}
             
                     \PY{n}{total\PYZus{}reward} \PY{o}{+}\PY{o}{=} \PY{n}{reward}
                     
                     \PY{k}{if} \PY{n}{done}\PY{p}{:}
                         \PY{c+c1}{\PYZsh{} the episode ends so no next state}
                         \PY{n}{next\PYZus{}state} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{state}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
                         \PY{n}{t} \PY{o}{=} \PY{n}{max\PYZus{}steps}
                         
                         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Episode: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{ep}\PY{p}{)}\PY{p}{,}
                               \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Total reward: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{total\PYZus{}reward}\PY{p}{)}\PY{p}{,}
                               \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training loss: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{loss}\PY{p}{)}\PY{p}{,}
                               \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Explore P: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{explore\PYZus{}p}\PY{p}{)}\PY{p}{)}
                         \PY{n}{rewards\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{n}{ep}\PY{p}{,} \PY{n}{total\PYZus{}reward}\PY{p}{)}\PY{p}{)}
                         
                         \PY{c+c1}{\PYZsh{} Add experience to memory}
                         \PY{n}{memory}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{p}{(}\PY{n}{state}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{next\PYZus{}state}\PY{p}{)}\PY{p}{)}
                         
                         \PY{c+c1}{\PYZsh{} Start new episode}
                         \PY{n}{env}\PY{o}{.}\PY{n}{reset}\PY{p}{(}\PY{p}{)}
                         \PY{c+c1}{\PYZsh{} Take one random step to get the pole and cart moving}
                         \PY{n}{state}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{done}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{env}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{env}\PY{o}{.}\PY{n}{action\PYZus{}space}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         
                     \PY{k}{else}\PY{p}{:}
                         \PY{c+c1}{\PYZsh{} Add experience to memory}
                         \PY{n}{memory}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{p}{(}\PY{n}{state}\PY{p}{,} \PY{n}{action}\PY{p}{,} \PY{n}{reward}\PY{p}{,} \PY{n}{next\PYZus{}state}\PY{p}{)}\PY{p}{)}
                         \PY{n}{state} \PY{o}{=} \PY{n}{next\PYZus{}state}
                         \PY{n}{t} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                     
                     \PY{c+c1}{\PYZsh{} Sample mini\PYZhy{}batch from memory}
                     \PY{n}{batch} \PY{o}{=} \PY{n}{memory}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}
                     \PY{n}{states} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{each}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{each} \PY{o+ow}{in} \PY{n}{batch}\PY{p}{]}\PY{p}{)}
                     \PY{n}{actions} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{each}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{k}{for} \PY{n}{each} \PY{o+ow}{in} \PY{n}{batch}\PY{p}{]}\PY{p}{)}
                     \PY{n}{rewards} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{each}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{k}{for} \PY{n}{each} \PY{o+ow}{in} \PY{n}{batch}\PY{p}{]}\PY{p}{)}
                     \PY{n}{next\PYZus{}states} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{each}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]} \PY{k}{for} \PY{n}{each} \PY{o+ow}{in} \PY{n}{batch}\PY{p}{]}\PY{p}{)}
                     
                     \PY{c+c1}{\PYZsh{} Train network}
                     \PY{n}{target\PYZus{}Qs} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{mainQN}\PY{o}{.}\PY{n}{output}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{mainQN}\PY{o}{.}\PY{n}{inputs\PYZus{}}\PY{p}{:} \PY{n}{next\PYZus{}states}\PY{p}{\PYZcb{}}\PY{p}{)}
                     
                     \PY{c+c1}{\PYZsh{} Set target\PYZus{}Qs to 0 for states where episode ends}
                     \PY{n}{episode\PYZus{}ends} \PY{o}{=} \PY{p}{(}\PY{n}{next\PYZus{}states} \PY{o}{==} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{states}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{all}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                     \PY{n}{target\PYZus{}Qs}\PY{p}{[}\PY{n}{episode\PYZus{}ends}\PY{p}{]} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
                     
                     \PY{n}{targets} \PY{o}{=} \PY{n}{rewards} \PY{o}{+} \PY{n}{gamma} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{target\PYZus{}Qs}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
                     \PY{n}{loss}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{mainQN}\PY{o}{.}\PY{n}{loss}\PY{p}{,} \PY{n}{mainQN}\PY{o}{.}\PY{n}{opt}\PY{p}{]}\PY{p}{,}
                                         \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{mainQN}\PY{o}{.}\PY{n}{inputs\PYZus{}}\PY{p}{:} \PY{n}{states}\PY{p}{,}
                                                    \PY{n}{mainQN}\PY{o}{.}\PY{n}{targetQs\PYZus{}}\PY{p}{:} \PY{n}{targets}\PY{p}{,}
                                                    \PY{n}{mainQN}\PY{o}{.}\PY{n}{actions\PYZus{}}\PY{p}{:} \PY{n}{actions}\PY{p}{\PYZcb{}}\PY{p}{)}
                 
             \PY{n}{saver}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{checkpoints/cartpole.ckpt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Episode: 1 Total reward: 31.0 Training loss: 1.1336 Explore P: 0.9969
Episode: 2 Total reward: 56.0 Training loss: 1.0566 Explore P: 0.9914
Episode: 3 Total reward: 31.0 Training loss: 1.0755 Explore P: 0.9884
Episode: 4 Total reward: 22.0 Training loss: 1.1408 Explore P: 0.9862
Episode: 5 Total reward: 26.0 Training loss: 1.0530 Explore P: 0.9837
Episode: 6 Total reward: 16.0 Training loss: 1.0998 Explore P: 0.9821
Episode: 7 Total reward: 33.0 Training loss: 1.0975 Explore P: 0.9789
Episode: 8 Total reward: 52.0 Training loss: 1.0742 Explore P: 0.9739
Episode: 9 Total reward: 20.0 Training loss: 1.0625 Explore P: 0.9720
Episode: 10 Total reward: 31.0 Training loss: 1.2108 Explore P: 0.9690
Episode: 11 Total reward: 47.0 Training loss: 1.0890 Explore P: 0.9645
Episode: 12 Total reward: 10.0 Training loss: 1.2381 Explore P: 0.9636
Episode: 13 Total reward: 32.0 Training loss: 1.3163 Explore P: 0.9605
Episode: 14 Total reward: 19.0 Training loss: 1.0309 Explore P: 0.9587
Episode: 15 Total reward: 23.0 Training loss: 1.1489 Explore P: 0.9565
Episode: 16 Total reward: 16.0 Training loss: 1.2078 Explore P: 0.9550
Episode: 17 Total reward: 20.0 Training loss: 1.2635 Explore P: 0.9531
Episode: 18 Total reward: 9.0 Training loss: 1.8861 Explore P: 0.9523
Episode: 19 Total reward: 27.0 Training loss: 1.2006 Explore P: 0.9497
Episode: 20 Total reward: 16.0 Training loss: 1.0622 Explore P: 0.9482
Episode: 21 Total reward: 28.0 Training loss: 2.0219 Explore P: 0.9456
Episode: 22 Total reward: 17.0 Training loss: 1.4304 Explore P: 0.9440
Episode: 23 Total reward: 33.0 Training loss: 1.3175 Explore P: 0.9409
Episode: 24 Total reward: 14.0 Training loss: 1.6090 Explore P: 0.9396
Episode: 25 Total reward: 16.0 Training loss: 8.1292 Explore P: 0.9382
Episode: 26 Total reward: 17.0 Training loss: 1.8868 Explore P: 0.9366
Episode: 27 Total reward: 47.0 Training loss: 2.5920 Explore P: 0.9322
Episode: 28 Total reward: 25.0 Training loss: 4.0312 Explore P: 0.9299
Episode: 29 Total reward: 16.0 Training loss: 2.3412 Explore P: 0.9285
Episode: 30 Total reward: 19.0 Training loss: 2.6611 Explore P: 0.9267
Episode: 31 Total reward: 53.0 Training loss: 9.0382 Explore P: 0.9219
Episode: 32 Total reward: 30.0 Training loss: 3.8215 Explore P: 0.9191
Episode: 33 Total reward: 25.0 Training loss: 5.1638 Explore P: 0.9169
Episode: 34 Total reward: 22.0 Training loss: 4.3479 Explore P: 0.9149
Episode: 35 Total reward: 24.0 Training loss: 5.3145 Explore P: 0.9127
Episode: 36 Total reward: 10.0 Training loss: 6.6377 Explore P: 0.9118
Episode: 37 Total reward: 29.0 Training loss: 5.7618 Explore P: 0.9092
Episode: 38 Total reward: 16.0 Training loss: 6.8798 Explore P: 0.9078
Episode: 39 Total reward: 23.0 Training loss: 8.3189 Explore P: 0.9057
Episode: 40 Total reward: 13.0 Training loss: 8.9495 Explore P: 0.9045
Episode: 41 Total reward: 25.0 Training loss: 8.5624 Explore P: 0.9023
Episode: 42 Total reward: 31.0 Training loss: 6.9123 Explore P: 0.8995
Episode: 43 Total reward: 15.0 Training loss: 10.0572 Explore P: 0.8982
Episode: 44 Total reward: 33.0 Training loss: 10.8361 Explore P: 0.8953
Episode: 45 Total reward: 14.0 Training loss: 9.2104 Explore P: 0.8940
Episode: 46 Total reward: 11.0 Training loss: 10.3698 Explore P: 0.8931
Episode: 47 Total reward: 10.0 Training loss: 10.6126 Explore P: 0.8922
Episode: 48 Total reward: 47.0 Training loss: 13.0452 Explore P: 0.8881
Episode: 49 Total reward: 19.0 Training loss: 33.6639 Explore P: 0.8864
Episode: 50 Total reward: 10.0 Training loss: 14.8669 Explore P: 0.8855
Episode: 51 Total reward: 16.0 Training loss: 18.0135 Explore P: 0.8841
Episode: 52 Total reward: 11.0 Training loss: 19.1708 Explore P: 0.8831
Episode: 53 Total reward: 9.0 Training loss: 16.7087 Explore P: 0.8824
Episode: 54 Total reward: 34.0 Training loss: 18.9158 Explore P: 0.8794
Episode: 55 Total reward: 13.0 Training loss: 90.0493 Explore P: 0.8783
Episode: 56 Total reward: 18.0 Training loss: 33.9070 Explore P: 0.8767
Episode: 57 Total reward: 28.0 Training loss: 27.9644 Explore P: 0.8743
Episode: 58 Total reward: 17.0 Training loss: 28.9324 Explore P: 0.8728
Episode: 59 Total reward: 22.0 Training loss: 35.1372 Explore P: 0.8709
Episode: 60 Total reward: 12.0 Training loss: 216.6624 Explore P: 0.8699
Episode: 61 Total reward: 15.0 Training loss: 287.0281 Explore P: 0.8686
Episode: 62 Total reward: 19.0 Training loss: 30.7282 Explore P: 0.8670
Episode: 63 Total reward: 9.0 Training loss: 36.0398 Explore P: 0.8662
Episode: 64 Total reward: 29.0 Training loss: 43.7811 Explore P: 0.8637
Episode: 65 Total reward: 9.0 Training loss: 38.8963 Explore P: 0.8630
Episode: 66 Total reward: 12.0 Training loss: 47.3502 Explore P: 0.8619
Episode: 67 Total reward: 11.0 Training loss: 40.9041 Explore P: 0.8610
Episode: 68 Total reward: 12.0 Training loss: 39.5051 Explore P: 0.8600
Episode: 69 Total reward: 11.0 Training loss: 43.7188 Explore P: 0.8590
Episode: 70 Total reward: 24.0 Training loss: 333.3359 Explore P: 0.8570
Episode: 71 Total reward: 18.0 Training loss: 74.6702 Explore P: 0.8555
Episode: 72 Total reward: 18.0 Training loss: 58.5559 Explore P: 0.8540
Episode: 73 Total reward: 28.0 Training loss: 1486.7451 Explore P: 0.8516
Episode: 74 Total reward: 13.0 Training loss: 67.7643 Explore P: 0.8505
Episode: 75 Total reward: 14.0 Training loss: 515.9315 Explore P: 0.8493
Episode: 76 Total reward: 26.0 Training loss: 3037.3940 Explore P: 0.8472
Episode: 77 Total reward: 13.0 Training loss: 62.8928 Explore P: 0.8461
Episode: 78 Total reward: 54.0 Training loss: 70.7524 Explore P: 0.8416
Episode: 79 Total reward: 16.0 Training loss: 74.0478 Explore P: 0.8402
Episode: 80 Total reward: 27.0 Training loss: 364.2993 Explore P: 0.8380
Episode: 81 Total reward: 24.0 Training loss: 1307.3883 Explore P: 0.8360
Episode: 82 Total reward: 22.0 Training loss: 78.5216 Explore P: 0.8342
Episode: 83 Total reward: 11.0 Training loss: 58.8493 Explore P: 0.8333
Episode: 84 Total reward: 25.0 Training loss: 79.7611 Explore P: 0.8312
Episode: 85 Total reward: 26.0 Training loss: 107.7045 Explore P: 0.8291
Episode: 86 Total reward: 9.0 Training loss: 74.6755 Explore P: 0.8284
Episode: 87 Total reward: 14.0 Training loss: 90.1754 Explore P: 0.8272
Episode: 88 Total reward: 15.0 Training loss: 84.0657 Explore P: 0.8260
Episode: 89 Total reward: 18.0 Training loss: 75.5678 Explore P: 0.8245
Episode: 90 Total reward: 15.0 Training loss: 5649.0352 Explore P: 0.8233
Episode: 91 Total reward: 44.0 Training loss: 75.1080 Explore P: 0.8197
Episode: 92 Total reward: 16.0 Training loss: 78.2813 Explore P: 0.8184
Episode: 93 Total reward: 40.0 Training loss: 88.2141 Explore P: 0.8152
Episode: 94 Total reward: 13.0 Training loss: 96.8995 Explore P: 0.8142
Episode: 95 Total reward: 18.0 Training loss: 75.3191 Explore P: 0.8127
Episode: 96 Total reward: 32.0 Training loss: 101.5171 Explore P: 0.8102
Episode: 97 Total reward: 23.0 Training loss: 86.5028 Explore P: 0.8083
Episode: 98 Total reward: 22.0 Training loss: 2131.7183 Explore P: 0.8066
Episode: 99 Total reward: 25.0 Training loss: 116.2479 Explore P: 0.8046
Episode: 100 Total reward: 8.0 Training loss: 79.0282 Explore P: 0.8039
Episode: 101 Total reward: 22.0 Training loss: 115.5971 Explore P: 0.8022
Episode: 102 Total reward: 11.0 Training loss: 107.5002 Explore P: 0.8013
Episode: 103 Total reward: 17.0 Training loss: 133.8950 Explore P: 0.8000
Episode: 104 Total reward: 41.0 Training loss: 107.8689 Explore P: 0.7967
Episode: 105 Total reward: 14.0 Training loss: 74.1046 Explore P: 0.7956
Episode: 106 Total reward: 24.0 Training loss: 118.8142 Explore P: 0.7938
Episode: 107 Total reward: 24.0 Training loss: 122.5212 Explore P: 0.7919
Episode: 108 Total reward: 25.0 Training loss: 1332.2993 Explore P: 0.7899
Episode: 109 Total reward: 16.0 Training loss: 1699.3975 Explore P: 0.7887
Episode: 110 Total reward: 22.0 Training loss: 151.4867 Explore P: 0.7870
Episode: 111 Total reward: 24.0 Training loss: 165.0690 Explore P: 0.7851
Episode: 112 Total reward: 36.0 Training loss: 114.0432 Explore P: 0.7823
Episode: 113 Total reward: 22.0 Training loss: 142.3817 Explore P: 0.7806
Episode: 114 Total reward: 47.0 Training loss: 125.3903 Explore P: 0.7770
Episode: 115 Total reward: 19.0 Training loss: 150.7352 Explore P: 0.7756
Episode: 116 Total reward: 8.0 Training loss: 158.0875 Explore P: 0.7749
Episode: 117 Total reward: 24.0 Training loss: 117.2614 Explore P: 0.7731
Episode: 118 Total reward: 8.0 Training loss: 147.2529 Explore P: 0.7725
Episode: 119 Total reward: 21.0 Training loss: 170.5463 Explore P: 0.7709
Episode: 120 Total reward: 25.0 Training loss: 121.8112 Explore P: 0.7690
Episode: 121 Total reward: 8.0 Training loss: 136.6019 Explore P: 0.7684
Episode: 122 Total reward: 11.0 Training loss: 135.4133 Explore P: 0.7676
Episode: 123 Total reward: 24.0 Training loss: 17195.9199 Explore P: 0.7657
Episode: 124 Total reward: 10.0 Training loss: 140.5972 Explore P: 0.7650
Episode: 125 Total reward: 28.0 Training loss: 99.6012 Explore P: 0.7629
Episode: 126 Total reward: 19.0 Training loss: 114.5515 Explore P: 0.7615
Episode: 127 Total reward: 9.0 Training loss: 160.3778 Explore P: 0.7608
Episode: 128 Total reward: 10.0 Training loss: 140.0286 Explore P: 0.7600
Episode: 129 Total reward: 29.0 Training loss: 132.3573 Explore P: 0.7579
Episode: 130 Total reward: 50.0 Training loss: 106.5341 Explore P: 0.7541
Episode: 131 Total reward: 13.0 Training loss: 101.7785 Explore P: 0.7532
Episode: 132 Total reward: 23.0 Training loss: 107.3102 Explore P: 0.7514
Episode: 133 Total reward: 21.0 Training loss: 4932.7354 Explore P: 0.7499
Episode: 134 Total reward: 14.0 Training loss: 116.8652 Explore P: 0.7489
Episode: 135 Total reward: 11.0 Training loss: 109.7918 Explore P: 0.7480
Episode: 136 Total reward: 14.0 Training loss: 96.9658 Explore P: 0.7470
Episode: 137 Total reward: 34.0 Training loss: 119.0808 Explore P: 0.7445
Episode: 138 Total reward: 13.0 Training loss: 20978.1523 Explore P: 0.7436
Episode: 139 Total reward: 41.0 Training loss: 96.9322 Explore P: 0.7406
Episode: 140 Total reward: 19.0 Training loss: 99.9643 Explore P: 0.7392
Episode: 141 Total reward: 16.0 Training loss: 121.9502 Explore P: 0.7380
Episode: 142 Total reward: 12.0 Training loss: 2665.6499 Explore P: 0.7371
Episode: 143 Total reward: 23.0 Training loss: 71.9992 Explore P: 0.7355
Episode: 144 Total reward: 25.0 Training loss: 110.3935 Explore P: 0.7336
Episode: 145 Total reward: 58.0 Training loss: 75.4962 Explore P: 0.7295
Episode: 146 Total reward: 13.0 Training loss: 100.1675 Explore P: 0.7285
Episode: 147 Total reward: 9.0 Training loss: 98.0521 Explore P: 0.7279
Episode: 148 Total reward: 12.0 Training loss: 4006.7378 Explore P: 0.7270
Episode: 149 Total reward: 13.0 Training loss: 80.5920 Explore P: 0.7261
Episode: 150 Total reward: 10.0 Training loss: 73.5030 Explore P: 0.7254
Episode: 151 Total reward: 49.0 Training loss: 109.3066 Explore P: 0.7219
Episode: 152 Total reward: 14.0 Training loss: 3463.6172 Explore P: 0.7209
Episode: 153 Total reward: 10.0 Training loss: 91.8522 Explore P: 0.7202
Episode: 154 Total reward: 13.0 Training loss: 75.7582 Explore P: 0.7192
Episode: 155 Total reward: 12.0 Training loss: 73.6117 Explore P: 0.7184
Episode: 156 Total reward: 18.0 Training loss: 5046.8506 Explore P: 0.7171
Episode: 157 Total reward: 12.0 Training loss: 3164.2979 Explore P: 0.7163
Episode: 158 Total reward: 10.0 Training loss: 88.7032 Explore P: 0.7156
Episode: 159 Total reward: 21.0 Training loss: 3141.7478 Explore P: 0.7141
Episode: 160 Total reward: 7.0 Training loss: 73.3956 Explore P: 0.7136
Episode: 161 Total reward: 11.0 Training loss: 5334.0166 Explore P: 0.7128
Episode: 162 Total reward: 13.0 Training loss: 4079.9731 Explore P: 0.7119
Episode: 163 Total reward: 28.0 Training loss: 81.2171 Explore P: 0.7099
Episode: 164 Total reward: 12.0 Training loss: 76.0322 Explore P: 0.7091
Episode: 165 Total reward: 21.0 Training loss: 53.9511 Explore P: 0.7076
Episode: 166 Total reward: 34.0 Training loss: 73.7509 Explore P: 0.7053
Episode: 167 Total reward: 10.0 Training loss: 74.3256 Explore P: 0.7046
Episode: 168 Total reward: 12.0 Training loss: 42.5936 Explore P: 0.7037
Episode: 169 Total reward: 14.0 Training loss: 56.0576 Explore P: 0.7028
Episode: 170 Total reward: 21.0 Training loss: 43.9802 Explore P: 0.7013
Episode: 171 Total reward: 13.0 Training loss: 7777.7476 Explore P: 0.7004
Episode: 172 Total reward: 13.0 Training loss: 2723.1489 Explore P: 0.6995
Episode: 173 Total reward: 14.0 Training loss: 57.4662 Explore P: 0.6986
Episode: 174 Total reward: 11.0 Training loss: 50.3084 Explore P: 0.6978
Episode: 175 Total reward: 38.0 Training loss: 37.8473 Explore P: 0.6952
Episode: 176 Total reward: 7.0 Training loss: 5064.1279 Explore P: 0.6947
Episode: 177 Total reward: 27.0 Training loss: 58.1898 Explore P: 0.6929
Episode: 178 Total reward: 23.0 Training loss: 41.7299 Explore P: 0.6913
Episode: 179 Total reward: 22.0 Training loss: 44.9884 Explore P: 0.6898
Episode: 180 Total reward: 18.0 Training loss: 3656.8450 Explore P: 0.6886
Episode: 181 Total reward: 15.0 Training loss: 25144.4844 Explore P: 0.6876
Episode: 182 Total reward: 26.0 Training loss: 33.8962 Explore P: 0.6858
Episode: 183 Total reward: 19.0 Training loss: 57.6533 Explore P: 0.6845
Episode: 184 Total reward: 23.0 Training loss: 44.3963 Explore P: 0.6830
Episode: 185 Total reward: 13.0 Training loss: 3428.7397 Explore P: 0.6821
Episode: 186 Total reward: 14.0 Training loss: 36.6019 Explore P: 0.6812
Episode: 187 Total reward: 19.0 Training loss: 2737.3289 Explore P: 0.6799
Episode: 188 Total reward: 19.0 Training loss: 17.8467 Explore P: 0.6786
Episode: 189 Total reward: 10.0 Training loss: 16.8355 Explore P: 0.6779
Episode: 190 Total reward: 24.0 Training loss: 22.5102 Explore P: 0.6763
Episode: 191 Total reward: 26.0 Training loss: 4047.0984 Explore P: 0.6746
Episode: 192 Total reward: 28.0 Training loss: 13.1256 Explore P: 0.6728
Episode: 193 Total reward: 38.0 Training loss: 17.7296 Explore P: 0.6702
Episode: 194 Total reward: 11.0 Training loss: 35.6565 Explore P: 0.6695
Episode: 195 Total reward: 12.0 Training loss: 2895.4243 Explore P: 0.6687
Episode: 196 Total reward: 11.0 Training loss: 1793.0479 Explore P: 0.6680
Episode: 197 Total reward: 21.0 Training loss: 16.0983 Explore P: 0.6666
Episode: 198 Total reward: 12.0 Training loss: 5853.1216 Explore P: 0.6658
Episode: 199 Total reward: 13.0 Training loss: 26.5910 Explore P: 0.6650
Episode: 200 Total reward: 20.0 Training loss: 24.3130 Explore P: 0.6637
Episode: 201 Total reward: 11.0 Training loss: 22.0467 Explore P: 0.6630
Episode: 202 Total reward: 21.0 Training loss: 2706.8464 Explore P: 0.6616
Episode: 203 Total reward: 14.0 Training loss: 4888.1533 Explore P: 0.6607
Episode: 204 Total reward: 9.0 Training loss: 9.0408 Explore P: 0.6601
Episode: 205 Total reward: 26.0 Training loss: 7.3871 Explore P: 0.6584
Episode: 206 Total reward: 11.0 Training loss: 14.6403 Explore P: 0.6577
Episode: 207 Total reward: 17.0 Training loss: 9.1154 Explore P: 0.6566
Episode: 208 Total reward: 49.0 Training loss: 4.4314 Explore P: 0.6534
Episode: 209 Total reward: 15.0 Training loss: 7.4842 Explore P: 0.6525
Episode: 210 Total reward: 60.0 Training loss: 1753.0670 Explore P: 0.6486
Episode: 211 Total reward: 13.0 Training loss: 9.2378 Explore P: 0.6478
Episode: 212 Total reward: 19.0 Training loss: 6.4863 Explore P: 0.6466
Episode: 213 Total reward: 12.0 Training loss: 2.6975 Explore P: 0.6458
Episode: 214 Total reward: 19.0 Training loss: 4.7349 Explore P: 0.6446
Episode: 215 Total reward: 20.0 Training loss: 5.6127 Explore P: 0.6433
Episode: 216 Total reward: 25.0 Training loss: 5.9732 Explore P: 0.6418
Episode: 217 Total reward: 20.0 Training loss: 4.0889 Explore P: 0.6405
Episode: 218 Total reward: 23.0 Training loss: 15.0587 Explore P: 0.6390
Episode: 219 Total reward: 20.0 Training loss: 6.7505 Explore P: 0.6378
Episode: 220 Total reward: 14.0 Training loss: 5.9254 Explore P: 0.6369
Episode: 221 Total reward: 15.0 Training loss: 10.1932 Explore P: 0.6360
Episode: 222 Total reward: 12.0 Training loss: 6.3386 Explore P: 0.6352
Episode: 223 Total reward: 25.0 Training loss: 10.1164 Explore P: 0.6337
Episode: 224 Total reward: 21.0 Training loss: 7.3444 Explore P: 0.6324
Episode: 225 Total reward: 16.0 Training loss: 2586.8862 Explore P: 0.6314
Episode: 226 Total reward: 26.0 Training loss: 7.9807 Explore P: 0.6297
Episode: 227 Total reward: 17.0 Training loss: 2536.1643 Explore P: 0.6287
Episode: 228 Total reward: 14.0 Training loss: 3055.9155 Explore P: 0.6278
Episode: 229 Total reward: 21.0 Training loss: 3600.8188 Explore P: 0.6265
Episode: 230 Total reward: 34.0 Training loss: 2178.9675 Explore P: 0.6244
Episode: 231 Total reward: 19.0 Training loss: 8.2447 Explore P: 0.6233
Episode: 232 Total reward: 38.0 Training loss: 1734.4548 Explore P: 0.6209
Episode: 233 Total reward: 17.0 Training loss: 1192.4335 Explore P: 0.6199
Episode: 234 Total reward: 25.0 Training loss: 1959.9935 Explore P: 0.6184
Episode: 235 Total reward: 18.0 Training loss: 2580.2327 Explore P: 0.6173
Episode: 236 Total reward: 16.0 Training loss: 1340.3333 Explore P: 0.6163
Episode: 237 Total reward: 28.0 Training loss: 11.0779 Explore P: 0.6146
Episode: 238 Total reward: 15.0 Training loss: 3158.1431 Explore P: 0.6137
Episode: 239 Total reward: 22.0 Training loss: 5.9163 Explore P: 0.6124
Episode: 240 Total reward: 23.0 Training loss: 4.7254 Explore P: 0.6110
Episode: 241 Total reward: 16.0 Training loss: 1168.8042 Explore P: 0.6100
Episode: 242 Total reward: 12.0 Training loss: 9.5911 Explore P: 0.6093
Episode: 243 Total reward: 18.0 Training loss: 6.3828 Explore P: 0.6082
Episode: 244 Total reward: 14.0 Training loss: 12.3495 Explore P: 0.6074
Episode: 245 Total reward: 17.0 Training loss: 6.8395 Explore P: 0.6064
Episode: 246 Total reward: 65.0 Training loss: 10.0302 Explore P: 0.6025
Episode: 247 Total reward: 24.0 Training loss: 2993.6069 Explore P: 0.6011
Episode: 248 Total reward: 9.0 Training loss: 13.7001 Explore P: 0.6006
Episode: 249 Total reward: 22.0 Training loss: 14.2397 Explore P: 0.5993
Episode: 250 Total reward: 10.0 Training loss: 11.5850 Explore P: 0.5987
Episode: 251 Total reward: 19.0 Training loss: 9.0400 Explore P: 0.5976
Episode: 252 Total reward: 12.0 Training loss: 10.3943 Explore P: 0.5969
Episode: 253 Total reward: 22.0 Training loss: 8.0987 Explore P: 0.5956
Episode: 254 Total reward: 12.0 Training loss: 2830.7603 Explore P: 0.5949
Episode: 255 Total reward: 25.0 Training loss: 7.6015 Explore P: 0.5934
Episode: 256 Total reward: 36.0 Training loss: 794.9814 Explore P: 0.5913
Episode: 257 Total reward: 11.0 Training loss: 9.3359 Explore P: 0.5907
Episode: 258 Total reward: 26.0 Training loss: 2794.4878 Explore P: 0.5892
Episode: 259 Total reward: 57.0 Training loss: 2519.6260 Explore P: 0.5859
Episode: 260 Total reward: 8.0 Training loss: 8.5677 Explore P: 0.5854
Episode: 261 Total reward: 9.0 Training loss: 9.5728 Explore P: 0.5849
Episode: 262 Total reward: 23.0 Training loss: 1266.1208 Explore P: 0.5836
Episode: 263 Total reward: 16.0 Training loss: 4768.1035 Explore P: 0.5827
Episode: 264 Total reward: 10.0 Training loss: 14.5032 Explore P: 0.5821
Episode: 265 Total reward: 20.0 Training loss: 22.2063 Explore P: 0.5810
Episode: 266 Total reward: 22.0 Training loss: 17.9686 Explore P: 0.5797
Episode: 267 Total reward: 9.0 Training loss: 18.5366 Explore P: 0.5792
Episode: 268 Total reward: 15.0 Training loss: 19.4260 Explore P: 0.5783
Episode: 269 Total reward: 9.0 Training loss: 31.3878 Explore P: 0.5778
Episode: 270 Total reward: 12.0 Training loss: 2398.3108 Explore P: 0.5771
Episode: 271 Total reward: 27.0 Training loss: 15.6864 Explore P: 0.5756
Episode: 272 Total reward: 9.0 Training loss: 14.7353 Explore P: 0.5751
Episode: 273 Total reward: 20.0 Training loss: 14358.8828 Explore P: 0.5740
Episode: 274 Total reward: 11.0 Training loss: 505.4643 Explore P: 0.5734
Episode: 275 Total reward: 12.0 Training loss: 775.4535 Explore P: 0.5727
Episode: 276 Total reward: 10.0 Training loss: 685.5820 Explore P: 0.5721
Episode: 277 Total reward: 12.0 Training loss: 22.1317 Explore P: 0.5714
Episode: 278 Total reward: 13.0 Training loss: 9.7825 Explore P: 0.5707
Episode: 279 Total reward: 12.0 Training loss: 18.2383 Explore P: 0.5700
Episode: 280 Total reward: 22.0 Training loss: 620.8180 Explore P: 0.5688
Episode: 281 Total reward: 12.0 Training loss: 3160.5129 Explore P: 0.5681
Episode: 282 Total reward: 12.0 Training loss: 34.2596 Explore P: 0.5675
Episode: 283 Total reward: 10.0 Training loss: 710.8776 Explore P: 0.5669
Episode: 284 Total reward: 25.0 Training loss: 14.6413 Explore P: 0.5655
Episode: 285 Total reward: 8.0 Training loss: 2192.1277 Explore P: 0.5651
Episode: 286 Total reward: 10.0 Training loss: 19.3262 Explore P: 0.5645
Episode: 287 Total reward: 10.0 Training loss: 26.7271 Explore P: 0.5640
Episode: 288 Total reward: 20.0 Training loss: 874.6312 Explore P: 0.5629
Episode: 289 Total reward: 8.0 Training loss: 25.4117 Explore P: 0.5624
Episode: 290 Total reward: 16.0 Training loss: 510.8039 Explore P: 0.5615
Episode: 291 Total reward: 35.0 Training loss: 507.0634 Explore P: 0.5596
Episode: 292 Total reward: 39.0 Training loss: 19.2204 Explore P: 0.5575
Episode: 293 Total reward: 14.0 Training loss: 2035.6892 Explore P: 0.5567
Episode: 294 Total reward: 15.0 Training loss: 13.9245 Explore P: 0.5559
Episode: 295 Total reward: 17.0 Training loss: 18.2830 Explore P: 0.5550
Episode: 296 Total reward: 24.0 Training loss: 1134.6091 Explore P: 0.5536
Episode: 297 Total reward: 16.0 Training loss: 1191.5876 Explore P: 0.5528
Episode: 298 Total reward: 10.0 Training loss: 11.2063 Explore P: 0.5522
Episode: 299 Total reward: 23.0 Training loss: 16.2845 Explore P: 0.5510
Episode: 300 Total reward: 11.0 Training loss: 1508.8815 Explore P: 0.5504
Episode: 301 Total reward: 8.0 Training loss: 1898.6448 Explore P: 0.5500
Episode: 302 Total reward: 13.0 Training loss: 1811.7810 Explore P: 0.5493
Episode: 303 Total reward: 9.0 Training loss: 750.8111 Explore P: 0.5488
Episode: 304 Total reward: 11.0 Training loss: 2661.1360 Explore P: 0.5482
Episode: 305 Total reward: 14.0 Training loss: 609.3965 Explore P: 0.5474
Episode: 306 Total reward: 12.0 Training loss: 17.7551 Explore P: 0.5468
Episode: 307 Total reward: 17.0 Training loss: 12.5250 Explore P: 0.5459
Episode: 308 Total reward: 26.0 Training loss: 2239.8113 Explore P: 0.5445
Episode: 309 Total reward: 10.0 Training loss: 15.3298 Explore P: 0.5440
Episode: 310 Total reward: 18.0 Training loss: 511.7708 Explore P: 0.5430
Episode: 311 Total reward: 13.0 Training loss: 1040.2487 Explore P: 0.5423
Episode: 312 Total reward: 16.0 Training loss: 473.7540 Explore P: 0.5414
Episode: 313 Total reward: 17.0 Training loss: 17.1217 Explore P: 0.5405
Episode: 314 Total reward: 10.0 Training loss: 16.9178 Explore P: 0.5400
Episode: 315 Total reward: 11.0 Training loss: 2982.5537 Explore P: 0.5394
Episode: 316 Total reward: 18.0 Training loss: 18.6705 Explore P: 0.5385
Episode: 317 Total reward: 33.0 Training loss: 2201.3279 Explore P: 0.5367
Episode: 318 Total reward: 13.0 Training loss: 923.5317 Explore P: 0.5361
Episode: 319 Total reward: 15.0 Training loss: 24.6642 Explore P: 0.5353
Episode: 320 Total reward: 8.0 Training loss: 646.1931 Explore P: 0.5348
Episode: 321 Total reward: 13.0 Training loss: 606.1357 Explore P: 0.5342
Episode: 322 Total reward: 18.0 Training loss: 28.9088 Explore P: 0.5332
Episode: 323 Total reward: 10.0 Training loss: 406.5051 Explore P: 0.5327
Episode: 324 Total reward: 27.0 Training loss: 25.6876 Explore P: 0.5313
Episode: 325 Total reward: 10.0 Training loss: 734.9943 Explore P: 0.5308
Episode: 326 Total reward: 13.0 Training loss: 17.5832 Explore P: 0.5301
Episode: 327 Total reward: 13.0 Training loss: 3052.4731 Explore P: 0.5294
Episode: 328 Total reward: 8.0 Training loss: 19.4911 Explore P: 0.5290
Episode: 329 Total reward: 24.0 Training loss: 2470.5872 Explore P: 0.5278
Episode: 330 Total reward: 18.0 Training loss: 17.6961 Explore P: 0.5268
Episode: 331 Total reward: 12.0 Training loss: 1883.9108 Explore P: 0.5262
Episode: 332 Total reward: 12.0 Training loss: 16.8807 Explore P: 0.5256
Episode: 333 Total reward: 10.0 Training loss: 14.4583 Explore P: 0.5251
Episode: 334 Total reward: 21.0 Training loss: 2276.5396 Explore P: 0.5240
Episode: 335 Total reward: 9.0 Training loss: 7.8440 Explore P: 0.5235
Episode: 336 Total reward: 12.0 Training loss: 14.5624 Explore P: 0.5229
Episode: 337 Total reward: 10.0 Training loss: 2540.2903 Explore P: 0.5224
Episode: 338 Total reward: 13.0 Training loss: 470.6934 Explore P: 0.5217
Episode: 339 Total reward: 9.0 Training loss: 17.5104 Explore P: 0.5213
Episode: 340 Total reward: 14.0 Training loss: 12.8044 Explore P: 0.5206
Episode: 341 Total reward: 14.0 Training loss: 984.1576 Explore P: 0.5198
Episode: 342 Total reward: 11.0 Training loss: 11.8259 Explore P: 0.5193
Episode: 343 Total reward: 8.0 Training loss: 645.4559 Explore P: 0.5189
Episode: 344 Total reward: 12.0 Training loss: 396.2121 Explore P: 0.5183
Episode: 345 Total reward: 15.0 Training loss: 12.1033 Explore P: 0.5175
Episode: 346 Total reward: 11.0 Training loss: 2260.5591 Explore P: 0.5169
Episode: 347 Total reward: 26.0 Training loss: 10.2991 Explore P: 0.5156
Episode: 348 Total reward: 11.0 Training loss: 8.6716 Explore P: 0.5151
Episode: 349 Total reward: 18.0 Training loss: 13.4752 Explore P: 0.5142
Episode: 350 Total reward: 18.0 Training loss: 2264.0474 Explore P: 0.5133
Episode: 351 Total reward: 14.0 Training loss: 22.1365 Explore P: 0.5126
Episode: 352 Total reward: 16.0 Training loss: 14249.8379 Explore P: 0.5118
Episode: 353 Total reward: 16.0 Training loss: 448.7430 Explore P: 0.5109
Episode: 354 Total reward: 13.0 Training loss: 1878.0905 Explore P: 0.5103
Episode: 355 Total reward: 14.0 Training loss: 958.3232 Explore P: 0.5096
Episode: 356 Total reward: 8.0 Training loss: 2861.6284 Explore P: 0.5092
Episode: 357 Total reward: 9.0 Training loss: 11687.9805 Explore P: 0.5087
Episode: 358 Total reward: 9.0 Training loss: 9.2547 Explore P: 0.5083
Episode: 359 Total reward: 12.0 Training loss: 1794.3864 Explore P: 0.5077
Episode: 360 Total reward: 19.0 Training loss: 12.0000 Explore P: 0.5068
Episode: 361 Total reward: 11.0 Training loss: 2041.6752 Explore P: 0.5062
Episode: 362 Total reward: 7.0 Training loss: 15.6710 Explore P: 0.5059
Episode: 363 Total reward: 22.0 Training loss: 306.6039 Explore P: 0.5048
Episode: 364 Total reward: 17.0 Training loss: 1709.5319 Explore P: 0.5039
Episode: 365 Total reward: 12.0 Training loss: 13.6199 Explore P: 0.5033
Episode: 366 Total reward: 14.0 Training loss: 389.3366 Explore P: 0.5027
Episode: 367 Total reward: 12.0 Training loss: 11.2351 Explore P: 0.5021
Episode: 368 Total reward: 11.0 Training loss: 12.0502 Explore P: 0.5015
Episode: 369 Total reward: 9.0 Training loss: 318.7679 Explore P: 0.5011
Episode: 370 Total reward: 14.0 Training loss: 567.2211 Explore P: 0.5004
Episode: 371 Total reward: 46.0 Training loss: 13.6296 Explore P: 0.4981
Episode: 372 Total reward: 10.0 Training loss: 19.5611 Explore P: 0.4977
Episode: 373 Total reward: 18.0 Training loss: 827.3085 Explore P: 0.4968
Episode: 374 Total reward: 17.0 Training loss: 6.7134 Explore P: 0.4959
Episode: 375 Total reward: 14.0 Training loss: 2675.8379 Explore P: 0.4953
Episode: 376 Total reward: 22.0 Training loss: 10.9745 Explore P: 0.4942
Episode: 377 Total reward: 20.0 Training loss: 12.4000 Explore P: 0.4932
Episode: 378 Total reward: 12.0 Training loss: 424.8512 Explore P: 0.4927
Episode: 379 Total reward: 12.0 Training loss: 14.3740 Explore P: 0.4921
Episode: 380 Total reward: 10.0 Training loss: 2511.8311 Explore P: 0.4916
Episode: 381 Total reward: 9.0 Training loss: 505.0193 Explore P: 0.4912
Episode: 382 Total reward: 31.0 Training loss: 387.2974 Explore P: 0.4897
Episode: 383 Total reward: 18.0 Training loss: 11.4671 Explore P: 0.4888
Episode: 384 Total reward: 28.0 Training loss: 1366.8923 Explore P: 0.4875
Episode: 385 Total reward: 16.0 Training loss: 307.9189 Explore P: 0.4867
Episode: 386 Total reward: 8.0 Training loss: 10.5875 Explore P: 0.4863
Episode: 387 Total reward: 11.0 Training loss: 3587.6062 Explore P: 0.4858
Episode: 388 Total reward: 18.0 Training loss: 5.8771 Explore P: 0.4849
Episode: 389 Total reward: 11.0 Training loss: 1515.3159 Explore P: 0.4844
Episode: 390 Total reward: 16.0 Training loss: 1307.3737 Explore P: 0.4837
Episode: 391 Total reward: 10.0 Training loss: 7.8306 Explore P: 0.4832
Episode: 392 Total reward: 12.0 Training loss: 2105.0166 Explore P: 0.4826
Episode: 393 Total reward: 14.0 Training loss: 6.7499 Explore P: 0.4820
Episode: 394 Total reward: 13.0 Training loss: 294.9380 Explore P: 0.4814
Episode: 395 Total reward: 19.0 Training loss: 434.8215 Explore P: 0.4805
Episode: 396 Total reward: 16.0 Training loss: 433.1816 Explore P: 0.4797
Episode: 397 Total reward: 12.0 Training loss: 6.9003 Explore P: 0.4791
Episode: 398 Total reward: 12.0 Training loss: 1617.0551 Explore P: 0.4786
Episode: 399 Total reward: 11.0 Training loss: 254.9394 Explore P: 0.4781
Episode: 400 Total reward: 9.0 Training loss: 4.5377 Explore P: 0.4776
Episode: 401 Total reward: 30.0 Training loss: 1814.2565 Explore P: 0.4762
Episode: 402 Total reward: 18.0 Training loss: 10.3146 Explore P: 0.4754
Episode: 403 Total reward: 16.0 Training loss: 2.6532 Explore P: 0.4747
Episode: 404 Total reward: 19.0 Training loss: 693.9641 Explore P: 0.4738
Episode: 405 Total reward: 13.0 Training loss: 3.9940 Explore P: 0.4732
Episode: 406 Total reward: 10.0 Training loss: 351.5669 Explore P: 0.4727
Episode: 407 Total reward: 11.0 Training loss: 299.4555 Explore P: 0.4722
Episode: 408 Total reward: 12.0 Training loss: 10.4676 Explore P: 0.4716
Episode: 409 Total reward: 26.0 Training loss: 7.6152 Explore P: 0.4705
Episode: 410 Total reward: 13.0 Training loss: 2071.2192 Explore P: 0.4699
Episode: 411 Total reward: 51.0 Training loss: 12.2107 Explore P: 0.4675
Episode: 412 Total reward: 13.0 Training loss: 967.0776 Explore P: 0.4669
Episode: 413 Total reward: 20.0 Training loss: 15.1653 Explore P: 0.4660
Episode: 414 Total reward: 15.0 Training loss: 458.5507 Explore P: 0.4653
Episode: 415 Total reward: 16.0 Training loss: 259.3179 Explore P: 0.4646
Episode: 416 Total reward: 23.0 Training loss: 1018.5815 Explore P: 0.4635
Episode: 417 Total reward: 14.0 Training loss: 7.7518 Explore P: 0.4629
Episode: 418 Total reward: 18.0 Training loss: 4.0836 Explore P: 0.4621
Episode: 419 Total reward: 14.0 Training loss: 238.3980 Explore P: 0.4615
Episode: 420 Total reward: 17.0 Training loss: 3.5531 Explore P: 0.4607
Episode: 421 Total reward: 42.0 Training loss: 934.8664 Explore P: 0.4588
Episode: 422 Total reward: 13.0 Training loss: 10.7482 Explore P: 0.4582
Episode: 423 Total reward: 26.0 Training loss: 4.8551 Explore P: 0.4571
Episode: 424 Total reward: 10.0 Training loss: 438.0523 Explore P: 0.4566
Episode: 425 Total reward: 10.0 Training loss: 3.1533 Explore P: 0.4562
Episode: 426 Total reward: 21.0 Training loss: 495.9139 Explore P: 0.4552
Episode: 427 Total reward: 17.0 Training loss: 6.5882 Explore P: 0.4545
Episode: 428 Total reward: 15.0 Training loss: 170.0226 Explore P: 0.4538
Episode: 429 Total reward: 10.0 Training loss: 379.5156 Explore P: 0.4534
Episode: 430 Total reward: 13.0 Training loss: 251.7760 Explore P: 0.4528
Episode: 431 Total reward: 12.0 Training loss: 264.2087 Explore P: 0.4523
Episode: 432 Total reward: 12.0 Training loss: 8.5085 Explore P: 0.4517
Episode: 433 Total reward: 11.0 Training loss: 7.8822 Explore P: 0.4512
Episode: 434 Total reward: 25.0 Training loss: 5.5916 Explore P: 0.4501
Episode: 435 Total reward: 18.0 Training loss: 1198.3523 Explore P: 0.4494
Episode: 436 Total reward: 11.0 Training loss: 975.9279 Explore P: 0.4489
Episode: 437 Total reward: 14.0 Training loss: 7.0462 Explore P: 0.4483
Episode: 438 Total reward: 16.0 Training loss: 766.6583 Explore P: 0.4476
Episode: 439 Total reward: 16.0 Training loss: 7.1953 Explore P: 0.4469
Episode: 440 Total reward: 11.0 Training loss: 2335.2944 Explore P: 0.4464
Episode: 441 Total reward: 41.0 Training loss: 4.8481 Explore P: 0.4446
Episode: 442 Total reward: 18.0 Training loss: 3.7209 Explore P: 0.4438
Episode: 443 Total reward: 15.0 Training loss: 4.3218 Explore P: 0.4432
Episode: 444 Total reward: 29.0 Training loss: 2721.1987 Explore P: 0.4419
Episode: 445 Total reward: 13.0 Training loss: 215.2063 Explore P: 0.4413
Episode: 446 Total reward: 15.0 Training loss: 7.8983 Explore P: 0.4407
Episode: 447 Total reward: 11.0 Training loss: 169.7182 Explore P: 0.4402
Episode: 448 Total reward: 16.0 Training loss: 1718.5627 Explore P: 0.4395
Episode: 449 Total reward: 15.0 Training loss: 663.4957 Explore P: 0.4389
Episode: 450 Total reward: 11.0 Training loss: 98.4129 Explore P: 0.4384
Episode: 451 Total reward: 17.0 Training loss: 1242.5032 Explore P: 0.4377
Episode: 452 Total reward: 27.0 Training loss: 5.2918 Explore P: 0.4365
Episode: 453 Total reward: 18.0 Training loss: 329.4759 Explore P: 0.4358
Episode: 454 Total reward: 19.0 Training loss: 543.0585 Explore P: 0.4350
Episode: 455 Total reward: 14.0 Training loss: 7.8573 Explore P: 0.4344
Episode: 456 Total reward: 23.0 Training loss: 454.1478 Explore P: 0.4334
Episode: 457 Total reward: 13.0 Training loss: 547.3274 Explore P: 0.4328
Episode: 458 Total reward: 12.0 Training loss: 8.0125 Explore P: 0.4323
Episode: 459 Total reward: 11.0 Training loss: 4.8602 Explore P: 0.4319
Episode: 460 Total reward: 13.0 Training loss: 464.1033 Explore P: 0.4313
Episode: 461 Total reward: 32.0 Training loss: 241.1246 Explore P: 0.4300
Episode: 462 Total reward: 14.0 Training loss: 4.9168 Explore P: 0.4294
Episode: 463 Total reward: 14.0 Training loss: 611.6248 Explore P: 0.4288
Episode: 464 Total reward: 14.0 Training loss: 216.0107 Explore P: 0.4282
Episode: 465 Total reward: 14.0 Training loss: 522.1945 Explore P: 0.4276
Episode: 466 Total reward: 16.0 Training loss: 206.5324 Explore P: 0.4270
Episode: 467 Total reward: 26.0 Training loss: 646.1320 Explore P: 0.4259
Episode: 468 Total reward: 10.0 Training loss: 34.2836 Explore P: 0.4255
Episode: 469 Total reward: 19.0 Training loss: 5.1561 Explore P: 0.4247
Episode: 470 Total reward: 17.0 Training loss: 629.2855 Explore P: 0.4240
Episode: 471 Total reward: 11.0 Training loss: 531.9976 Explore P: 0.4235
Episode: 472 Total reward: 14.0 Training loss: 336.6075 Explore P: 0.4229
Episode: 473 Total reward: 15.0 Training loss: 53.7856 Explore P: 0.4223
Episode: 474 Total reward: 36.0 Training loss: 219.3026 Explore P: 0.4208
Episode: 475 Total reward: 18.0 Training loss: 3.4661 Explore P: 0.4201
Episode: 476 Total reward: 18.0 Training loss: 254.0515 Explore P: 0.4194
Episode: 477 Total reward: 23.0 Training loss: 841.4808 Explore P: 0.4184
Episode: 478 Total reward: 36.0 Training loss: 8.6495 Explore P: 0.4170
Episode: 479 Total reward: 29.0 Training loss: 268.2657 Explore P: 0.4158
Episode: 480 Total reward: 19.0 Training loss: 5.0780 Explore P: 0.4150
Episode: 481 Total reward: 26.0 Training loss: 2.9369 Explore P: 0.4140
Episode: 482 Total reward: 31.0 Training loss: 7.7216 Explore P: 0.4127
Episode: 483 Total reward: 18.0 Training loss: 853.9831 Explore P: 0.4120
Episode: 484 Total reward: 18.0 Training loss: 84.0259 Explore P: 0.4113
Episode: 485 Total reward: 8.0 Training loss: 388.7159 Explore P: 0.4109
Episode: 486 Total reward: 30.0 Training loss: 269.9201 Explore P: 0.4097
Episode: 487 Total reward: 12.0 Training loss: 1389.4558 Explore P: 0.4093
Episode: 488 Total reward: 17.0 Training loss: 928.5421 Explore P: 0.4086
Episode: 489 Total reward: 15.0 Training loss: 1.7265 Explore P: 0.4080
Episode: 490 Total reward: 19.0 Training loss: 407.6818 Explore P: 0.4072
Episode: 491 Total reward: 37.0 Training loss: 612.4919 Explore P: 0.4058
Episode: 492 Total reward: 26.0 Training loss: 6.7501 Explore P: 0.4047
Episode: 493 Total reward: 26.0 Training loss: 209.0076 Explore P: 0.4037
Episode: 494 Total reward: 21.0 Training loss: 343.6093 Explore P: 0.4029
Episode: 495 Total reward: 48.0 Training loss: 3.9203 Explore P: 0.4010
Episode: 496 Total reward: 45.0 Training loss: 301.8509 Explore P: 0.3992
Episode: 497 Total reward: 24.0 Training loss: 8.8500 Explore P: 0.3983
Episode: 498 Total reward: 17.0 Training loss: 1170.3754 Explore P: 0.3977
Episode: 499 Total reward: 30.0 Training loss: 153.8571 Explore P: 0.3965
Episode: 500 Total reward: 48.0 Training loss: 696.7855 Explore P: 0.3946
Episode: 501 Total reward: 25.0 Training loss: 3.2578 Explore P: 0.3937
Episode: 502 Total reward: 25.0 Training loss: 7.2231 Explore P: 0.3927
Episode: 503 Total reward: 21.0 Training loss: 198.8927 Explore P: 0.3919
Episode: 504 Total reward: 21.0 Training loss: 5.9145 Explore P: 0.3911
Episode: 505 Total reward: 15.0 Training loss: 5.9346 Explore P: 0.3905
Episode: 506 Total reward: 32.0 Training loss: 3.8662 Explore P: 0.3893
Episode: 507 Total reward: 18.0 Training loss: 3.3817 Explore P: 0.3886
Episode: 508 Total reward: 24.0 Training loss: 49.5891 Explore P: 0.3877
Episode: 509 Total reward: 20.0 Training loss: 75.3168 Explore P: 0.3870
Episode: 510 Total reward: 25.0 Training loss: 3.6143 Explore P: 0.3860
Episode: 511 Total reward: 28.0 Training loss: 639.0432 Explore P: 0.3850
Episode: 512 Total reward: 34.0 Training loss: 297.9716 Explore P: 0.3837
Episode: 513 Total reward: 22.0 Training loss: 205.2259 Explore P: 0.3829
Episode: 514 Total reward: 17.0 Training loss: 2.7754 Explore P: 0.3823
Episode: 515 Total reward: 16.0 Training loss: 121.5799 Explore P: 0.3817
Episode: 516 Total reward: 17.0 Training loss: 775.7901 Explore P: 0.3810
Episode: 517 Total reward: 19.0 Training loss: 116.3986 Explore P: 0.3803
Episode: 518 Total reward: 17.0 Training loss: 4.7324 Explore P: 0.3797
Episode: 519 Total reward: 24.0 Training loss: 410.1209 Explore P: 0.3788
Episode: 520 Total reward: 30.0 Training loss: 157.6344 Explore P: 0.3777
Episode: 521 Total reward: 27.0 Training loss: 5.6855 Explore P: 0.3767
Episode: 522 Total reward: 38.0 Training loss: 573.9545 Explore P: 0.3753
Episode: 523 Total reward: 32.0 Training loss: 238.2151 Explore P: 0.3742
Episode: 524 Total reward: 20.0 Training loss: 6.0902 Explore P: 0.3734
Episode: 525 Total reward: 18.0 Training loss: 235.6646 Explore P: 0.3728
Episode: 526 Total reward: 25.0 Training loss: 306.3424 Explore P: 0.3719
Episode: 527 Total reward: 28.0 Training loss: 240.5276 Explore P: 0.3709
Episode: 528 Total reward: 20.0 Training loss: 365.1735 Explore P: 0.3701
Episode: 529 Total reward: 11.0 Training loss: 3.5649 Explore P: 0.3697
Episode: 530 Total reward: 22.0 Training loss: 130.7427 Explore P: 0.3690
Episode: 531 Total reward: 24.0 Training loss: 4.5332 Explore P: 0.3681
Episode: 532 Total reward: 25.0 Training loss: 42.1354 Explore P: 0.3672
Episode: 533 Total reward: 28.0 Training loss: 378.0653 Explore P: 0.3662
Episode: 534 Total reward: 26.0 Training loss: 5.3626 Explore P: 0.3653
Episode: 535 Total reward: 13.0 Training loss: 5.2367 Explore P: 0.3648
Episode: 536 Total reward: 23.0 Training loss: 6.0566 Explore P: 0.3640
Episode: 537 Total reward: 25.0 Training loss: 89.4480 Explore P: 0.3631
Episode: 538 Total reward: 18.0 Training loss: 389.4726 Explore P: 0.3625
Episode: 539 Total reward: 31.0 Training loss: 98.0575 Explore P: 0.3614
Episode: 540 Total reward: 17.0 Training loss: 100.9925 Explore P: 0.3608
Episode: 541 Total reward: 25.0 Training loss: 225.0518 Explore P: 0.3599
Episode: 542 Total reward: 25.0 Training loss: 7.0077 Explore P: 0.3590
Episode: 543 Total reward: 18.0 Training loss: 110.6044 Explore P: 0.3584
Episode: 544 Total reward: 29.0 Training loss: 197.6844 Explore P: 0.3574
Episode: 545 Total reward: 13.0 Training loss: 37.2853 Explore P: 0.3570
Episode: 546 Total reward: 19.0 Training loss: 203.1637 Explore P: 0.3563
Episode: 547 Total reward: 15.0 Training loss: 2.8235 Explore P: 0.3558
Episode: 548 Total reward: 23.0 Training loss: 127.1622 Explore P: 0.3550
Episode: 549 Total reward: 19.0 Training loss: 205.9512 Explore P: 0.3543
Episode: 550 Total reward: 17.0 Training loss: 7.3892 Explore P: 0.3537
Episode: 551 Total reward: 16.0 Training loss: 286.4356 Explore P: 0.3532
Episode: 552 Total reward: 17.0 Training loss: 61.2301 Explore P: 0.3526
Episode: 553 Total reward: 14.0 Training loss: 24.6704 Explore P: 0.3521
Episode: 554 Total reward: 19.0 Training loss: 4.5917 Explore P: 0.3515
Episode: 555 Total reward: 24.0 Training loss: 5.6980 Explore P: 0.3507
Episode: 556 Total reward: 17.0 Training loss: 212.3639 Explore P: 0.3501
Episode: 557 Total reward: 20.0 Training loss: 4.4784 Explore P: 0.3494
Episode: 558 Total reward: 27.0 Training loss: 82.5821 Explore P: 0.3485
Episode: 559 Total reward: 15.0 Training loss: 53.8638 Explore P: 0.3480
Episode: 560 Total reward: 18.0 Training loss: 5.9644 Explore P: 0.3474
Episode: 561 Total reward: 35.0 Training loss: 5.9584 Explore P: 0.3462
Episode: 562 Total reward: 24.0 Training loss: 260.4533 Explore P: 0.3454
Episode: 563 Total reward: 47.0 Training loss: 264.1849 Explore P: 0.3438
Episode: 564 Total reward: 45.0 Training loss: 3.0455 Explore P: 0.3423
Episode: 565 Total reward: 21.0 Training loss: 4.7239 Explore P: 0.3416
Episode: 566 Total reward: 44.0 Training loss: 3.7766 Explore P: 0.3402
Episode: 567 Total reward: 19.0 Training loss: 3.9122 Explore P: 0.3395
Episode: 568 Total reward: 66.0 Training loss: 212.2846 Explore P: 0.3374
Episode: 569 Total reward: 103.0 Training loss: 33.8501 Explore P: 0.3340
Episode: 570 Total reward: 37.0 Training loss: 184.0299 Explore P: 0.3328
Episode: 571 Total reward: 19.0 Training loss: 77.5866 Explore P: 0.3322
Episode: 572 Total reward: 20.0 Training loss: 4.6995 Explore P: 0.3316
Episode: 573 Total reward: 40.0 Training loss: 6.0328 Explore P: 0.3303
Episode: 574 Total reward: 81.0 Training loss: 5.1123 Explore P: 0.3277
Episode: 575 Total reward: 27.0 Training loss: 9.3883 Explore P: 0.3268
Episode: 576 Total reward: 30.0 Training loss: 78.4735 Explore P: 0.3259
Episode: 577 Total reward: 45.0 Training loss: 65.8872 Explore P: 0.3245
Episode: 578 Total reward: 60.0 Training loss: 43.5584 Explore P: 0.3226
Episode: 579 Total reward: 42.0 Training loss: 4.4862 Explore P: 0.3213
Episode: 580 Total reward: 61.0 Training loss: 8.0100 Explore P: 0.3194
Episode: 581 Total reward: 62.0 Training loss: 128.8654 Explore P: 0.3175
Episode: 582 Total reward: 40.0 Training loss: 168.7390 Explore P: 0.3163
Episode: 583 Total reward: 29.0 Training loss: 9.9085 Explore P: 0.3154
Episode: 584 Total reward: 30.0 Training loss: 4.3371 Explore P: 0.3144
Episode: 585 Total reward: 32.0 Training loss: 4.5118 Explore P: 0.3135
Episode: 586 Total reward: 25.0 Training loss: 29.6014 Explore P: 0.3127
Episode: 587 Total reward: 35.0 Training loss: 7.8034 Explore P: 0.3117
Episode: 588 Total reward: 33.0 Training loss: 3541.6692 Explore P: 0.3107
Episode: 589 Total reward: 39.0 Training loss: 3.1998 Explore P: 0.3095
Episode: 590 Total reward: 53.0 Training loss: 158.7361 Explore P: 0.3079
Episode: 591 Total reward: 80.0 Training loss: 6.1514 Explore P: 0.3055
Episode: 592 Total reward: 65.0 Training loss: 8.9506 Explore P: 0.3036
Episode: 593 Total reward: 37.0 Training loss: 268.1830 Explore P: 0.3025
Episode: 594 Total reward: 45.0 Training loss: 2.8680 Explore P: 0.3012
Episode: 595 Total reward: 47.0 Training loss: 5.8958 Explore P: 0.2999
Episode: 596 Total reward: 37.0 Training loss: 6.5402 Explore P: 0.2988
Episode: 597 Total reward: 37.0 Training loss: 28.5462 Explore P: 0.2977
Episode: 598 Total reward: 39.0 Training loss: 63.8882 Explore P: 0.2966
Episode: 599 Total reward: 36.0 Training loss: 153.0553 Explore P: 0.2956
Episode: 600 Total reward: 51.0 Training loss: 17.2110 Explore P: 0.2941
Episode: 601 Total reward: 35.0 Training loss: 8.3424 Explore P: 0.2931
Episode: 602 Total reward: 45.0 Training loss: 95.4431 Explore P: 0.2919
Episode: 603 Total reward: 46.0 Training loss: 4.3492 Explore P: 0.2906
Episode: 604 Total reward: 42.0 Training loss: 56.7290 Explore P: 0.2894
Episode: 605 Total reward: 50.0 Training loss: 2.5836 Explore P: 0.2880
Episode: 606 Total reward: 40.0 Training loss: 32.4431 Explore P: 0.2869
Episode: 607 Total reward: 34.0 Training loss: 10.6222 Explore P: 0.2859
Episode: 608 Total reward: 45.0 Training loss: 117.3146 Explore P: 0.2847
Episode: 609 Total reward: 42.0 Training loss: 8.8554 Explore P: 0.2836
Episode: 610 Total reward: 39.0 Training loss: 12.3777 Explore P: 0.2825
Episode: 611 Total reward: 43.0 Training loss: 4.8672 Explore P: 0.2813
Episode: 612 Total reward: 35.0 Training loss: 6.4338 Explore P: 0.2804
Episode: 613 Total reward: 40.0 Training loss: 3.9079 Explore P: 0.2793
Episode: 614 Total reward: 40.0 Training loss: 38.9865 Explore P: 0.2782
Episode: 615 Total reward: 31.0 Training loss: 56.0722 Explore P: 0.2774
Episode: 616 Total reward: 47.0 Training loss: 4.1930 Explore P: 0.2761
Episode: 617 Total reward: 26.0 Training loss: 33.3703 Explore P: 0.2754
Episode: 618 Total reward: 23.0 Training loss: 3.7547 Explore P: 0.2748
Episode: 619 Total reward: 102.0 Training loss: 7.1800 Explore P: 0.2721
Episode: 620 Total reward: 60.0 Training loss: 4.8917 Explore P: 0.2706
Episode: 621 Total reward: 33.0 Training loss: 3.9055 Explore P: 0.2697
Episode: 622 Total reward: 84.0 Training loss: 108.1593 Explore P: 0.2675
Episode: 623 Total reward: 96.0 Training loss: 5.6092 Explore P: 0.2651
Episode: 624 Total reward: 77.0 Training loss: 7.1489 Explore P: 0.2631
Episode: 625 Total reward: 55.0 Training loss: 16.4858 Explore P: 0.2617
Episode: 626 Total reward: 43.0 Training loss: 18.5192 Explore P: 0.2607
Episode: 627 Total reward: 34.0 Training loss: 3.1746 Explore P: 0.2598
Episode: 628 Total reward: 33.0 Training loss: 86.7883 Explore P: 0.2590
Episode: 629 Total reward: 44.0 Training loss: 2.2608 Explore P: 0.2579
Episode: 630 Total reward: 27.0 Training loss: 4.3098 Explore P: 0.2572
Episode: 631 Total reward: 54.0 Training loss: 9.6541 Explore P: 0.2559
Episode: 632 Total reward: 37.0 Training loss: 22.2504 Explore P: 0.2550
Episode: 633 Total reward: 37.0 Training loss: 6.5687 Explore P: 0.2541
Episode: 634 Total reward: 31.0 Training loss: 73.9561 Explore P: 0.2533
Episode: 635 Total reward: 37.0 Training loss: 39.2320 Explore P: 0.2524
Episode: 636 Total reward: 26.0 Training loss: 6.7892 Explore P: 0.2518
Episode: 637 Total reward: 31.0 Training loss: 1.5057 Explore P: 0.2511
Episode: 638 Total reward: 56.0 Training loss: 189.0412 Explore P: 0.2497
Episode: 639 Total reward: 45.0 Training loss: 8.0887 Explore P: 0.2486
Episode: 640 Total reward: 31.0 Training loss: 84.1479 Explore P: 0.2479
Episode: 641 Total reward: 38.0 Training loss: 33.8725 Explore P: 0.2470
Episode: 642 Total reward: 39.0 Training loss: 5.8959 Explore P: 0.2461
Episode: 643 Total reward: 93.0 Training loss: 4.4480 Explore P: 0.2439
Episode: 644 Total reward: 58.0 Training loss: 14.2085 Explore P: 0.2425
Episode: 645 Total reward: 31.0 Training loss: 3.3501 Explore P: 0.2418
Episode: 646 Total reward: 41.0 Training loss: 76.1727 Explore P: 0.2409
Episode: 647 Total reward: 40.0 Training loss: 9.9661 Explore P: 0.2399
Episode: 648 Total reward: 36.0 Training loss: 502.1139 Explore P: 0.2391
Episode: 649 Total reward: 26.0 Training loss: 5.9730 Explore P: 0.2385
Episode: 650 Total reward: 30.0 Training loss: 7.8049 Explore P: 0.2378
Episode: 651 Total reward: 34.0 Training loss: 94.6944 Explore P: 0.2371
Episode: 652 Total reward: 40.0 Training loss: 24.5197 Explore P: 0.2362
Episode: 653 Total reward: 20.0 Training loss: 42.2009 Explore P: 0.2357
Episode: 654 Total reward: 33.0 Training loss: 10.6266 Explore P: 0.2350
Episode: 655 Total reward: 41.0 Training loss: 13.4396 Explore P: 0.2340
Episode: 656 Total reward: 34.0 Training loss: 32.6747 Explore P: 0.2333
Episode: 657 Total reward: 28.0 Training loss: 75.9534 Explore P: 0.2327
Episode: 658 Total reward: 30.0 Training loss: 78.0404 Explore P: 0.2320
Episode: 659 Total reward: 34.0 Training loss: 134.9823 Explore P: 0.2312
Episode: 660 Total reward: 39.0 Training loss: 44.7073 Explore P: 0.2304
Episode: 661 Total reward: 30.0 Training loss: 6.0627 Explore P: 0.2297
Episode: 662 Total reward: 18.0 Training loss: 4.0473 Explore P: 0.2293
Episode: 663 Total reward: 24.0 Training loss: 5.3534 Explore P: 0.2288
Episode: 664 Total reward: 27.0 Training loss: 15.0171 Explore P: 0.2282
Episode: 665 Total reward: 23.0 Training loss: 6.8084 Explore P: 0.2277
Episode: 666 Total reward: 31.0 Training loss: 5.0730 Explore P: 0.2270
Episode: 667 Total reward: 18.0 Training loss: 51.9317 Explore P: 0.2266
Episode: 668 Total reward: 29.0 Training loss: 53.9886 Explore P: 0.2260
Episode: 669 Total reward: 21.0 Training loss: 126.1072 Explore P: 0.2256
Episode: 670 Total reward: 20.0 Training loss: 77.7373 Explore P: 0.2251
Episode: 671 Total reward: 22.0 Training loss: 5.6996 Explore P: 0.2246
Episode: 672 Total reward: 20.0 Training loss: 23.8649 Explore P: 0.2242
Episode: 673 Total reward: 37.0 Training loss: 3.7537 Explore P: 0.2234
Episode: 674 Total reward: 25.0 Training loss: 2.3030 Explore P: 0.2229
Episode: 675 Total reward: 26.0 Training loss: 5.7478 Explore P: 0.2223
Episode: 676 Total reward: 15.0 Training loss: 8.2644 Explore P: 0.2220
Episode: 677 Total reward: 26.0 Training loss: 176.0338 Explore P: 0.2215
Episode: 678 Total reward: 24.0 Training loss: 9.4650 Explore P: 0.2210
Episode: 679 Total reward: 38.0 Training loss: 4.7542 Explore P: 0.2202
Episode: 680 Total reward: 27.0 Training loss: 2.9297 Explore P: 0.2196
Episode: 681 Total reward: 40.0 Training loss: 10.8870 Explore P: 0.2188
Episode: 682 Total reward: 28.0 Training loss: 53.3684 Explore P: 0.2182
Episode: 683 Total reward: 36.0 Training loss: 5.0648 Explore P: 0.2174
Episode: 684 Total reward: 39.0 Training loss: 3.7231 Explore P: 0.2166
Episode: 685 Total reward: 31.0 Training loss: 5.1630 Explore P: 0.2160
Episode: 686 Total reward: 35.0 Training loss: 6.6538 Explore P: 0.2153
Episode: 687 Total reward: 35.0 Training loss: 6.6423 Explore P: 0.2145
Episode: 688 Total reward: 37.0 Training loss: 22.5066 Explore P: 0.2138
Episode: 689 Total reward: 29.0 Training loss: 49.0416 Explore P: 0.2132
Episode: 690 Total reward: 24.0 Training loss: 23.6996 Explore P: 0.2127
Episode: 691 Total reward: 20.0 Training loss: 6.1629 Explore P: 0.2123
Episode: 692 Total reward: 21.0 Training loss: 20.2038 Explore P: 0.2119
Episode: 693 Total reward: 22.0 Training loss: 77.5055 Explore P: 0.2114
Episode: 694 Total reward: 48.0 Training loss: 2.3779 Explore P: 0.2105
Episode: 695 Total reward: 18.0 Training loss: 28.9267 Explore P: 0.2101
Episode: 696 Total reward: 37.0 Training loss: 18.2988 Explore P: 0.2094
Episode: 697 Total reward: 32.0 Training loss: 149.0555 Explore P: 0.2087
Episode: 698 Total reward: 25.0 Training loss: 5.2044 Explore P: 0.2082
Episode: 699 Total reward: 22.0 Training loss: 6.0675 Explore P: 0.2078
Episode: 700 Total reward: 18.0 Training loss: 14.7760 Explore P: 0.2075
Episode: 701 Total reward: 25.0 Training loss: 2.7021 Explore P: 0.2070
Episode: 702 Total reward: 21.0 Training loss: 43.9106 Explore P: 0.2065
Episode: 703 Total reward: 35.0 Training loss: 48.6368 Explore P: 0.2059
Episode: 704 Total reward: 26.0 Training loss: 4.4747 Explore P: 0.2054
Episode: 705 Total reward: 23.0 Training loss: 51.1720 Explore P: 0.2049
Episode: 706 Total reward: 25.0 Training loss: 5.1769 Explore P: 0.2044
Episode: 707 Total reward: 40.0 Training loss: 18.6617 Explore P: 0.2036
Episode: 708 Total reward: 24.0 Training loss: 78.3689 Explore P: 0.2032
Episode: 709 Total reward: 31.0 Training loss: 9.2608 Explore P: 0.2026
Episode: 710 Total reward: 23.0 Training loss: 32.7557 Explore P: 0.2021
Episode: 711 Total reward: 35.0 Training loss: 4.2644 Explore P: 0.2015
Episode: 712 Total reward: 33.0 Training loss: 25.5676 Explore P: 0.2008
Episode: 713 Total reward: 32.0 Training loss: 2.8764 Explore P: 0.2002
Episode: 714 Total reward: 35.0 Training loss: 3.8180 Explore P: 0.1996
Episode: 715 Total reward: 24.0 Training loss: 5.7022 Explore P: 0.1991
Episode: 716 Total reward: 26.0 Training loss: 904.5330 Explore P: 0.1986
Episode: 717 Total reward: 60.0 Training loss: 70.2445 Explore P: 0.1975
Episode: 718 Total reward: 29.0 Training loss: 21.1503 Explore P: 0.1969
Episode: 719 Total reward: 31.0 Training loss: 1.1548 Explore P: 0.1964
Episode: 720 Total reward: 41.0 Training loss: 58.4807 Explore P: 0.1956
Episode: 721 Total reward: 30.0 Training loss: 3.7433 Explore P: 0.1950
Episode: 722 Total reward: 20.0 Training loss: 3.1594 Explore P: 0.1947
Episode: 723 Total reward: 36.0 Training loss: 5.5467 Explore P: 0.1940
Episode: 724 Total reward: 27.0 Training loss: 6.8184 Explore P: 0.1935
Episode: 725 Total reward: 26.0 Training loss: 5.0006 Explore P: 0.1930
Episode: 726 Total reward: 33.0 Training loss: 4.5762 Explore P: 0.1924
Episode: 727 Total reward: 22.0 Training loss: 57.5509 Explore P: 0.1920
Episode: 728 Total reward: 49.0 Training loss: 7.7875 Explore P: 0.1911
Episode: 729 Total reward: 36.0 Training loss: 21.5389 Explore P: 0.1905
Episode: 730 Total reward: 29.0 Training loss: 50.8841 Explore P: 0.1900
Episode: 731 Total reward: 34.0 Training loss: 82.7065 Explore P: 0.1894
Episode: 732 Total reward: 29.0 Training loss: 2.1687 Explore P: 0.1888
Episode: 733 Total reward: 23.0 Training loss: 2.3640 Explore P: 0.1884
Episode: 734 Total reward: 37.0 Training loss: 5.6865 Explore P: 0.1878
Episode: 735 Total reward: 27.0 Training loss: 2.3244 Explore P: 0.1873
Episode: 736 Total reward: 87.0 Training loss: 2.7052 Explore P: 0.1858
Episode: 737 Total reward: 35.0 Training loss: 2.4801 Explore P: 0.1851
Episode: 738 Total reward: 41.0 Training loss: 2.2179 Explore P: 0.1844
Episode: 739 Total reward: 50.0 Training loss: 12.5403 Explore P: 0.1836
Episode: 740 Total reward: 70.0 Training loss: 19.7735 Explore P: 0.1823
Episode: 741 Total reward: 48.0 Training loss: 5.8427 Explore P: 0.1815
Episode: 742 Total reward: 98.0 Training loss: 79.3475 Explore P: 0.1798
Episode: 743 Total reward: 48.0 Training loss: 118.0547 Explore P: 0.1790
Episode: 744 Total reward: 41.0 Training loss: 24.0809 Explore P: 0.1783
Episode: 745 Total reward: 37.0 Training loss: 64.8641 Explore P: 0.1777
Episode: 746 Total reward: 40.0 Training loss: 2.0824 Explore P: 0.1771
Episode: 747 Total reward: 71.0 Training loss: 2.0848 Explore P: 0.1759
Episode: 748 Total reward: 48.0 Training loss: 4.1659 Explore P: 0.1751
Episode: 749 Total reward: 61.0 Training loss: 4.9902 Explore P: 0.1741
Episode: 750 Total reward: 67.0 Training loss: 5.9283 Explore P: 0.1730
Episode: 751 Total reward: 29.0 Training loss: 52.0283 Explore P: 0.1725
Episode: 752 Total reward: 36.0 Training loss: 2.3619 Explore P: 0.1719
Episode: 753 Total reward: 62.0 Training loss: 54.8476 Explore P: 0.1709
Episode: 754 Total reward: 48.0 Training loss: 1.7420 Explore P: 0.1701
Episode: 755 Total reward: 99.0 Training loss: 363.3338 Explore P: 0.1686
Episode: 756 Total reward: 58.0 Training loss: 0.9604 Explore P: 0.1677
Episode: 757 Total reward: 58.0 Training loss: 0.8592 Explore P: 0.1667
Episode: 758 Total reward: 36.0 Training loss: 3.6604 Explore P: 0.1662
Episode: 759 Total reward: 49.0 Training loss: 1.7767 Explore P: 0.1654
Episode: 760 Total reward: 56.0 Training loss: 2.2053 Explore P: 0.1645
Episode: 761 Total reward: 28.0 Training loss: 200.0378 Explore P: 0.1641
Episode: 762 Total reward: 43.0 Training loss: 126.6259 Explore P: 0.1635
Episode: 763 Total reward: 62.0 Training loss: 5.9595 Explore P: 0.1625
Episode: 764 Total reward: 31.0 Training loss: 4.2685 Explore P: 0.1620
Episode: 765 Total reward: 36.0 Training loss: 4.8309 Explore P: 0.1615
Episode: 766 Total reward: 61.0 Training loss: 60.8729 Explore P: 0.1606
Episode: 767 Total reward: 56.0 Training loss: 14.9212 Explore P: 0.1597
Episode: 768 Total reward: 51.0 Training loss: 2.0420 Explore P: 0.1590
Episode: 769 Total reward: 50.0 Training loss: 59.6588 Explore P: 0.1582
Episode: 770 Total reward: 40.0 Training loss: 2.8628 Explore P: 0.1576
Episode: 771 Total reward: 26.0 Training loss: 2.1876 Explore P: 0.1572
Episode: 772 Total reward: 36.0 Training loss: 2.6843 Explore P: 0.1567
Episode: 773 Total reward: 38.0 Training loss: 1.9430 Explore P: 0.1562
Episode: 774 Total reward: 58.0 Training loss: 11.1358 Explore P: 0.1553
Episode: 775 Total reward: 42.0 Training loss: 3.3864 Explore P: 0.1547
Episode: 776 Total reward: 38.0 Training loss: 2.6025 Explore P: 0.1542
Episode: 777 Total reward: 35.0 Training loss: 2.4224 Explore P: 0.1537
Episode: 778 Total reward: 35.0 Training loss: 18.4421 Explore P: 0.1532
Episode: 779 Total reward: 37.0 Training loss: 4.6206 Explore P: 0.1526
Episode: 780 Total reward: 67.0 Training loss: 2.5203 Explore P: 0.1517
Episode: 781 Total reward: 37.0 Training loss: 0.4618 Explore P: 0.1511
Episode: 782 Total reward: 54.0 Training loss: 4.2466 Explore P: 0.1504
Episode: 783 Total reward: 53.0 Training loss: 3.6517 Explore P: 0.1496
Episode: 784 Total reward: 56.0 Training loss: 6.1881 Explore P: 0.1489
Episode: 785 Total reward: 44.0 Training loss: 1.7604 Explore P: 0.1483
Episode: 786 Total reward: 59.0 Training loss: 1.4898 Explore P: 0.1474
Episode: 787 Total reward: 43.0 Training loss: 3.3405 Explore P: 0.1469
Episode: 788 Total reward: 27.0 Training loss: 127.9671 Explore P: 0.1465
Episode: 789 Total reward: 41.0 Training loss: 2.9552 Explore P: 0.1459
Episode: 790 Total reward: 70.0 Training loss: 2.9942 Explore P: 0.1450
Episode: 791 Total reward: 42.0 Training loss: 2.8949 Explore P: 0.1444
Episode: 792 Total reward: 33.0 Training loss: 5.4970 Explore P: 0.1440
Episode: 793 Total reward: 51.0 Training loss: 1.3554 Explore P: 0.1433
Episode: 794 Total reward: 43.0 Training loss: 0.7841 Explore P: 0.1427
Episode: 795 Total reward: 53.0 Training loss: 1.3484 Explore P: 0.1420
Episode: 796 Total reward: 121.0 Training loss: 1.7600 Explore P: 0.1404
Episode: 797 Total reward: 86.0 Training loss: 36.7660 Explore P: 0.1393
Episode: 798 Total reward: 38.0 Training loss: 1.2794 Explore P: 0.1388
Episode: 799 Total reward: 43.0 Training loss: 0.9256 Explore P: 0.1383
Episode: 800 Total reward: 92.0 Training loss: 0.5621 Explore P: 0.1371
Episode: 801 Total reward: 118.0 Training loss: 0.6442 Explore P: 0.1356
Episode: 802 Total reward: 52.0 Training loss: 8.5783 Explore P: 0.1349
Episode: 803 Total reward: 63.0 Training loss: 1.4115 Explore P: 0.1342
Episode: 804 Total reward: 83.0 Training loss: 1.7019 Explore P: 0.1331
Episode: 805 Total reward: 53.0 Training loss: 0.9256 Explore P: 0.1325
Episode: 806 Total reward: 28.0 Training loss: 3.2014 Explore P: 0.1321
Episode: 807 Total reward: 32.0 Training loss: 297.7047 Explore P: 0.1318
Episode: 808 Total reward: 34.0 Training loss: 21.8687 Explore P: 0.1313
Episode: 809 Total reward: 48.0 Training loss: 3.6502 Explore P: 0.1308
Episode: 810 Total reward: 46.0 Training loss: 0.5735 Explore P: 0.1302
Episode: 811 Total reward: 34.0 Training loss: 0.9185 Explore P: 0.1298
Episode: 812 Total reward: 58.0 Training loss: 0.5429 Explore P: 0.1291
Episode: 813 Total reward: 42.0 Training loss: 34.8559 Explore P: 0.1286
Episode: 814 Total reward: 54.0 Training loss: 1.1691 Explore P: 0.1280
Episode: 815 Total reward: 52.0 Training loss: 2.8903 Explore P: 0.1274
Episode: 816 Total reward: 79.0 Training loss: 1.0637 Explore P: 0.1264
Episode: 817 Total reward: 46.0 Training loss: 1.7267 Explore P: 0.1259
Episode: 818 Total reward: 92.0 Training loss: 13.8054 Explore P: 0.1248
Episode: 819 Total reward: 48.0 Training loss: 1.2360 Explore P: 0.1243
Episode: 820 Total reward: 46.0 Training loss: 0.8049 Explore P: 0.1238
Episode: 821 Total reward: 43.0 Training loss: 33.1233 Explore P: 0.1233
Episode: 822 Total reward: 112.0 Training loss: 0.6822 Explore P: 0.1220
Episode: 823 Total reward: 43.0 Training loss: 0.8931 Explore P: 0.1215
Episode: 824 Total reward: 43.0 Training loss: 0.7396 Explore P: 0.1211
Episode: 825 Total reward: 83.0 Training loss: 0.5648 Explore P: 0.1201
Episode: 826 Total reward: 63.0 Training loss: 0.9254 Explore P: 0.1194
Episode: 827 Total reward: 34.0 Training loss: 0.6402 Explore P: 0.1191
Episode: 828 Total reward: 123.0 Training loss: 1.5834 Explore P: 0.1177
Episode: 829 Total reward: 40.0 Training loss: 2.0576 Explore P: 0.1173
Episode: 830 Total reward: 127.0 Training loss: 1.6665 Explore P: 0.1160
Episode: 831 Total reward: 59.0 Training loss: 0.7740 Explore P: 0.1153
Episode: 832 Total reward: 41.0 Training loss: 1.1921 Explore P: 0.1149
Episode: 833 Total reward: 83.0 Training loss: 0.4972 Explore P: 0.1140
Episode: 834 Total reward: 75.0 Training loss: 1.5284 Explore P: 0.1133
Episode: 835 Total reward: 43.0 Training loss: 0.9132 Explore P: 0.1128
Episode: 836 Total reward: 40.0 Training loss: 0.5321 Explore P: 0.1124
Episode: 837 Total reward: 86.0 Training loss: 0.8238 Explore P: 0.1115
Episode: 838 Total reward: 114.0 Training loss: 0.8317 Explore P: 0.1104
Episode: 839 Total reward: 57.0 Training loss: 1.8433 Explore P: 0.1098
Episode: 840 Total reward: 41.0 Training loss: 566.3483 Explore P: 0.1094
Episode: 841 Total reward: 61.0 Training loss: 0.8881 Explore P: 0.1088
Episode: 842 Total reward: 70.0 Training loss: 581.5745 Explore P: 0.1081
Episode: 843 Total reward: 165.0 Training loss: 0.7405 Explore P: 0.1065
Episode: 844 Total reward: 66.0 Training loss: 0.9552 Explore P: 0.1059
Episode: 845 Total reward: 59.0 Training loss: 0.9079 Explore P: 0.1053
Episode: 846 Total reward: 74.0 Training loss: 0.9050 Explore P: 0.1046
Episode: 847 Total reward: 43.0 Training loss: 4.3611 Explore P: 0.1042
Episode: 848 Total reward: 49.0 Training loss: 0.6488 Explore P: 0.1037
Episode: 849 Total reward: 102.0 Training loss: 0.5066 Explore P: 0.1028
Episode: 850 Total reward: 108.0 Training loss: 0.6736 Explore P: 0.1018
Episode: 851 Total reward: 56.0 Training loss: 1.5557 Explore P: 0.1013
Episode: 852 Total reward: 54.0 Training loss: 2.5033 Explore P: 0.1008
Episode: 853 Total reward: 40.0 Training loss: 1.1168 Explore P: 0.1004
Episode: 854 Total reward: 51.0 Training loss: 0.8495 Explore P: 0.1000
Episode: 855 Total reward: 58.0 Training loss: 1.8349 Explore P: 0.0994
Episode: 856 Total reward: 61.0 Training loss: 1.2716 Explore P: 0.0989
Episode: 857 Total reward: 66.0 Training loss: 0.8454 Explore P: 0.0983
Episode: 858 Total reward: 49.0 Training loss: 0.4934 Explore P: 0.0979
Episode: 859 Total reward: 51.0 Training loss: 0.4209 Explore P: 0.0974
Episode: 860 Total reward: 110.0 Training loss: 2.2261 Explore P: 0.0965
Episode: 861 Total reward: 94.0 Training loss: 3.8160 Explore P: 0.0957
Episode: 862 Total reward: 60.0 Training loss: 1.1179 Explore P: 0.0951
Episode: 863 Total reward: 43.0 Training loss: 3.4876 Explore P: 0.0948
Episode: 864 Total reward: 49.0 Training loss: 1.1089 Explore P: 0.0944
Episode: 865 Total reward: 37.0 Training loss: 0.8413 Explore P: 0.0941
Episode: 866 Total reward: 120.0 Training loss: 0.4388 Explore P: 0.0931
Episode: 867 Total reward: 99.0 Training loss: 932.8121 Explore P: 0.0922
Episode: 868 Total reward: 60.0 Training loss: 0.7343 Explore P: 0.0917
Episode: 869 Total reward: 86.0 Training loss: 4.4113 Explore P: 0.0910
Episode: 870 Total reward: 49.0 Training loss: 1.3641 Explore P: 0.0906
Episode: 871 Total reward: 65.0 Training loss: 0.6059 Explore P: 0.0901
Episode: 872 Total reward: 82.0 Training loss: 4.2169 Explore P: 0.0895
Episode: 873 Total reward: 152.0 Training loss: 1.0234 Explore P: 0.0883
Episode: 874 Total reward: 145.0 Training loss: 0.5227 Explore P: 0.0871
Episode: 875 Total reward: 58.0 Training loss: 1.0859 Explore P: 0.0867
Episode: 876 Total reward: 72.0 Training loss: 3.4329 Explore P: 0.0861
Episode: 877 Total reward: 58.0 Training loss: 1.0401 Explore P: 0.0857
Episode: 878 Total reward: 46.0 Training loss: 2.3011 Explore P: 0.0854
Episode: 879 Total reward: 74.0 Training loss: 0.4199 Explore P: 0.0848
Episode: 880 Total reward: 83.0 Training loss: 0.9828 Explore P: 0.0842
Episode: 881 Total reward: 72.0 Training loss: 0.2836 Explore P: 0.0837
Episode: 882 Total reward: 89.0 Training loss: 0.6194 Explore P: 0.0830
Episode: 883 Total reward: 67.0 Training loss: 2.4304 Explore P: 0.0825
Episode: 884 Total reward: 65.0 Training loss: 0.6025 Explore P: 0.0820
Episode: 885 Total reward: 95.0 Training loss: 1.6653 Explore P: 0.0814
Episode: 886 Total reward: 76.0 Training loss: 1.1331 Explore P: 0.0808
Episode: 887 Total reward: 83.0 Training loss: 1.2703 Explore P: 0.0802
Episode: 888 Total reward: 62.0 Training loss: 0.9843 Explore P: 0.0798
Episode: 889 Total reward: 63.0 Training loss: 3.4969 Explore P: 0.0794
Episode: 890 Total reward: 108.0 Training loss: 0.6453 Explore P: 0.0786
Episode: 891 Total reward: 87.0 Training loss: 0.6568 Explore P: 0.0780
Episode: 892 Total reward: 58.0 Training loss: 0.8591 Explore P: 0.0776
Episode: 893 Total reward: 62.0 Training loss: 3.3252 Explore P: 0.0772
Episode: 894 Total reward: 80.0 Training loss: 0.7019 Explore P: 0.0767
Episode: 895 Total reward: 128.0 Training loss: 1.2736 Explore P: 0.0758
Episode: 896 Total reward: 58.0 Training loss: 0.7667 Explore P: 0.0755
Episode: 897 Total reward: 116.0 Training loss: 0.8452 Explore P: 0.0747
Episode: 898 Total reward: 66.0 Training loss: 0.9634 Explore P: 0.0743
Episode: 899 Total reward: 67.0 Training loss: 0.5339 Explore P: 0.0738
Episode: 900 Total reward: 111.0 Training loss: 0.3876 Explore P: 0.0731
Episode: 901 Total reward: 66.0 Training loss: 1.1084 Explore P: 0.0727
Episode: 902 Total reward: 69.0 Training loss: 0.7963 Explore P: 0.0723
Episode: 903 Total reward: 59.0 Training loss: 0.6543 Explore P: 0.0719
Episode: 904 Total reward: 108.0 Training loss: 0.4179 Explore P: 0.0713
Episode: 905 Total reward: 72.0 Training loss: 1.0481 Explore P: 0.0708
Episode: 906 Total reward: 74.0 Training loss: 1173.4460 Explore P: 0.0704
Episode: 907 Total reward: 80.0 Training loss: 2661.2258 Explore P: 0.0699
Episode: 908 Total reward: 66.0 Training loss: 0.9100 Explore P: 0.0695
Episode: 909 Total reward: 85.0 Training loss: 0.4980 Explore P: 0.0690
Episode: 910 Total reward: 166.0 Training loss: 0.7316 Explore P: 0.0680
Episode: 911 Total reward: 68.0 Training loss: 0.8067 Explore P: 0.0676
Episode: 912 Total reward: 74.0 Training loss: 0.5365 Explore P: 0.0672
Episode: 913 Total reward: 60.0 Training loss: 0.4750 Explore P: 0.0669
Episode: 914 Total reward: 168.0 Training loss: 0.5685 Explore P: 0.0659
Episode: 915 Total reward: 149.0 Training loss: 0.2931 Explore P: 0.0651
Episode: 916 Total reward: 89.0 Training loss: 0.4645 Explore P: 0.0646
Episode: 917 Total reward: 93.0 Training loss: 0.5246 Explore P: 0.0641
Episode: 918 Total reward: 104.0 Training loss: 1.4856 Explore P: 0.0635
Episode: 919 Total reward: 67.0 Training loss: 1.8770 Explore P: 0.0632
Episode: 920 Total reward: 71.0 Training loss: 1.2043 Explore P: 0.0628
Episode: 921 Total reward: 65.0 Training loss: 1.2087 Explore P: 0.0625
Episode: 922 Total reward: 40.0 Training loss: 3.0441 Explore P: 0.0622
Episode: 923 Total reward: 54.0 Training loss: 0.4717 Explore P: 0.0620
Episode: 924 Total reward: 62.0 Training loss: 2.8642 Explore P: 0.0616
Episode: 925 Total reward: 146.0 Training loss: 0.7477 Explore P: 0.0609
Episode: 926 Total reward: 164.0 Training loss: 0.4985 Explore P: 0.0601
Episode: 927 Total reward: 75.0 Training loss: 2.0526 Explore P: 0.0597
Episode: 928 Total reward: 193.0 Training loss: 2.2332 Explore P: 0.0587
Episode: 929 Total reward: 88.0 Training loss: 2.8641 Explore P: 0.0583
Episode: 930 Total reward: 72.0 Training loss: 5.4780 Explore P: 0.0580
Episode: 931 Total reward: 60.0 Training loss: 1.1414 Explore P: 0.0577
Episode: 932 Total reward: 66.0 Training loss: 2.1263 Explore P: 0.0574
Episode: 933 Total reward: 141.0 Training loss: 1.6948 Explore P: 0.0567
Episode: 934 Total reward: 104.0 Training loss: 0.4671 Explore P: 0.0562
Episode: 935 Total reward: 64.0 Training loss: 1.0820 Explore P: 0.0559
Episode: 936 Total reward: 93.0 Training loss: 1.4454 Explore P: 0.0555
Episode: 937 Total reward: 58.0 Training loss: 1.1443 Explore P: 0.0552
Episode: 938 Total reward: 91.0 Training loss: 0.7856 Explore P: 0.0548
Episode: 939 Total reward: 82.0 Training loss: 1.2169 Explore P: 0.0545
Episode: 940 Total reward: 76.0 Training loss: 2.6995 Explore P: 0.0541
Episode: 941 Total reward: 59.0 Training loss: 0.6650 Explore P: 0.0539
Episode: 942 Total reward: 70.0 Training loss: 0.5730 Explore P: 0.0536
Episode: 943 Total reward: 50.0 Training loss: 0.6075 Explore P: 0.0533
Episode: 944 Total reward: 77.0 Training loss: 0.8477 Explore P: 0.0530
Episode: 945 Total reward: 63.0 Training loss: 1.2773 Explore P: 0.0527
Episode: 946 Total reward: 100.0 Training loss: 1.8242 Explore P: 0.0523
Episode: 947 Total reward: 97.0 Training loss: 0.4518 Explore P: 0.0519
Episode: 948 Total reward: 46.0 Training loss: 0.3361 Explore P: 0.0517
Episode: 949 Total reward: 52.0 Training loss: 1.8415 Explore P: 0.0515
Episode: 950 Total reward: 62.0 Training loss: 0.4674 Explore P: 0.0512
Episode: 951 Total reward: 128.0 Training loss: 0.2724 Explore P: 0.0507
Episode: 952 Total reward: 58.0 Training loss: 1.4779 Explore P: 0.0505
Episode: 953 Total reward: 62.0 Training loss: 1.0798 Explore P: 0.0502
Episode: 954 Total reward: 58.0 Training loss: 0.9669 Explore P: 0.0500
Episode: 955 Total reward: 51.0 Training loss: 0.7086 Explore P: 0.0498
Episode: 956 Total reward: 82.0 Training loss: 3.8886 Explore P: 0.0495
Episode: 957 Total reward: 68.0 Training loss: 0.5903 Explore P: 0.0492
Episode: 958 Total reward: 128.0 Training loss: 3.6998 Explore P: 0.0487
Episode: 959 Total reward: 47.0 Training loss: 0.9240 Explore P: 0.0485
Episode: 960 Total reward: 105.0 Training loss: 249.4460 Explore P: 0.0481
Episode: 961 Total reward: 153.0 Training loss: 0.4654 Explore P: 0.0475
Episode: 962 Total reward: 58.0 Training loss: 4.7054 Explore P: 0.0473
Episode: 963 Total reward: 63.0 Training loss: 0.3346 Explore P: 0.0471
Episode: 964 Total reward: 64.0 Training loss: 0.4290 Explore P: 0.0469
Episode: 966 Total reward: 11.0 Training loss: 3.4817 Explore P: 0.0461
Episode: 967 Total reward: 90.0 Training loss: 0.6088 Explore P: 0.0458
Episode: 968 Total reward: 72.0 Training loss: 1.3545 Explore P: 0.0455
Episode: 969 Total reward: 96.0 Training loss: 0.9832 Explore P: 0.0452
Episode: 970 Total reward: 62.0 Training loss: 0.6248 Explore P: 0.0449
Episode: 971 Total reward: 66.0 Training loss: 0.7960 Explore P: 0.0447
Episode: 972 Total reward: 46.0 Training loss: 5.8745 Explore P: 0.0446
Episode: 973 Total reward: 73.0 Training loss: 1.0479 Explore P: 0.0443
Episode: 974 Total reward: 56.0 Training loss: 0.5480 Explore P: 0.0441
Episode: 975 Total reward: 59.0 Training loss: 0.6247 Explore P: 0.0439
Episode: 976 Total reward: 92.0 Training loss: 1.3324 Explore P: 0.0436
Episode: 977 Total reward: 60.0 Training loss: 0.8268 Explore P: 0.0434
Episode: 978 Total reward: 64.0 Training loss: 2.1525 Explore P: 0.0432
Episode: 979 Total reward: 52.0 Training loss: 0.8312 Explore P: 0.0430
Episode: 980 Total reward: 68.0 Training loss: 0.3244 Explore P: 0.0428
Episode: 981 Total reward: 50.0 Training loss: 0.9681 Explore P: 0.0426
Episode: 982 Total reward: 102.0 Training loss: 1.5673 Explore P: 0.0423
Episode: 983 Total reward: 118.0 Training loss: 472.7228 Explore P: 0.0419
Episode: 984 Total reward: 51.0 Training loss: 0.5272 Explore P: 0.0418
Episode: 985 Total reward: 40.0 Training loss: 4.7630 Explore P: 0.0416
Episode: 986 Total reward: 87.0 Training loss: 0.6154 Explore P: 0.0414
Episode: 987 Total reward: 72.0 Training loss: 6.6989 Explore P: 0.0411
Episode: 988 Total reward: 75.0 Training loss: 4.9717 Explore P: 0.0409
Episode: 989 Total reward: 121.0 Training loss: 2.1798 Explore P: 0.0405
Episode: 990 Total reward: 46.0 Training loss: 0.7465 Explore P: 0.0404
Episode: 991 Total reward: 62.0 Training loss: 0.5556 Explore P: 0.0402
Episode: 992 Total reward: 73.0 Training loss: 0.3874 Explore P: 0.0400
Episode: 993 Total reward: 51.0 Training loss: 192.2492 Explore P: 0.0398
Episode: 994 Total reward: 70.0 Training loss: 1.3114 Explore P: 0.0396
Episode: 995 Total reward: 70.0 Training loss: 0.9061 Explore P: 0.0394
Episode: 996 Total reward: 57.0 Training loss: 1.4195 Explore P: 0.0392
Episode: 997 Total reward: 59.0 Training loss: 0.9880 Explore P: 0.0391
Episode: 998 Total reward: 70.0 Training loss: 0.7650 Explore P: 0.0389
Episode: 999 Total reward: 83.0 Training loss: 0.9134 Explore P: 0.0386

    \end{Verbatim}

    \subsection{Visualizing training}\label{visualizing-training}

Below we plot the total rewards for each episode. The rolling average is
plotted in blue.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         
         \PY{k}{def} \PY{n+nf}{running\PYZus{}mean}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{N}\PY{p}{)}\PY{p}{:}
             \PY{n}{cumsum} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{cumsum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)} 
             \PY{k}{return} \PY{p}{(}\PY{n}{cumsum}\PY{p}{[}\PY{n}{N}\PY{p}{:}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{cumsum}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{n}{N}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n}{N} 
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{eps}\PY{p}{,} \PY{n}{rews} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rewards\PYZus{}list}\PY{p}{)}\PY{o}{.}\PY{n}{T}
         \PY{n}{smoothed\PYZus{}rews} \PY{o}{=} \PY{n}{running\PYZus{}mean}\PY{p}{(}\PY{n}{rews}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{eps}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{smoothed\PYZus{}rews}\PY{p}{)}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{smoothed\PYZus{}rews}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{running\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{eps}\PY{p}{,} \PY{n}{rews}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rewards\PYZus{}list}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Episode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Total Reward}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} <matplotlib.legend.Legend at 0x139888828>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{figure}
\centering
\includegraphics{output_21_1.png}
\caption{png}
\end{figure}

\subsection{Playing Atari Games}\label{playing-atari-games}

So, Cart-Pole is a pretty simple game. However, the same model can be
used to train an agent to play something much more complicated like Pong
or Space Invaders. Instead of a state like we're using here though,
you'd want to use convolutional layers to get the state from the screen
images.

\begin{figure}
\centering
\includegraphics{assets/atari-network.png}
\caption{Deep Q-Learning Atari}
\end{figure}

I'll leave it as a challenge for you to use deep Q-learning to train an
agent to play Atari games. Here's the original paper which will get you
started: http://www.davidqiu.com:8888/research/nature14236.pdf.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
