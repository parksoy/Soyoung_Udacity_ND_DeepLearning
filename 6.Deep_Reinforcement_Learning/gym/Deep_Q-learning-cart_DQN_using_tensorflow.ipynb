{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In conda env openAI\n",
    "#sudo -H pip install python=3.5  \n",
    "#sudo -H pip install tensorflow==1.3  \n",
    "Also Kernel should be openAI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/parksoy/Desktop/Soyoung_Udacity_ND_DeepLearning/6.Deep_Reinforcement_Learning/gym\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use $Q$-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://github.com/openai/gym). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Number of possible actions: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parksoy/Desktop/Soyoung_Udacity_ND_DeepLearning/6.Deep_Reinforcement_Learning/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Number of possible actions\n",
    "print('Number of possible actions:', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`.  You can see how many actions are possible from `env.action_space.n`, and to get a random action you can use `env.action_space.sample()`.  Passing in an action as an integer to `env.step` will generate the next step in the simulation.  This is general to all Gym games. \n",
    "\n",
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the actions and rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "To keep track of the action values, we'll use a neural network that accepts a state $s$ as input.  The output will be $Q$-values for each available action $a$ (i.e., the output is **all** action values $Q(s,a)$ _corresponding to the input state $s$_).\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "As explored in the lesson, to get the training target, we'll first use the context provided by the state $s$ to choose an action $a$, then simulate the game using that action. This will get us the next state, $s'$, and the reward $r$. With that, we can calculate $\\hat{Q}(s,a) = r + \\gamma \\max_{a'}{Q(s', a')}$.  Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "Below is one implementation of the $Q$-network. It uses two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate=0.01, state_size=4, \n",
    "                 action_size=2, hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        # state inputs to the Q-network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], \\\n",
    "                                          name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "We will use the below algorithm to train the network.  For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "You are welcome (and encouraged!) to take the time to extend this code to implement some of the improvements that we discussed in the lesson, to include fixed $Q$ targets, double DQNs, prioritized replay, and/or dueling networks.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcement learning is the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/parksoy/anaconda3/envs/openAI/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here we re-initialize the simulation and pre-populate the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 31.0 Training loss: 1.1336 Explore P: 0.9969\n",
      "Episode: 2 Total reward: 56.0 Training loss: 1.0566 Explore P: 0.9914\n",
      "Episode: 3 Total reward: 31.0 Training loss: 1.0755 Explore P: 0.9884\n",
      "Episode: 4 Total reward: 22.0 Training loss: 1.1408 Explore P: 0.9862\n",
      "Episode: 5 Total reward: 26.0 Training loss: 1.0530 Explore P: 0.9837\n",
      "Episode: 6 Total reward: 16.0 Training loss: 1.0998 Explore P: 0.9821\n",
      "Episode: 7 Total reward: 33.0 Training loss: 1.0975 Explore P: 0.9789\n",
      "Episode: 8 Total reward: 52.0 Training loss: 1.0742 Explore P: 0.9739\n",
      "Episode: 9 Total reward: 20.0 Training loss: 1.0625 Explore P: 0.9720\n",
      "Episode: 10 Total reward: 31.0 Training loss: 1.2108 Explore P: 0.9690\n",
      "Episode: 11 Total reward: 47.0 Training loss: 1.0890 Explore P: 0.9645\n",
      "Episode: 12 Total reward: 10.0 Training loss: 1.2381 Explore P: 0.9636\n",
      "Episode: 13 Total reward: 32.0 Training loss: 1.3163 Explore P: 0.9605\n",
      "Episode: 14 Total reward: 19.0 Training loss: 1.0309 Explore P: 0.9587\n",
      "Episode: 15 Total reward: 23.0 Training loss: 1.1489 Explore P: 0.9565\n",
      "Episode: 16 Total reward: 16.0 Training loss: 1.2078 Explore P: 0.9550\n",
      "Episode: 17 Total reward: 20.0 Training loss: 1.2635 Explore P: 0.9531\n",
      "Episode: 18 Total reward: 9.0 Training loss: 1.8861 Explore P: 0.9523\n",
      "Episode: 19 Total reward: 27.0 Training loss: 1.2006 Explore P: 0.9497\n",
      "Episode: 20 Total reward: 16.0 Training loss: 1.0622 Explore P: 0.9482\n",
      "Episode: 21 Total reward: 28.0 Training loss: 2.0219 Explore P: 0.9456\n",
      "Episode: 22 Total reward: 17.0 Training loss: 1.4304 Explore P: 0.9440\n",
      "Episode: 23 Total reward: 33.0 Training loss: 1.3175 Explore P: 0.9409\n",
      "Episode: 24 Total reward: 14.0 Training loss: 1.6090 Explore P: 0.9396\n",
      "Episode: 25 Total reward: 16.0 Training loss: 8.1292 Explore P: 0.9382\n",
      "Episode: 26 Total reward: 17.0 Training loss: 1.8868 Explore P: 0.9366\n",
      "Episode: 27 Total reward: 47.0 Training loss: 2.5920 Explore P: 0.9322\n",
      "Episode: 28 Total reward: 25.0 Training loss: 4.0312 Explore P: 0.9299\n",
      "Episode: 29 Total reward: 16.0 Training loss: 2.3412 Explore P: 0.9285\n",
      "Episode: 30 Total reward: 19.0 Training loss: 2.6611 Explore P: 0.9267\n",
      "Episode: 31 Total reward: 53.0 Training loss: 9.0382 Explore P: 0.9219\n",
      "Episode: 32 Total reward: 30.0 Training loss: 3.8215 Explore P: 0.9191\n",
      "Episode: 33 Total reward: 25.0 Training loss: 5.1638 Explore P: 0.9169\n",
      "Episode: 34 Total reward: 22.0 Training loss: 4.3479 Explore P: 0.9149\n",
      "Episode: 35 Total reward: 24.0 Training loss: 5.3145 Explore P: 0.9127\n",
      "Episode: 36 Total reward: 10.0 Training loss: 6.6377 Explore P: 0.9118\n",
      "Episode: 37 Total reward: 29.0 Training loss: 5.7618 Explore P: 0.9092\n",
      "Episode: 38 Total reward: 16.0 Training loss: 6.8798 Explore P: 0.9078\n",
      "Episode: 39 Total reward: 23.0 Training loss: 8.3189 Explore P: 0.9057\n",
      "Episode: 40 Total reward: 13.0 Training loss: 8.9495 Explore P: 0.9045\n",
      "Episode: 41 Total reward: 25.0 Training loss: 8.5624 Explore P: 0.9023\n",
      "Episode: 42 Total reward: 31.0 Training loss: 6.9123 Explore P: 0.8995\n",
      "Episode: 43 Total reward: 15.0 Training loss: 10.0572 Explore P: 0.8982\n",
      "Episode: 44 Total reward: 33.0 Training loss: 10.8361 Explore P: 0.8953\n",
      "Episode: 45 Total reward: 14.0 Training loss: 9.2104 Explore P: 0.8940\n",
      "Episode: 46 Total reward: 11.0 Training loss: 10.3698 Explore P: 0.8931\n",
      "Episode: 47 Total reward: 10.0 Training loss: 10.6126 Explore P: 0.8922\n",
      "Episode: 48 Total reward: 47.0 Training loss: 13.0452 Explore P: 0.8881\n",
      "Episode: 49 Total reward: 19.0 Training loss: 33.6639 Explore P: 0.8864\n",
      "Episode: 50 Total reward: 10.0 Training loss: 14.8669 Explore P: 0.8855\n",
      "Episode: 51 Total reward: 16.0 Training loss: 18.0135 Explore P: 0.8841\n",
      "Episode: 52 Total reward: 11.0 Training loss: 19.1708 Explore P: 0.8831\n",
      "Episode: 53 Total reward: 9.0 Training loss: 16.7087 Explore P: 0.8824\n",
      "Episode: 54 Total reward: 34.0 Training loss: 18.9158 Explore P: 0.8794\n",
      "Episode: 55 Total reward: 13.0 Training loss: 90.0493 Explore P: 0.8783\n",
      "Episode: 56 Total reward: 18.0 Training loss: 33.9070 Explore P: 0.8767\n",
      "Episode: 57 Total reward: 28.0 Training loss: 27.9644 Explore P: 0.8743\n",
      "Episode: 58 Total reward: 17.0 Training loss: 28.9324 Explore P: 0.8728\n",
      "Episode: 59 Total reward: 22.0 Training loss: 35.1372 Explore P: 0.8709\n",
      "Episode: 60 Total reward: 12.0 Training loss: 216.6624 Explore P: 0.8699\n",
      "Episode: 61 Total reward: 15.0 Training loss: 287.0281 Explore P: 0.8686\n",
      "Episode: 62 Total reward: 19.0 Training loss: 30.7282 Explore P: 0.8670\n",
      "Episode: 63 Total reward: 9.0 Training loss: 36.0398 Explore P: 0.8662\n",
      "Episode: 64 Total reward: 29.0 Training loss: 43.7811 Explore P: 0.8637\n",
      "Episode: 65 Total reward: 9.0 Training loss: 38.8963 Explore P: 0.8630\n",
      "Episode: 66 Total reward: 12.0 Training loss: 47.3502 Explore P: 0.8619\n",
      "Episode: 67 Total reward: 11.0 Training loss: 40.9041 Explore P: 0.8610\n",
      "Episode: 68 Total reward: 12.0 Training loss: 39.5051 Explore P: 0.8600\n",
      "Episode: 69 Total reward: 11.0 Training loss: 43.7188 Explore P: 0.8590\n",
      "Episode: 70 Total reward: 24.0 Training loss: 333.3359 Explore P: 0.8570\n",
      "Episode: 71 Total reward: 18.0 Training loss: 74.6702 Explore P: 0.8555\n",
      "Episode: 72 Total reward: 18.0 Training loss: 58.5559 Explore P: 0.8540\n",
      "Episode: 73 Total reward: 28.0 Training loss: 1486.7451 Explore P: 0.8516\n",
      "Episode: 74 Total reward: 13.0 Training loss: 67.7643 Explore P: 0.8505\n",
      "Episode: 75 Total reward: 14.0 Training loss: 515.9315 Explore P: 0.8493\n",
      "Episode: 76 Total reward: 26.0 Training loss: 3037.3940 Explore P: 0.8472\n",
      "Episode: 77 Total reward: 13.0 Training loss: 62.8928 Explore P: 0.8461\n",
      "Episode: 78 Total reward: 54.0 Training loss: 70.7524 Explore P: 0.8416\n",
      "Episode: 79 Total reward: 16.0 Training loss: 74.0478 Explore P: 0.8402\n",
      "Episode: 80 Total reward: 27.0 Training loss: 364.2993 Explore P: 0.8380\n",
      "Episode: 81 Total reward: 24.0 Training loss: 1307.3883 Explore P: 0.8360\n",
      "Episode: 82 Total reward: 22.0 Training loss: 78.5216 Explore P: 0.8342\n",
      "Episode: 83 Total reward: 11.0 Training loss: 58.8493 Explore P: 0.8333\n",
      "Episode: 84 Total reward: 25.0 Training loss: 79.7611 Explore P: 0.8312\n",
      "Episode: 85 Total reward: 26.0 Training loss: 107.7045 Explore P: 0.8291\n",
      "Episode: 86 Total reward: 9.0 Training loss: 74.6755 Explore P: 0.8284\n",
      "Episode: 87 Total reward: 14.0 Training loss: 90.1754 Explore P: 0.8272\n",
      "Episode: 88 Total reward: 15.0 Training loss: 84.0657 Explore P: 0.8260\n",
      "Episode: 89 Total reward: 18.0 Training loss: 75.5678 Explore P: 0.8245\n",
      "Episode: 90 Total reward: 15.0 Training loss: 5649.0352 Explore P: 0.8233\n",
      "Episode: 91 Total reward: 44.0 Training loss: 75.1080 Explore P: 0.8197\n",
      "Episode: 92 Total reward: 16.0 Training loss: 78.2813 Explore P: 0.8184\n",
      "Episode: 93 Total reward: 40.0 Training loss: 88.2141 Explore P: 0.8152\n",
      "Episode: 94 Total reward: 13.0 Training loss: 96.8995 Explore P: 0.8142\n",
      "Episode: 95 Total reward: 18.0 Training loss: 75.3191 Explore P: 0.8127\n",
      "Episode: 96 Total reward: 32.0 Training loss: 101.5171 Explore P: 0.8102\n",
      "Episode: 97 Total reward: 23.0 Training loss: 86.5028 Explore P: 0.8083\n",
      "Episode: 98 Total reward: 22.0 Training loss: 2131.7183 Explore P: 0.8066\n",
      "Episode: 99 Total reward: 25.0 Training loss: 116.2479 Explore P: 0.8046\n",
      "Episode: 100 Total reward: 8.0 Training loss: 79.0282 Explore P: 0.8039\n",
      "Episode: 101 Total reward: 22.0 Training loss: 115.5971 Explore P: 0.8022\n",
      "Episode: 102 Total reward: 11.0 Training loss: 107.5002 Explore P: 0.8013\n",
      "Episode: 103 Total reward: 17.0 Training loss: 133.8950 Explore P: 0.8000\n",
      "Episode: 104 Total reward: 41.0 Training loss: 107.8689 Explore P: 0.7967\n",
      "Episode: 105 Total reward: 14.0 Training loss: 74.1046 Explore P: 0.7956\n",
      "Episode: 106 Total reward: 24.0 Training loss: 118.8142 Explore P: 0.7938\n",
      "Episode: 107 Total reward: 24.0 Training loss: 122.5212 Explore P: 0.7919\n",
      "Episode: 108 Total reward: 25.0 Training loss: 1332.2993 Explore P: 0.7899\n",
      "Episode: 109 Total reward: 16.0 Training loss: 1699.3975 Explore P: 0.7887\n",
      "Episode: 110 Total reward: 22.0 Training loss: 151.4867 Explore P: 0.7870\n",
      "Episode: 111 Total reward: 24.0 Training loss: 165.0690 Explore P: 0.7851\n",
      "Episode: 112 Total reward: 36.0 Training loss: 114.0432 Explore P: 0.7823\n",
      "Episode: 113 Total reward: 22.0 Training loss: 142.3817 Explore P: 0.7806\n",
      "Episode: 114 Total reward: 47.0 Training loss: 125.3903 Explore P: 0.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 115 Total reward: 19.0 Training loss: 150.7352 Explore P: 0.7756\n",
      "Episode: 116 Total reward: 8.0 Training loss: 158.0875 Explore P: 0.7749\n",
      "Episode: 117 Total reward: 24.0 Training loss: 117.2614 Explore P: 0.7731\n",
      "Episode: 118 Total reward: 8.0 Training loss: 147.2529 Explore P: 0.7725\n",
      "Episode: 119 Total reward: 21.0 Training loss: 170.5463 Explore P: 0.7709\n",
      "Episode: 120 Total reward: 25.0 Training loss: 121.8112 Explore P: 0.7690\n",
      "Episode: 121 Total reward: 8.0 Training loss: 136.6019 Explore P: 0.7684\n",
      "Episode: 122 Total reward: 11.0 Training loss: 135.4133 Explore P: 0.7676\n",
      "Episode: 123 Total reward: 24.0 Training loss: 17195.9199 Explore P: 0.7657\n",
      "Episode: 124 Total reward: 10.0 Training loss: 140.5972 Explore P: 0.7650\n",
      "Episode: 125 Total reward: 28.0 Training loss: 99.6012 Explore P: 0.7629\n",
      "Episode: 126 Total reward: 19.0 Training loss: 114.5515 Explore P: 0.7615\n",
      "Episode: 127 Total reward: 9.0 Training loss: 160.3778 Explore P: 0.7608\n",
      "Episode: 128 Total reward: 10.0 Training loss: 140.0286 Explore P: 0.7600\n",
      "Episode: 129 Total reward: 29.0 Training loss: 132.3573 Explore P: 0.7579\n",
      "Episode: 130 Total reward: 50.0 Training loss: 106.5341 Explore P: 0.7541\n",
      "Episode: 131 Total reward: 13.0 Training loss: 101.7785 Explore P: 0.7532\n",
      "Episode: 132 Total reward: 23.0 Training loss: 107.3102 Explore P: 0.7514\n",
      "Episode: 133 Total reward: 21.0 Training loss: 4932.7354 Explore P: 0.7499\n",
      "Episode: 134 Total reward: 14.0 Training loss: 116.8652 Explore P: 0.7489\n",
      "Episode: 135 Total reward: 11.0 Training loss: 109.7918 Explore P: 0.7480\n",
      "Episode: 136 Total reward: 14.0 Training loss: 96.9658 Explore P: 0.7470\n",
      "Episode: 137 Total reward: 34.0 Training loss: 119.0808 Explore P: 0.7445\n",
      "Episode: 138 Total reward: 13.0 Training loss: 20978.1523 Explore P: 0.7436\n",
      "Episode: 139 Total reward: 41.0 Training loss: 96.9322 Explore P: 0.7406\n",
      "Episode: 140 Total reward: 19.0 Training loss: 99.9643 Explore P: 0.7392\n",
      "Episode: 141 Total reward: 16.0 Training loss: 121.9502 Explore P: 0.7380\n",
      "Episode: 142 Total reward: 12.0 Training loss: 2665.6499 Explore P: 0.7371\n",
      "Episode: 143 Total reward: 23.0 Training loss: 71.9992 Explore P: 0.7355\n",
      "Episode: 144 Total reward: 25.0 Training loss: 110.3935 Explore P: 0.7336\n",
      "Episode: 145 Total reward: 58.0 Training loss: 75.4962 Explore P: 0.7295\n",
      "Episode: 146 Total reward: 13.0 Training loss: 100.1675 Explore P: 0.7285\n",
      "Episode: 147 Total reward: 9.0 Training loss: 98.0521 Explore P: 0.7279\n",
      "Episode: 148 Total reward: 12.0 Training loss: 4006.7378 Explore P: 0.7270\n",
      "Episode: 149 Total reward: 13.0 Training loss: 80.5920 Explore P: 0.7261\n",
      "Episode: 150 Total reward: 10.0 Training loss: 73.5030 Explore P: 0.7254\n",
      "Episode: 151 Total reward: 49.0 Training loss: 109.3066 Explore P: 0.7219\n",
      "Episode: 152 Total reward: 14.0 Training loss: 3463.6172 Explore P: 0.7209\n",
      "Episode: 153 Total reward: 10.0 Training loss: 91.8522 Explore P: 0.7202\n",
      "Episode: 154 Total reward: 13.0 Training loss: 75.7582 Explore P: 0.7192\n",
      "Episode: 155 Total reward: 12.0 Training loss: 73.6117 Explore P: 0.7184\n",
      "Episode: 156 Total reward: 18.0 Training loss: 5046.8506 Explore P: 0.7171\n",
      "Episode: 157 Total reward: 12.0 Training loss: 3164.2979 Explore P: 0.7163\n",
      "Episode: 158 Total reward: 10.0 Training loss: 88.7032 Explore P: 0.7156\n",
      "Episode: 159 Total reward: 21.0 Training loss: 3141.7478 Explore P: 0.7141\n",
      "Episode: 160 Total reward: 7.0 Training loss: 73.3956 Explore P: 0.7136\n",
      "Episode: 161 Total reward: 11.0 Training loss: 5334.0166 Explore P: 0.7128\n",
      "Episode: 162 Total reward: 13.0 Training loss: 4079.9731 Explore P: 0.7119\n",
      "Episode: 163 Total reward: 28.0 Training loss: 81.2171 Explore P: 0.7099\n",
      "Episode: 164 Total reward: 12.0 Training loss: 76.0322 Explore P: 0.7091\n",
      "Episode: 165 Total reward: 21.0 Training loss: 53.9511 Explore P: 0.7076\n",
      "Episode: 166 Total reward: 34.0 Training loss: 73.7509 Explore P: 0.7053\n",
      "Episode: 167 Total reward: 10.0 Training loss: 74.3256 Explore P: 0.7046\n",
      "Episode: 168 Total reward: 12.0 Training loss: 42.5936 Explore P: 0.7037\n",
      "Episode: 169 Total reward: 14.0 Training loss: 56.0576 Explore P: 0.7028\n",
      "Episode: 170 Total reward: 21.0 Training loss: 43.9802 Explore P: 0.7013\n",
      "Episode: 171 Total reward: 13.0 Training loss: 7777.7476 Explore P: 0.7004\n",
      "Episode: 172 Total reward: 13.0 Training loss: 2723.1489 Explore P: 0.6995\n",
      "Episode: 173 Total reward: 14.0 Training loss: 57.4662 Explore P: 0.6986\n",
      "Episode: 174 Total reward: 11.0 Training loss: 50.3084 Explore P: 0.6978\n",
      "Episode: 175 Total reward: 38.0 Training loss: 37.8473 Explore P: 0.6952\n",
      "Episode: 176 Total reward: 7.0 Training loss: 5064.1279 Explore P: 0.6947\n",
      "Episode: 177 Total reward: 27.0 Training loss: 58.1898 Explore P: 0.6929\n",
      "Episode: 178 Total reward: 23.0 Training loss: 41.7299 Explore P: 0.6913\n",
      "Episode: 179 Total reward: 22.0 Training loss: 44.9884 Explore P: 0.6898\n",
      "Episode: 180 Total reward: 18.0 Training loss: 3656.8450 Explore P: 0.6886\n",
      "Episode: 181 Total reward: 15.0 Training loss: 25144.4844 Explore P: 0.6876\n",
      "Episode: 182 Total reward: 26.0 Training loss: 33.8962 Explore P: 0.6858\n",
      "Episode: 183 Total reward: 19.0 Training loss: 57.6533 Explore P: 0.6845\n",
      "Episode: 184 Total reward: 23.0 Training loss: 44.3963 Explore P: 0.6830\n",
      "Episode: 185 Total reward: 13.0 Training loss: 3428.7397 Explore P: 0.6821\n",
      "Episode: 186 Total reward: 14.0 Training loss: 36.6019 Explore P: 0.6812\n",
      "Episode: 187 Total reward: 19.0 Training loss: 2737.3289 Explore P: 0.6799\n",
      "Episode: 188 Total reward: 19.0 Training loss: 17.8467 Explore P: 0.6786\n",
      "Episode: 189 Total reward: 10.0 Training loss: 16.8355 Explore P: 0.6779\n",
      "Episode: 190 Total reward: 24.0 Training loss: 22.5102 Explore P: 0.6763\n",
      "Episode: 191 Total reward: 26.0 Training loss: 4047.0984 Explore P: 0.6746\n",
      "Episode: 192 Total reward: 28.0 Training loss: 13.1256 Explore P: 0.6728\n",
      "Episode: 193 Total reward: 38.0 Training loss: 17.7296 Explore P: 0.6702\n",
      "Episode: 194 Total reward: 11.0 Training loss: 35.6565 Explore P: 0.6695\n",
      "Episode: 195 Total reward: 12.0 Training loss: 2895.4243 Explore P: 0.6687\n",
      "Episode: 196 Total reward: 11.0 Training loss: 1793.0479 Explore P: 0.6680\n",
      "Episode: 197 Total reward: 21.0 Training loss: 16.0983 Explore P: 0.6666\n",
      "Episode: 198 Total reward: 12.0 Training loss: 5853.1216 Explore P: 0.6658\n",
      "Episode: 199 Total reward: 13.0 Training loss: 26.5910 Explore P: 0.6650\n",
      "Episode: 200 Total reward: 20.0 Training loss: 24.3130 Explore P: 0.6637\n",
      "Episode: 201 Total reward: 11.0 Training loss: 22.0467 Explore P: 0.6630\n",
      "Episode: 202 Total reward: 21.0 Training loss: 2706.8464 Explore P: 0.6616\n",
      "Episode: 203 Total reward: 14.0 Training loss: 4888.1533 Explore P: 0.6607\n",
      "Episode: 204 Total reward: 9.0 Training loss: 9.0408 Explore P: 0.6601\n",
      "Episode: 205 Total reward: 26.0 Training loss: 7.3871 Explore P: 0.6584\n",
      "Episode: 206 Total reward: 11.0 Training loss: 14.6403 Explore P: 0.6577\n",
      "Episode: 207 Total reward: 17.0 Training loss: 9.1154 Explore P: 0.6566\n",
      "Episode: 208 Total reward: 49.0 Training loss: 4.4314 Explore P: 0.6534\n",
      "Episode: 209 Total reward: 15.0 Training loss: 7.4842 Explore P: 0.6525\n",
      "Episode: 210 Total reward: 60.0 Training loss: 1753.0670 Explore P: 0.6486\n",
      "Episode: 211 Total reward: 13.0 Training loss: 9.2378 Explore P: 0.6478\n",
      "Episode: 212 Total reward: 19.0 Training loss: 6.4863 Explore P: 0.6466\n",
      "Episode: 213 Total reward: 12.0 Training loss: 2.6975 Explore P: 0.6458\n",
      "Episode: 214 Total reward: 19.0 Training loss: 4.7349 Explore P: 0.6446\n",
      "Episode: 215 Total reward: 20.0 Training loss: 5.6127 Explore P: 0.6433\n",
      "Episode: 216 Total reward: 25.0 Training loss: 5.9732 Explore P: 0.6418\n",
      "Episode: 217 Total reward: 20.0 Training loss: 4.0889 Explore P: 0.6405\n",
      "Episode: 218 Total reward: 23.0 Training loss: 15.0587 Explore P: 0.6390\n",
      "Episode: 219 Total reward: 20.0 Training loss: 6.7505 Explore P: 0.6378\n",
      "Episode: 220 Total reward: 14.0 Training loss: 5.9254 Explore P: 0.6369\n",
      "Episode: 221 Total reward: 15.0 Training loss: 10.1932 Explore P: 0.6360\n",
      "Episode: 222 Total reward: 12.0 Training loss: 6.3386 Explore P: 0.6352\n",
      "Episode: 223 Total reward: 25.0 Training loss: 10.1164 Explore P: 0.6337\n",
      "Episode: 224 Total reward: 21.0 Training loss: 7.3444 Explore P: 0.6324\n",
      "Episode: 225 Total reward: 16.0 Training loss: 2586.8862 Explore P: 0.6314\n",
      "Episode: 226 Total reward: 26.0 Training loss: 7.9807 Explore P: 0.6297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 227 Total reward: 17.0 Training loss: 2536.1643 Explore P: 0.6287\n",
      "Episode: 228 Total reward: 14.0 Training loss: 3055.9155 Explore P: 0.6278\n",
      "Episode: 229 Total reward: 21.0 Training loss: 3600.8188 Explore P: 0.6265\n",
      "Episode: 230 Total reward: 34.0 Training loss: 2178.9675 Explore P: 0.6244\n",
      "Episode: 231 Total reward: 19.0 Training loss: 8.2447 Explore P: 0.6233\n",
      "Episode: 232 Total reward: 38.0 Training loss: 1734.4548 Explore P: 0.6209\n",
      "Episode: 233 Total reward: 17.0 Training loss: 1192.4335 Explore P: 0.6199\n",
      "Episode: 234 Total reward: 25.0 Training loss: 1959.9935 Explore P: 0.6184\n",
      "Episode: 235 Total reward: 18.0 Training loss: 2580.2327 Explore P: 0.6173\n",
      "Episode: 236 Total reward: 16.0 Training loss: 1340.3333 Explore P: 0.6163\n",
      "Episode: 237 Total reward: 28.0 Training loss: 11.0779 Explore P: 0.6146\n",
      "Episode: 238 Total reward: 15.0 Training loss: 3158.1431 Explore P: 0.6137\n",
      "Episode: 239 Total reward: 22.0 Training loss: 5.9163 Explore P: 0.6124\n",
      "Episode: 240 Total reward: 23.0 Training loss: 4.7254 Explore P: 0.6110\n",
      "Episode: 241 Total reward: 16.0 Training loss: 1168.8042 Explore P: 0.6100\n",
      "Episode: 242 Total reward: 12.0 Training loss: 9.5911 Explore P: 0.6093\n",
      "Episode: 243 Total reward: 18.0 Training loss: 6.3828 Explore P: 0.6082\n",
      "Episode: 244 Total reward: 14.0 Training loss: 12.3495 Explore P: 0.6074\n",
      "Episode: 245 Total reward: 17.0 Training loss: 6.8395 Explore P: 0.6064\n",
      "Episode: 246 Total reward: 65.0 Training loss: 10.0302 Explore P: 0.6025\n",
      "Episode: 247 Total reward: 24.0 Training loss: 2993.6069 Explore P: 0.6011\n",
      "Episode: 248 Total reward: 9.0 Training loss: 13.7001 Explore P: 0.6006\n",
      "Episode: 249 Total reward: 22.0 Training loss: 14.2397 Explore P: 0.5993\n",
      "Episode: 250 Total reward: 10.0 Training loss: 11.5850 Explore P: 0.5987\n",
      "Episode: 251 Total reward: 19.0 Training loss: 9.0400 Explore P: 0.5976\n",
      "Episode: 252 Total reward: 12.0 Training loss: 10.3943 Explore P: 0.5969\n",
      "Episode: 253 Total reward: 22.0 Training loss: 8.0987 Explore P: 0.5956\n",
      "Episode: 254 Total reward: 12.0 Training loss: 2830.7603 Explore P: 0.5949\n",
      "Episode: 255 Total reward: 25.0 Training loss: 7.6015 Explore P: 0.5934\n",
      "Episode: 256 Total reward: 36.0 Training loss: 794.9814 Explore P: 0.5913\n",
      "Episode: 257 Total reward: 11.0 Training loss: 9.3359 Explore P: 0.5907\n",
      "Episode: 258 Total reward: 26.0 Training loss: 2794.4878 Explore P: 0.5892\n",
      "Episode: 259 Total reward: 57.0 Training loss: 2519.6260 Explore P: 0.5859\n",
      "Episode: 260 Total reward: 8.0 Training loss: 8.5677 Explore P: 0.5854\n",
      "Episode: 261 Total reward: 9.0 Training loss: 9.5728 Explore P: 0.5849\n",
      "Episode: 262 Total reward: 23.0 Training loss: 1266.1208 Explore P: 0.5836\n",
      "Episode: 263 Total reward: 16.0 Training loss: 4768.1035 Explore P: 0.5827\n",
      "Episode: 264 Total reward: 10.0 Training loss: 14.5032 Explore P: 0.5821\n",
      "Episode: 265 Total reward: 20.0 Training loss: 22.2063 Explore P: 0.5810\n",
      "Episode: 266 Total reward: 22.0 Training loss: 17.9686 Explore P: 0.5797\n",
      "Episode: 267 Total reward: 9.0 Training loss: 18.5366 Explore P: 0.5792\n",
      "Episode: 268 Total reward: 15.0 Training loss: 19.4260 Explore P: 0.5783\n",
      "Episode: 269 Total reward: 9.0 Training loss: 31.3878 Explore P: 0.5778\n",
      "Episode: 270 Total reward: 12.0 Training loss: 2398.3108 Explore P: 0.5771\n",
      "Episode: 271 Total reward: 27.0 Training loss: 15.6864 Explore P: 0.5756\n",
      "Episode: 272 Total reward: 9.0 Training loss: 14.7353 Explore P: 0.5751\n",
      "Episode: 273 Total reward: 20.0 Training loss: 14358.8828 Explore P: 0.5740\n",
      "Episode: 274 Total reward: 11.0 Training loss: 505.4643 Explore P: 0.5734\n",
      "Episode: 275 Total reward: 12.0 Training loss: 775.4535 Explore P: 0.5727\n",
      "Episode: 276 Total reward: 10.0 Training loss: 685.5820 Explore P: 0.5721\n",
      "Episode: 277 Total reward: 12.0 Training loss: 22.1317 Explore P: 0.5714\n",
      "Episode: 278 Total reward: 13.0 Training loss: 9.7825 Explore P: 0.5707\n",
      "Episode: 279 Total reward: 12.0 Training loss: 18.2383 Explore P: 0.5700\n",
      "Episode: 280 Total reward: 22.0 Training loss: 620.8180 Explore P: 0.5688\n",
      "Episode: 281 Total reward: 12.0 Training loss: 3160.5129 Explore P: 0.5681\n",
      "Episode: 282 Total reward: 12.0 Training loss: 34.2596 Explore P: 0.5675\n",
      "Episode: 283 Total reward: 10.0 Training loss: 710.8776 Explore P: 0.5669\n",
      "Episode: 284 Total reward: 25.0 Training loss: 14.6413 Explore P: 0.5655\n",
      "Episode: 285 Total reward: 8.0 Training loss: 2192.1277 Explore P: 0.5651\n",
      "Episode: 286 Total reward: 10.0 Training loss: 19.3262 Explore P: 0.5645\n",
      "Episode: 287 Total reward: 10.0 Training loss: 26.7271 Explore P: 0.5640\n",
      "Episode: 288 Total reward: 20.0 Training loss: 874.6312 Explore P: 0.5629\n",
      "Episode: 289 Total reward: 8.0 Training loss: 25.4117 Explore P: 0.5624\n",
      "Episode: 290 Total reward: 16.0 Training loss: 510.8039 Explore P: 0.5615\n",
      "Episode: 291 Total reward: 35.0 Training loss: 507.0634 Explore P: 0.5596\n",
      "Episode: 292 Total reward: 39.0 Training loss: 19.2204 Explore P: 0.5575\n",
      "Episode: 293 Total reward: 14.0 Training loss: 2035.6892 Explore P: 0.5567\n",
      "Episode: 294 Total reward: 15.0 Training loss: 13.9245 Explore P: 0.5559\n",
      "Episode: 295 Total reward: 17.0 Training loss: 18.2830 Explore P: 0.5550\n",
      "Episode: 296 Total reward: 24.0 Training loss: 1134.6091 Explore P: 0.5536\n",
      "Episode: 297 Total reward: 16.0 Training loss: 1191.5876 Explore P: 0.5528\n",
      "Episode: 298 Total reward: 10.0 Training loss: 11.2063 Explore P: 0.5522\n",
      "Episode: 299 Total reward: 23.0 Training loss: 16.2845 Explore P: 0.5510\n",
      "Episode: 300 Total reward: 11.0 Training loss: 1508.8815 Explore P: 0.5504\n",
      "Episode: 301 Total reward: 8.0 Training loss: 1898.6448 Explore P: 0.5500\n",
      "Episode: 302 Total reward: 13.0 Training loss: 1811.7810 Explore P: 0.5493\n",
      "Episode: 303 Total reward: 9.0 Training loss: 750.8111 Explore P: 0.5488\n",
      "Episode: 304 Total reward: 11.0 Training loss: 2661.1360 Explore P: 0.5482\n",
      "Episode: 305 Total reward: 14.0 Training loss: 609.3965 Explore P: 0.5474\n",
      "Episode: 306 Total reward: 12.0 Training loss: 17.7551 Explore P: 0.5468\n",
      "Episode: 307 Total reward: 17.0 Training loss: 12.5250 Explore P: 0.5459\n",
      "Episode: 308 Total reward: 26.0 Training loss: 2239.8113 Explore P: 0.5445\n",
      "Episode: 309 Total reward: 10.0 Training loss: 15.3298 Explore P: 0.5440\n",
      "Episode: 310 Total reward: 18.0 Training loss: 511.7708 Explore P: 0.5430\n",
      "Episode: 311 Total reward: 13.0 Training loss: 1040.2487 Explore P: 0.5423\n",
      "Episode: 312 Total reward: 16.0 Training loss: 473.7540 Explore P: 0.5414\n",
      "Episode: 313 Total reward: 17.0 Training loss: 17.1217 Explore P: 0.5405\n",
      "Episode: 314 Total reward: 10.0 Training loss: 16.9178 Explore P: 0.5400\n",
      "Episode: 315 Total reward: 11.0 Training loss: 2982.5537 Explore P: 0.5394\n",
      "Episode: 316 Total reward: 18.0 Training loss: 18.6705 Explore P: 0.5385\n",
      "Episode: 317 Total reward: 33.0 Training loss: 2201.3279 Explore P: 0.5367\n",
      "Episode: 318 Total reward: 13.0 Training loss: 923.5317 Explore P: 0.5361\n",
      "Episode: 319 Total reward: 15.0 Training loss: 24.6642 Explore P: 0.5353\n",
      "Episode: 320 Total reward: 8.0 Training loss: 646.1931 Explore P: 0.5348\n",
      "Episode: 321 Total reward: 13.0 Training loss: 606.1357 Explore P: 0.5342\n",
      "Episode: 322 Total reward: 18.0 Training loss: 28.9088 Explore P: 0.5332\n",
      "Episode: 323 Total reward: 10.0 Training loss: 406.5051 Explore P: 0.5327\n",
      "Episode: 324 Total reward: 27.0 Training loss: 25.6876 Explore P: 0.5313\n",
      "Episode: 325 Total reward: 10.0 Training loss: 734.9943 Explore P: 0.5308\n",
      "Episode: 326 Total reward: 13.0 Training loss: 17.5832 Explore P: 0.5301\n",
      "Episode: 327 Total reward: 13.0 Training loss: 3052.4731 Explore P: 0.5294\n",
      "Episode: 328 Total reward: 8.0 Training loss: 19.4911 Explore P: 0.5290\n",
      "Episode: 329 Total reward: 24.0 Training loss: 2470.5872 Explore P: 0.5278\n",
      "Episode: 330 Total reward: 18.0 Training loss: 17.6961 Explore P: 0.5268\n",
      "Episode: 331 Total reward: 12.0 Training loss: 1883.9108 Explore P: 0.5262\n",
      "Episode: 332 Total reward: 12.0 Training loss: 16.8807 Explore P: 0.5256\n",
      "Episode: 333 Total reward: 10.0 Training loss: 14.4583 Explore P: 0.5251\n",
      "Episode: 334 Total reward: 21.0 Training loss: 2276.5396 Explore P: 0.5240\n",
      "Episode: 335 Total reward: 9.0 Training loss: 7.8440 Explore P: 0.5235\n",
      "Episode: 336 Total reward: 12.0 Training loss: 14.5624 Explore P: 0.5229\n",
      "Episode: 337 Total reward: 10.0 Training loss: 2540.2903 Explore P: 0.5224\n",
      "Episode: 338 Total reward: 13.0 Training loss: 470.6934 Explore P: 0.5217\n",
      "Episode: 339 Total reward: 9.0 Training loss: 17.5104 Explore P: 0.5213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 340 Total reward: 14.0 Training loss: 12.8044 Explore P: 0.5206\n",
      "Episode: 341 Total reward: 14.0 Training loss: 984.1576 Explore P: 0.5198\n",
      "Episode: 342 Total reward: 11.0 Training loss: 11.8259 Explore P: 0.5193\n",
      "Episode: 343 Total reward: 8.0 Training loss: 645.4559 Explore P: 0.5189\n",
      "Episode: 344 Total reward: 12.0 Training loss: 396.2121 Explore P: 0.5183\n",
      "Episode: 345 Total reward: 15.0 Training loss: 12.1033 Explore P: 0.5175\n",
      "Episode: 346 Total reward: 11.0 Training loss: 2260.5591 Explore P: 0.5169\n",
      "Episode: 347 Total reward: 26.0 Training loss: 10.2991 Explore P: 0.5156\n",
      "Episode: 348 Total reward: 11.0 Training loss: 8.6716 Explore P: 0.5151\n",
      "Episode: 349 Total reward: 18.0 Training loss: 13.4752 Explore P: 0.5142\n",
      "Episode: 350 Total reward: 18.0 Training loss: 2264.0474 Explore P: 0.5133\n",
      "Episode: 351 Total reward: 14.0 Training loss: 22.1365 Explore P: 0.5126\n",
      "Episode: 352 Total reward: 16.0 Training loss: 14249.8379 Explore P: 0.5118\n",
      "Episode: 353 Total reward: 16.0 Training loss: 448.7430 Explore P: 0.5109\n",
      "Episode: 354 Total reward: 13.0 Training loss: 1878.0905 Explore P: 0.5103\n",
      "Episode: 355 Total reward: 14.0 Training loss: 958.3232 Explore P: 0.5096\n",
      "Episode: 356 Total reward: 8.0 Training loss: 2861.6284 Explore P: 0.5092\n",
      "Episode: 357 Total reward: 9.0 Training loss: 11687.9805 Explore P: 0.5087\n",
      "Episode: 358 Total reward: 9.0 Training loss: 9.2547 Explore P: 0.5083\n",
      "Episode: 359 Total reward: 12.0 Training loss: 1794.3864 Explore P: 0.5077\n",
      "Episode: 360 Total reward: 19.0 Training loss: 12.0000 Explore P: 0.5068\n",
      "Episode: 361 Total reward: 11.0 Training loss: 2041.6752 Explore P: 0.5062\n",
      "Episode: 362 Total reward: 7.0 Training loss: 15.6710 Explore P: 0.5059\n",
      "Episode: 363 Total reward: 22.0 Training loss: 306.6039 Explore P: 0.5048\n",
      "Episode: 364 Total reward: 17.0 Training loss: 1709.5319 Explore P: 0.5039\n",
      "Episode: 365 Total reward: 12.0 Training loss: 13.6199 Explore P: 0.5033\n",
      "Episode: 366 Total reward: 14.0 Training loss: 389.3366 Explore P: 0.5027\n",
      "Episode: 367 Total reward: 12.0 Training loss: 11.2351 Explore P: 0.5021\n",
      "Episode: 368 Total reward: 11.0 Training loss: 12.0502 Explore P: 0.5015\n",
      "Episode: 369 Total reward: 9.0 Training loss: 318.7679 Explore P: 0.5011\n",
      "Episode: 370 Total reward: 14.0 Training loss: 567.2211 Explore P: 0.5004\n",
      "Episode: 371 Total reward: 46.0 Training loss: 13.6296 Explore P: 0.4981\n",
      "Episode: 372 Total reward: 10.0 Training loss: 19.5611 Explore P: 0.4977\n",
      "Episode: 373 Total reward: 18.0 Training loss: 827.3085 Explore P: 0.4968\n",
      "Episode: 374 Total reward: 17.0 Training loss: 6.7134 Explore P: 0.4959\n",
      "Episode: 375 Total reward: 14.0 Training loss: 2675.8379 Explore P: 0.4953\n",
      "Episode: 376 Total reward: 22.0 Training loss: 10.9745 Explore P: 0.4942\n",
      "Episode: 377 Total reward: 20.0 Training loss: 12.4000 Explore P: 0.4932\n",
      "Episode: 378 Total reward: 12.0 Training loss: 424.8512 Explore P: 0.4927\n",
      "Episode: 379 Total reward: 12.0 Training loss: 14.3740 Explore P: 0.4921\n",
      "Episode: 380 Total reward: 10.0 Training loss: 2511.8311 Explore P: 0.4916\n",
      "Episode: 381 Total reward: 9.0 Training loss: 505.0193 Explore P: 0.4912\n",
      "Episode: 382 Total reward: 31.0 Training loss: 387.2974 Explore P: 0.4897\n",
      "Episode: 383 Total reward: 18.0 Training loss: 11.4671 Explore P: 0.4888\n",
      "Episode: 384 Total reward: 28.0 Training loss: 1366.8923 Explore P: 0.4875\n",
      "Episode: 385 Total reward: 16.0 Training loss: 307.9189 Explore P: 0.4867\n",
      "Episode: 386 Total reward: 8.0 Training loss: 10.5875 Explore P: 0.4863\n",
      "Episode: 387 Total reward: 11.0 Training loss: 3587.6062 Explore P: 0.4858\n",
      "Episode: 388 Total reward: 18.0 Training loss: 5.8771 Explore P: 0.4849\n",
      "Episode: 389 Total reward: 11.0 Training loss: 1515.3159 Explore P: 0.4844\n",
      "Episode: 390 Total reward: 16.0 Training loss: 1307.3737 Explore P: 0.4837\n",
      "Episode: 391 Total reward: 10.0 Training loss: 7.8306 Explore P: 0.4832\n",
      "Episode: 392 Total reward: 12.0 Training loss: 2105.0166 Explore P: 0.4826\n",
      "Episode: 393 Total reward: 14.0 Training loss: 6.7499 Explore P: 0.4820\n",
      "Episode: 394 Total reward: 13.0 Training loss: 294.9380 Explore P: 0.4814\n",
      "Episode: 395 Total reward: 19.0 Training loss: 434.8215 Explore P: 0.4805\n",
      "Episode: 396 Total reward: 16.0 Training loss: 433.1816 Explore P: 0.4797\n",
      "Episode: 397 Total reward: 12.0 Training loss: 6.9003 Explore P: 0.4791\n",
      "Episode: 398 Total reward: 12.0 Training loss: 1617.0551 Explore P: 0.4786\n",
      "Episode: 399 Total reward: 11.0 Training loss: 254.9394 Explore P: 0.4781\n",
      "Episode: 400 Total reward: 9.0 Training loss: 4.5377 Explore P: 0.4776\n",
      "Episode: 401 Total reward: 30.0 Training loss: 1814.2565 Explore P: 0.4762\n",
      "Episode: 402 Total reward: 18.0 Training loss: 10.3146 Explore P: 0.4754\n",
      "Episode: 403 Total reward: 16.0 Training loss: 2.6532 Explore P: 0.4747\n",
      "Episode: 404 Total reward: 19.0 Training loss: 693.9641 Explore P: 0.4738\n",
      "Episode: 405 Total reward: 13.0 Training loss: 3.9940 Explore P: 0.4732\n",
      "Episode: 406 Total reward: 10.0 Training loss: 351.5669 Explore P: 0.4727\n",
      "Episode: 407 Total reward: 11.0 Training loss: 299.4555 Explore P: 0.4722\n",
      "Episode: 408 Total reward: 12.0 Training loss: 10.4676 Explore P: 0.4716\n",
      "Episode: 409 Total reward: 26.0 Training loss: 7.6152 Explore P: 0.4705\n",
      "Episode: 410 Total reward: 13.0 Training loss: 2071.2192 Explore P: 0.4699\n",
      "Episode: 411 Total reward: 51.0 Training loss: 12.2107 Explore P: 0.4675\n",
      "Episode: 412 Total reward: 13.0 Training loss: 967.0776 Explore P: 0.4669\n",
      "Episode: 413 Total reward: 20.0 Training loss: 15.1653 Explore P: 0.4660\n",
      "Episode: 414 Total reward: 15.0 Training loss: 458.5507 Explore P: 0.4653\n",
      "Episode: 415 Total reward: 16.0 Training loss: 259.3179 Explore P: 0.4646\n",
      "Episode: 416 Total reward: 23.0 Training loss: 1018.5815 Explore P: 0.4635\n",
      "Episode: 417 Total reward: 14.0 Training loss: 7.7518 Explore P: 0.4629\n",
      "Episode: 418 Total reward: 18.0 Training loss: 4.0836 Explore P: 0.4621\n",
      "Episode: 419 Total reward: 14.0 Training loss: 238.3980 Explore P: 0.4615\n",
      "Episode: 420 Total reward: 17.0 Training loss: 3.5531 Explore P: 0.4607\n",
      "Episode: 421 Total reward: 42.0 Training loss: 934.8664 Explore P: 0.4588\n",
      "Episode: 422 Total reward: 13.0 Training loss: 10.7482 Explore P: 0.4582\n",
      "Episode: 423 Total reward: 26.0 Training loss: 4.8551 Explore P: 0.4571\n",
      "Episode: 424 Total reward: 10.0 Training loss: 438.0523 Explore P: 0.4566\n",
      "Episode: 425 Total reward: 10.0 Training loss: 3.1533 Explore P: 0.4562\n",
      "Episode: 426 Total reward: 21.0 Training loss: 495.9139 Explore P: 0.4552\n",
      "Episode: 427 Total reward: 17.0 Training loss: 6.5882 Explore P: 0.4545\n",
      "Episode: 428 Total reward: 15.0 Training loss: 170.0226 Explore P: 0.4538\n",
      "Episode: 429 Total reward: 10.0 Training loss: 379.5156 Explore P: 0.4534\n",
      "Episode: 430 Total reward: 13.0 Training loss: 251.7760 Explore P: 0.4528\n",
      "Episode: 431 Total reward: 12.0 Training loss: 264.2087 Explore P: 0.4523\n",
      "Episode: 432 Total reward: 12.0 Training loss: 8.5085 Explore P: 0.4517\n",
      "Episode: 433 Total reward: 11.0 Training loss: 7.8822 Explore P: 0.4512\n",
      "Episode: 434 Total reward: 25.0 Training loss: 5.5916 Explore P: 0.4501\n",
      "Episode: 435 Total reward: 18.0 Training loss: 1198.3523 Explore P: 0.4494\n",
      "Episode: 436 Total reward: 11.0 Training loss: 975.9279 Explore P: 0.4489\n",
      "Episode: 437 Total reward: 14.0 Training loss: 7.0462 Explore P: 0.4483\n",
      "Episode: 438 Total reward: 16.0 Training loss: 766.6583 Explore P: 0.4476\n",
      "Episode: 439 Total reward: 16.0 Training loss: 7.1953 Explore P: 0.4469\n",
      "Episode: 440 Total reward: 11.0 Training loss: 2335.2944 Explore P: 0.4464\n",
      "Episode: 441 Total reward: 41.0 Training loss: 4.8481 Explore P: 0.4446\n",
      "Episode: 442 Total reward: 18.0 Training loss: 3.7209 Explore P: 0.4438\n",
      "Episode: 443 Total reward: 15.0 Training loss: 4.3218 Explore P: 0.4432\n",
      "Episode: 444 Total reward: 29.0 Training loss: 2721.1987 Explore P: 0.4419\n",
      "Episode: 445 Total reward: 13.0 Training loss: 215.2063 Explore P: 0.4413\n",
      "Episode: 446 Total reward: 15.0 Training loss: 7.8983 Explore P: 0.4407\n",
      "Episode: 447 Total reward: 11.0 Training loss: 169.7182 Explore P: 0.4402\n",
      "Episode: 448 Total reward: 16.0 Training loss: 1718.5627 Explore P: 0.4395\n",
      "Episode: 449 Total reward: 15.0 Training loss: 663.4957 Explore P: 0.4389\n",
      "Episode: 450 Total reward: 11.0 Training loss: 98.4129 Explore P: 0.4384\n",
      "Episode: 451 Total reward: 17.0 Training loss: 1242.5032 Explore P: 0.4377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 452 Total reward: 27.0 Training loss: 5.2918 Explore P: 0.4365\n",
      "Episode: 453 Total reward: 18.0 Training loss: 329.4759 Explore P: 0.4358\n",
      "Episode: 454 Total reward: 19.0 Training loss: 543.0585 Explore P: 0.4350\n",
      "Episode: 455 Total reward: 14.0 Training loss: 7.8573 Explore P: 0.4344\n",
      "Episode: 456 Total reward: 23.0 Training loss: 454.1478 Explore P: 0.4334\n",
      "Episode: 457 Total reward: 13.0 Training loss: 547.3274 Explore P: 0.4328\n",
      "Episode: 458 Total reward: 12.0 Training loss: 8.0125 Explore P: 0.4323\n",
      "Episode: 459 Total reward: 11.0 Training loss: 4.8602 Explore P: 0.4319\n",
      "Episode: 460 Total reward: 13.0 Training loss: 464.1033 Explore P: 0.4313\n",
      "Episode: 461 Total reward: 32.0 Training loss: 241.1246 Explore P: 0.4300\n",
      "Episode: 462 Total reward: 14.0 Training loss: 4.9168 Explore P: 0.4294\n",
      "Episode: 463 Total reward: 14.0 Training loss: 611.6248 Explore P: 0.4288\n",
      "Episode: 464 Total reward: 14.0 Training loss: 216.0107 Explore P: 0.4282\n",
      "Episode: 465 Total reward: 14.0 Training loss: 522.1945 Explore P: 0.4276\n",
      "Episode: 466 Total reward: 16.0 Training loss: 206.5324 Explore P: 0.4270\n",
      "Episode: 467 Total reward: 26.0 Training loss: 646.1320 Explore P: 0.4259\n",
      "Episode: 468 Total reward: 10.0 Training loss: 34.2836 Explore P: 0.4255\n",
      "Episode: 469 Total reward: 19.0 Training loss: 5.1561 Explore P: 0.4247\n",
      "Episode: 470 Total reward: 17.0 Training loss: 629.2855 Explore P: 0.4240\n",
      "Episode: 471 Total reward: 11.0 Training loss: 531.9976 Explore P: 0.4235\n",
      "Episode: 472 Total reward: 14.0 Training loss: 336.6075 Explore P: 0.4229\n",
      "Episode: 473 Total reward: 15.0 Training loss: 53.7856 Explore P: 0.4223\n",
      "Episode: 474 Total reward: 36.0 Training loss: 219.3026 Explore P: 0.4208\n",
      "Episode: 475 Total reward: 18.0 Training loss: 3.4661 Explore P: 0.4201\n",
      "Episode: 476 Total reward: 18.0 Training loss: 254.0515 Explore P: 0.4194\n",
      "Episode: 477 Total reward: 23.0 Training loss: 841.4808 Explore P: 0.4184\n",
      "Episode: 478 Total reward: 36.0 Training loss: 8.6495 Explore P: 0.4170\n",
      "Episode: 479 Total reward: 29.0 Training loss: 268.2657 Explore P: 0.4158\n",
      "Episode: 480 Total reward: 19.0 Training loss: 5.0780 Explore P: 0.4150\n",
      "Episode: 481 Total reward: 26.0 Training loss: 2.9369 Explore P: 0.4140\n",
      "Episode: 482 Total reward: 31.0 Training loss: 7.7216 Explore P: 0.4127\n",
      "Episode: 483 Total reward: 18.0 Training loss: 853.9831 Explore P: 0.4120\n",
      "Episode: 484 Total reward: 18.0 Training loss: 84.0259 Explore P: 0.4113\n",
      "Episode: 485 Total reward: 8.0 Training loss: 388.7159 Explore P: 0.4109\n",
      "Episode: 486 Total reward: 30.0 Training loss: 269.9201 Explore P: 0.4097\n",
      "Episode: 487 Total reward: 12.0 Training loss: 1389.4558 Explore P: 0.4093\n",
      "Episode: 488 Total reward: 17.0 Training loss: 928.5421 Explore P: 0.4086\n",
      "Episode: 489 Total reward: 15.0 Training loss: 1.7265 Explore P: 0.4080\n",
      "Episode: 490 Total reward: 19.0 Training loss: 407.6818 Explore P: 0.4072\n",
      "Episode: 491 Total reward: 37.0 Training loss: 612.4919 Explore P: 0.4058\n",
      "Episode: 492 Total reward: 26.0 Training loss: 6.7501 Explore P: 0.4047\n",
      "Episode: 493 Total reward: 26.0 Training loss: 209.0076 Explore P: 0.4037\n",
      "Episode: 494 Total reward: 21.0 Training loss: 343.6093 Explore P: 0.4029\n",
      "Episode: 495 Total reward: 48.0 Training loss: 3.9203 Explore P: 0.4010\n",
      "Episode: 496 Total reward: 45.0 Training loss: 301.8509 Explore P: 0.3992\n",
      "Episode: 497 Total reward: 24.0 Training loss: 8.8500 Explore P: 0.3983\n",
      "Episode: 498 Total reward: 17.0 Training loss: 1170.3754 Explore P: 0.3977\n",
      "Episode: 499 Total reward: 30.0 Training loss: 153.8571 Explore P: 0.3965\n",
      "Episode: 500 Total reward: 48.0 Training loss: 696.7855 Explore P: 0.3946\n",
      "Episode: 501 Total reward: 25.0 Training loss: 3.2578 Explore P: 0.3937\n",
      "Episode: 502 Total reward: 25.0 Training loss: 7.2231 Explore P: 0.3927\n",
      "Episode: 503 Total reward: 21.0 Training loss: 198.8927 Explore P: 0.3919\n",
      "Episode: 504 Total reward: 21.0 Training loss: 5.9145 Explore P: 0.3911\n",
      "Episode: 505 Total reward: 15.0 Training loss: 5.9346 Explore P: 0.3905\n",
      "Episode: 506 Total reward: 32.0 Training loss: 3.8662 Explore P: 0.3893\n",
      "Episode: 507 Total reward: 18.0 Training loss: 3.3817 Explore P: 0.3886\n",
      "Episode: 508 Total reward: 24.0 Training loss: 49.5891 Explore P: 0.3877\n",
      "Episode: 509 Total reward: 20.0 Training loss: 75.3168 Explore P: 0.3870\n",
      "Episode: 510 Total reward: 25.0 Training loss: 3.6143 Explore P: 0.3860\n",
      "Episode: 511 Total reward: 28.0 Training loss: 639.0432 Explore P: 0.3850\n",
      "Episode: 512 Total reward: 34.0 Training loss: 297.9716 Explore P: 0.3837\n",
      "Episode: 513 Total reward: 22.0 Training loss: 205.2259 Explore P: 0.3829\n",
      "Episode: 514 Total reward: 17.0 Training loss: 2.7754 Explore P: 0.3823\n",
      "Episode: 515 Total reward: 16.0 Training loss: 121.5799 Explore P: 0.3817\n",
      "Episode: 516 Total reward: 17.0 Training loss: 775.7901 Explore P: 0.3810\n",
      "Episode: 517 Total reward: 19.0 Training loss: 116.3986 Explore P: 0.3803\n",
      "Episode: 518 Total reward: 17.0 Training loss: 4.7324 Explore P: 0.3797\n",
      "Episode: 519 Total reward: 24.0 Training loss: 410.1209 Explore P: 0.3788\n",
      "Episode: 520 Total reward: 30.0 Training loss: 157.6344 Explore P: 0.3777\n",
      "Episode: 521 Total reward: 27.0 Training loss: 5.6855 Explore P: 0.3767\n",
      "Episode: 522 Total reward: 38.0 Training loss: 573.9545 Explore P: 0.3753\n",
      "Episode: 523 Total reward: 32.0 Training loss: 238.2151 Explore P: 0.3742\n",
      "Episode: 524 Total reward: 20.0 Training loss: 6.0902 Explore P: 0.3734\n",
      "Episode: 525 Total reward: 18.0 Training loss: 235.6646 Explore P: 0.3728\n",
      "Episode: 526 Total reward: 25.0 Training loss: 306.3424 Explore P: 0.3719\n",
      "Episode: 527 Total reward: 28.0 Training loss: 240.5276 Explore P: 0.3709\n",
      "Episode: 528 Total reward: 20.0 Training loss: 365.1735 Explore P: 0.3701\n",
      "Episode: 529 Total reward: 11.0 Training loss: 3.5649 Explore P: 0.3697\n",
      "Episode: 530 Total reward: 22.0 Training loss: 130.7427 Explore P: 0.3690\n",
      "Episode: 531 Total reward: 24.0 Training loss: 4.5332 Explore P: 0.3681\n",
      "Episode: 532 Total reward: 25.0 Training loss: 42.1354 Explore P: 0.3672\n",
      "Episode: 533 Total reward: 28.0 Training loss: 378.0653 Explore P: 0.3662\n",
      "Episode: 534 Total reward: 26.0 Training loss: 5.3626 Explore P: 0.3653\n",
      "Episode: 535 Total reward: 13.0 Training loss: 5.2367 Explore P: 0.3648\n",
      "Episode: 536 Total reward: 23.0 Training loss: 6.0566 Explore P: 0.3640\n",
      "Episode: 537 Total reward: 25.0 Training loss: 89.4480 Explore P: 0.3631\n",
      "Episode: 538 Total reward: 18.0 Training loss: 389.4726 Explore P: 0.3625\n",
      "Episode: 539 Total reward: 31.0 Training loss: 98.0575 Explore P: 0.3614\n",
      "Episode: 540 Total reward: 17.0 Training loss: 100.9925 Explore P: 0.3608\n",
      "Episode: 541 Total reward: 25.0 Training loss: 225.0518 Explore P: 0.3599\n",
      "Episode: 542 Total reward: 25.0 Training loss: 7.0077 Explore P: 0.3590\n",
      "Episode: 543 Total reward: 18.0 Training loss: 110.6044 Explore P: 0.3584\n",
      "Episode: 544 Total reward: 29.0 Training loss: 197.6844 Explore P: 0.3574\n",
      "Episode: 545 Total reward: 13.0 Training loss: 37.2853 Explore P: 0.3570\n",
      "Episode: 546 Total reward: 19.0 Training loss: 203.1637 Explore P: 0.3563\n",
      "Episode: 547 Total reward: 15.0 Training loss: 2.8235 Explore P: 0.3558\n",
      "Episode: 548 Total reward: 23.0 Training loss: 127.1622 Explore P: 0.3550\n",
      "Episode: 549 Total reward: 19.0 Training loss: 205.9512 Explore P: 0.3543\n",
      "Episode: 550 Total reward: 17.0 Training loss: 7.3892 Explore P: 0.3537\n",
      "Episode: 551 Total reward: 16.0 Training loss: 286.4356 Explore P: 0.3532\n",
      "Episode: 552 Total reward: 17.0 Training loss: 61.2301 Explore P: 0.3526\n",
      "Episode: 553 Total reward: 14.0 Training loss: 24.6704 Explore P: 0.3521\n",
      "Episode: 554 Total reward: 19.0 Training loss: 4.5917 Explore P: 0.3515\n",
      "Episode: 555 Total reward: 24.0 Training loss: 5.6980 Explore P: 0.3507\n",
      "Episode: 556 Total reward: 17.0 Training loss: 212.3639 Explore P: 0.3501\n",
      "Episode: 557 Total reward: 20.0 Training loss: 4.4784 Explore P: 0.3494\n",
      "Episode: 558 Total reward: 27.0 Training loss: 82.5821 Explore P: 0.3485\n",
      "Episode: 559 Total reward: 15.0 Training loss: 53.8638 Explore P: 0.3480\n",
      "Episode: 560 Total reward: 18.0 Training loss: 5.9644 Explore P: 0.3474\n",
      "Episode: 561 Total reward: 35.0 Training loss: 5.9584 Explore P: 0.3462\n",
      "Episode: 562 Total reward: 24.0 Training loss: 260.4533 Explore P: 0.3454\n",
      "Episode: 563 Total reward: 47.0 Training loss: 264.1849 Explore P: 0.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 564 Total reward: 45.0 Training loss: 3.0455 Explore P: 0.3423\n",
      "Episode: 565 Total reward: 21.0 Training loss: 4.7239 Explore P: 0.3416\n",
      "Episode: 566 Total reward: 44.0 Training loss: 3.7766 Explore P: 0.3402\n",
      "Episode: 567 Total reward: 19.0 Training loss: 3.9122 Explore P: 0.3395\n",
      "Episode: 568 Total reward: 66.0 Training loss: 212.2846 Explore P: 0.3374\n",
      "Episode: 569 Total reward: 103.0 Training loss: 33.8501 Explore P: 0.3340\n",
      "Episode: 570 Total reward: 37.0 Training loss: 184.0299 Explore P: 0.3328\n",
      "Episode: 571 Total reward: 19.0 Training loss: 77.5866 Explore P: 0.3322\n",
      "Episode: 572 Total reward: 20.0 Training loss: 4.6995 Explore P: 0.3316\n",
      "Episode: 573 Total reward: 40.0 Training loss: 6.0328 Explore P: 0.3303\n",
      "Episode: 574 Total reward: 81.0 Training loss: 5.1123 Explore P: 0.3277\n",
      "Episode: 575 Total reward: 27.0 Training loss: 9.3883 Explore P: 0.3268\n",
      "Episode: 576 Total reward: 30.0 Training loss: 78.4735 Explore P: 0.3259\n",
      "Episode: 577 Total reward: 45.0 Training loss: 65.8872 Explore P: 0.3245\n",
      "Episode: 578 Total reward: 60.0 Training loss: 43.5584 Explore P: 0.3226\n",
      "Episode: 579 Total reward: 42.0 Training loss: 4.4862 Explore P: 0.3213\n",
      "Episode: 580 Total reward: 61.0 Training loss: 8.0100 Explore P: 0.3194\n",
      "Episode: 581 Total reward: 62.0 Training loss: 128.8654 Explore P: 0.3175\n",
      "Episode: 582 Total reward: 40.0 Training loss: 168.7390 Explore P: 0.3163\n",
      "Episode: 583 Total reward: 29.0 Training loss: 9.9085 Explore P: 0.3154\n",
      "Episode: 584 Total reward: 30.0 Training loss: 4.3371 Explore P: 0.3144\n",
      "Episode: 585 Total reward: 32.0 Training loss: 4.5118 Explore P: 0.3135\n",
      "Episode: 586 Total reward: 25.0 Training loss: 29.6014 Explore P: 0.3127\n",
      "Episode: 587 Total reward: 35.0 Training loss: 7.8034 Explore P: 0.3117\n",
      "Episode: 588 Total reward: 33.0 Training loss: 3541.6692 Explore P: 0.3107\n",
      "Episode: 589 Total reward: 39.0 Training loss: 3.1998 Explore P: 0.3095\n",
      "Episode: 590 Total reward: 53.0 Training loss: 158.7361 Explore P: 0.3079\n",
      "Episode: 591 Total reward: 80.0 Training loss: 6.1514 Explore P: 0.3055\n",
      "Episode: 592 Total reward: 65.0 Training loss: 8.9506 Explore P: 0.3036\n",
      "Episode: 593 Total reward: 37.0 Training loss: 268.1830 Explore P: 0.3025\n",
      "Episode: 594 Total reward: 45.0 Training loss: 2.8680 Explore P: 0.3012\n",
      "Episode: 595 Total reward: 47.0 Training loss: 5.8958 Explore P: 0.2999\n",
      "Episode: 596 Total reward: 37.0 Training loss: 6.5402 Explore P: 0.2988\n",
      "Episode: 597 Total reward: 37.0 Training loss: 28.5462 Explore P: 0.2977\n",
      "Episode: 598 Total reward: 39.0 Training loss: 63.8882 Explore P: 0.2966\n",
      "Episode: 599 Total reward: 36.0 Training loss: 153.0553 Explore P: 0.2956\n",
      "Episode: 600 Total reward: 51.0 Training loss: 17.2110 Explore P: 0.2941\n",
      "Episode: 601 Total reward: 35.0 Training loss: 8.3424 Explore P: 0.2931\n",
      "Episode: 602 Total reward: 45.0 Training loss: 95.4431 Explore P: 0.2919\n",
      "Episode: 603 Total reward: 46.0 Training loss: 4.3492 Explore P: 0.2906\n",
      "Episode: 604 Total reward: 42.0 Training loss: 56.7290 Explore P: 0.2894\n",
      "Episode: 605 Total reward: 50.0 Training loss: 2.5836 Explore P: 0.2880\n",
      "Episode: 606 Total reward: 40.0 Training loss: 32.4431 Explore P: 0.2869\n",
      "Episode: 607 Total reward: 34.0 Training loss: 10.6222 Explore P: 0.2859\n",
      "Episode: 608 Total reward: 45.0 Training loss: 117.3146 Explore P: 0.2847\n",
      "Episode: 609 Total reward: 42.0 Training loss: 8.8554 Explore P: 0.2836\n",
      "Episode: 610 Total reward: 39.0 Training loss: 12.3777 Explore P: 0.2825\n",
      "Episode: 611 Total reward: 43.0 Training loss: 4.8672 Explore P: 0.2813\n",
      "Episode: 612 Total reward: 35.0 Training loss: 6.4338 Explore P: 0.2804\n",
      "Episode: 613 Total reward: 40.0 Training loss: 3.9079 Explore P: 0.2793\n",
      "Episode: 614 Total reward: 40.0 Training loss: 38.9865 Explore P: 0.2782\n",
      "Episode: 615 Total reward: 31.0 Training loss: 56.0722 Explore P: 0.2774\n",
      "Episode: 616 Total reward: 47.0 Training loss: 4.1930 Explore P: 0.2761\n",
      "Episode: 617 Total reward: 26.0 Training loss: 33.3703 Explore P: 0.2754\n",
      "Episode: 618 Total reward: 23.0 Training loss: 3.7547 Explore P: 0.2748\n",
      "Episode: 619 Total reward: 102.0 Training loss: 7.1800 Explore P: 0.2721\n",
      "Episode: 620 Total reward: 60.0 Training loss: 4.8917 Explore P: 0.2706\n",
      "Episode: 621 Total reward: 33.0 Training loss: 3.9055 Explore P: 0.2697\n",
      "Episode: 622 Total reward: 84.0 Training loss: 108.1593 Explore P: 0.2675\n",
      "Episode: 623 Total reward: 96.0 Training loss: 5.6092 Explore P: 0.2651\n",
      "Episode: 624 Total reward: 77.0 Training loss: 7.1489 Explore P: 0.2631\n",
      "Episode: 625 Total reward: 55.0 Training loss: 16.4858 Explore P: 0.2617\n",
      "Episode: 626 Total reward: 43.0 Training loss: 18.5192 Explore P: 0.2607\n",
      "Episode: 627 Total reward: 34.0 Training loss: 3.1746 Explore P: 0.2598\n",
      "Episode: 628 Total reward: 33.0 Training loss: 86.7883 Explore P: 0.2590\n",
      "Episode: 629 Total reward: 44.0 Training loss: 2.2608 Explore P: 0.2579\n",
      "Episode: 630 Total reward: 27.0 Training loss: 4.3098 Explore P: 0.2572\n",
      "Episode: 631 Total reward: 54.0 Training loss: 9.6541 Explore P: 0.2559\n",
      "Episode: 632 Total reward: 37.0 Training loss: 22.2504 Explore P: 0.2550\n",
      "Episode: 633 Total reward: 37.0 Training loss: 6.5687 Explore P: 0.2541\n",
      "Episode: 634 Total reward: 31.0 Training loss: 73.9561 Explore P: 0.2533\n",
      "Episode: 635 Total reward: 37.0 Training loss: 39.2320 Explore P: 0.2524\n",
      "Episode: 636 Total reward: 26.0 Training loss: 6.7892 Explore P: 0.2518\n",
      "Episode: 637 Total reward: 31.0 Training loss: 1.5057 Explore P: 0.2511\n",
      "Episode: 638 Total reward: 56.0 Training loss: 189.0412 Explore P: 0.2497\n",
      "Episode: 639 Total reward: 45.0 Training loss: 8.0887 Explore P: 0.2486\n",
      "Episode: 640 Total reward: 31.0 Training loss: 84.1479 Explore P: 0.2479\n",
      "Episode: 641 Total reward: 38.0 Training loss: 33.8725 Explore P: 0.2470\n",
      "Episode: 642 Total reward: 39.0 Training loss: 5.8959 Explore P: 0.2461\n",
      "Episode: 643 Total reward: 93.0 Training loss: 4.4480 Explore P: 0.2439\n",
      "Episode: 644 Total reward: 58.0 Training loss: 14.2085 Explore P: 0.2425\n",
      "Episode: 645 Total reward: 31.0 Training loss: 3.3501 Explore P: 0.2418\n",
      "Episode: 646 Total reward: 41.0 Training loss: 76.1727 Explore P: 0.2409\n",
      "Episode: 647 Total reward: 40.0 Training loss: 9.9661 Explore P: 0.2399\n",
      "Episode: 648 Total reward: 36.0 Training loss: 502.1139 Explore P: 0.2391\n",
      "Episode: 649 Total reward: 26.0 Training loss: 5.9730 Explore P: 0.2385\n",
      "Episode: 650 Total reward: 30.0 Training loss: 7.8049 Explore P: 0.2378\n",
      "Episode: 651 Total reward: 34.0 Training loss: 94.6944 Explore P: 0.2371\n",
      "Episode: 652 Total reward: 40.0 Training loss: 24.5197 Explore P: 0.2362\n",
      "Episode: 653 Total reward: 20.0 Training loss: 42.2009 Explore P: 0.2357\n",
      "Episode: 654 Total reward: 33.0 Training loss: 10.6266 Explore P: 0.2350\n",
      "Episode: 655 Total reward: 41.0 Training loss: 13.4396 Explore P: 0.2340\n",
      "Episode: 656 Total reward: 34.0 Training loss: 32.6747 Explore P: 0.2333\n",
      "Episode: 657 Total reward: 28.0 Training loss: 75.9534 Explore P: 0.2327\n",
      "Episode: 658 Total reward: 30.0 Training loss: 78.0404 Explore P: 0.2320\n",
      "Episode: 659 Total reward: 34.0 Training loss: 134.9823 Explore P: 0.2312\n",
      "Episode: 660 Total reward: 39.0 Training loss: 44.7073 Explore P: 0.2304\n",
      "Episode: 661 Total reward: 30.0 Training loss: 6.0627 Explore P: 0.2297\n",
      "Episode: 662 Total reward: 18.0 Training loss: 4.0473 Explore P: 0.2293\n",
      "Episode: 663 Total reward: 24.0 Training loss: 5.3534 Explore P: 0.2288\n",
      "Episode: 664 Total reward: 27.0 Training loss: 15.0171 Explore P: 0.2282\n",
      "Episode: 665 Total reward: 23.0 Training loss: 6.8084 Explore P: 0.2277\n",
      "Episode: 666 Total reward: 31.0 Training loss: 5.0730 Explore P: 0.2270\n",
      "Episode: 667 Total reward: 18.0 Training loss: 51.9317 Explore P: 0.2266\n",
      "Episode: 668 Total reward: 29.0 Training loss: 53.9886 Explore P: 0.2260\n",
      "Episode: 669 Total reward: 21.0 Training loss: 126.1072 Explore P: 0.2256\n",
      "Episode: 670 Total reward: 20.0 Training loss: 77.7373 Explore P: 0.2251\n",
      "Episode: 671 Total reward: 22.0 Training loss: 5.6996 Explore P: 0.2246\n",
      "Episode: 672 Total reward: 20.0 Training loss: 23.8649 Explore P: 0.2242\n",
      "Episode: 673 Total reward: 37.0 Training loss: 3.7537 Explore P: 0.2234\n",
      "Episode: 674 Total reward: 25.0 Training loss: 2.3030 Explore P: 0.2229\n",
      "Episode: 675 Total reward: 26.0 Training loss: 5.7478 Explore P: 0.2223\n",
      "Episode: 676 Total reward: 15.0 Training loss: 8.2644 Explore P: 0.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 677 Total reward: 26.0 Training loss: 176.0338 Explore P: 0.2215\n",
      "Episode: 678 Total reward: 24.0 Training loss: 9.4650 Explore P: 0.2210\n",
      "Episode: 679 Total reward: 38.0 Training loss: 4.7542 Explore P: 0.2202\n",
      "Episode: 680 Total reward: 27.0 Training loss: 2.9297 Explore P: 0.2196\n",
      "Episode: 681 Total reward: 40.0 Training loss: 10.8870 Explore P: 0.2188\n",
      "Episode: 682 Total reward: 28.0 Training loss: 53.3684 Explore P: 0.2182\n",
      "Episode: 683 Total reward: 36.0 Training loss: 5.0648 Explore P: 0.2174\n",
      "Episode: 684 Total reward: 39.0 Training loss: 3.7231 Explore P: 0.2166\n",
      "Episode: 685 Total reward: 31.0 Training loss: 5.1630 Explore P: 0.2160\n",
      "Episode: 686 Total reward: 35.0 Training loss: 6.6538 Explore P: 0.2153\n",
      "Episode: 687 Total reward: 35.0 Training loss: 6.6423 Explore P: 0.2145\n",
      "Episode: 688 Total reward: 37.0 Training loss: 22.5066 Explore P: 0.2138\n",
      "Episode: 689 Total reward: 29.0 Training loss: 49.0416 Explore P: 0.2132\n",
      "Episode: 690 Total reward: 24.0 Training loss: 23.6996 Explore P: 0.2127\n",
      "Episode: 691 Total reward: 20.0 Training loss: 6.1629 Explore P: 0.2123\n",
      "Episode: 692 Total reward: 21.0 Training loss: 20.2038 Explore P: 0.2119\n",
      "Episode: 693 Total reward: 22.0 Training loss: 77.5055 Explore P: 0.2114\n",
      "Episode: 694 Total reward: 48.0 Training loss: 2.3779 Explore P: 0.2105\n",
      "Episode: 695 Total reward: 18.0 Training loss: 28.9267 Explore P: 0.2101\n",
      "Episode: 696 Total reward: 37.0 Training loss: 18.2988 Explore P: 0.2094\n",
      "Episode: 697 Total reward: 32.0 Training loss: 149.0555 Explore P: 0.2087\n",
      "Episode: 698 Total reward: 25.0 Training loss: 5.2044 Explore P: 0.2082\n",
      "Episode: 699 Total reward: 22.0 Training loss: 6.0675 Explore P: 0.2078\n",
      "Episode: 700 Total reward: 18.0 Training loss: 14.7760 Explore P: 0.2075\n",
      "Episode: 701 Total reward: 25.0 Training loss: 2.7021 Explore P: 0.2070\n",
      "Episode: 702 Total reward: 21.0 Training loss: 43.9106 Explore P: 0.2065\n",
      "Episode: 703 Total reward: 35.0 Training loss: 48.6368 Explore P: 0.2059\n",
      "Episode: 704 Total reward: 26.0 Training loss: 4.4747 Explore P: 0.2054\n",
      "Episode: 705 Total reward: 23.0 Training loss: 51.1720 Explore P: 0.2049\n",
      "Episode: 706 Total reward: 25.0 Training loss: 5.1769 Explore P: 0.2044\n",
      "Episode: 707 Total reward: 40.0 Training loss: 18.6617 Explore P: 0.2036\n",
      "Episode: 708 Total reward: 24.0 Training loss: 78.3689 Explore P: 0.2032\n",
      "Episode: 709 Total reward: 31.0 Training loss: 9.2608 Explore P: 0.2026\n",
      "Episode: 710 Total reward: 23.0 Training loss: 32.7557 Explore P: 0.2021\n",
      "Episode: 711 Total reward: 35.0 Training loss: 4.2644 Explore P: 0.2015\n",
      "Episode: 712 Total reward: 33.0 Training loss: 25.5676 Explore P: 0.2008\n",
      "Episode: 713 Total reward: 32.0 Training loss: 2.8764 Explore P: 0.2002\n",
      "Episode: 714 Total reward: 35.0 Training loss: 3.8180 Explore P: 0.1996\n",
      "Episode: 715 Total reward: 24.0 Training loss: 5.7022 Explore P: 0.1991\n",
      "Episode: 716 Total reward: 26.0 Training loss: 904.5330 Explore P: 0.1986\n",
      "Episode: 717 Total reward: 60.0 Training loss: 70.2445 Explore P: 0.1975\n",
      "Episode: 718 Total reward: 29.0 Training loss: 21.1503 Explore P: 0.1969\n",
      "Episode: 719 Total reward: 31.0 Training loss: 1.1548 Explore P: 0.1964\n",
      "Episode: 720 Total reward: 41.0 Training loss: 58.4807 Explore P: 0.1956\n",
      "Episode: 721 Total reward: 30.0 Training loss: 3.7433 Explore P: 0.1950\n",
      "Episode: 722 Total reward: 20.0 Training loss: 3.1594 Explore P: 0.1947\n",
      "Episode: 723 Total reward: 36.0 Training loss: 5.5467 Explore P: 0.1940\n",
      "Episode: 724 Total reward: 27.0 Training loss: 6.8184 Explore P: 0.1935\n",
      "Episode: 725 Total reward: 26.0 Training loss: 5.0006 Explore P: 0.1930\n",
      "Episode: 726 Total reward: 33.0 Training loss: 4.5762 Explore P: 0.1924\n",
      "Episode: 727 Total reward: 22.0 Training loss: 57.5509 Explore P: 0.1920\n",
      "Episode: 728 Total reward: 49.0 Training loss: 7.7875 Explore P: 0.1911\n",
      "Episode: 729 Total reward: 36.0 Training loss: 21.5389 Explore P: 0.1905\n",
      "Episode: 730 Total reward: 29.0 Training loss: 50.8841 Explore P: 0.1900\n",
      "Episode: 731 Total reward: 34.0 Training loss: 82.7065 Explore P: 0.1894\n",
      "Episode: 732 Total reward: 29.0 Training loss: 2.1687 Explore P: 0.1888\n",
      "Episode: 733 Total reward: 23.0 Training loss: 2.3640 Explore P: 0.1884\n",
      "Episode: 734 Total reward: 37.0 Training loss: 5.6865 Explore P: 0.1878\n",
      "Episode: 735 Total reward: 27.0 Training loss: 2.3244 Explore P: 0.1873\n",
      "Episode: 736 Total reward: 87.0 Training loss: 2.7052 Explore P: 0.1858\n",
      "Episode: 737 Total reward: 35.0 Training loss: 2.4801 Explore P: 0.1851\n",
      "Episode: 738 Total reward: 41.0 Training loss: 2.2179 Explore P: 0.1844\n",
      "Episode: 739 Total reward: 50.0 Training loss: 12.5403 Explore P: 0.1836\n",
      "Episode: 740 Total reward: 70.0 Training loss: 19.7735 Explore P: 0.1823\n",
      "Episode: 741 Total reward: 48.0 Training loss: 5.8427 Explore P: 0.1815\n",
      "Episode: 742 Total reward: 98.0 Training loss: 79.3475 Explore P: 0.1798\n",
      "Episode: 743 Total reward: 48.0 Training loss: 118.0547 Explore P: 0.1790\n",
      "Episode: 744 Total reward: 41.0 Training loss: 24.0809 Explore P: 0.1783\n",
      "Episode: 745 Total reward: 37.0 Training loss: 64.8641 Explore P: 0.1777\n",
      "Episode: 746 Total reward: 40.0 Training loss: 2.0824 Explore P: 0.1771\n",
      "Episode: 747 Total reward: 71.0 Training loss: 2.0848 Explore P: 0.1759\n",
      "Episode: 748 Total reward: 48.0 Training loss: 4.1659 Explore P: 0.1751\n",
      "Episode: 749 Total reward: 61.0 Training loss: 4.9902 Explore P: 0.1741\n",
      "Episode: 750 Total reward: 67.0 Training loss: 5.9283 Explore P: 0.1730\n",
      "Episode: 751 Total reward: 29.0 Training loss: 52.0283 Explore P: 0.1725\n",
      "Episode: 752 Total reward: 36.0 Training loss: 2.3619 Explore P: 0.1719\n",
      "Episode: 753 Total reward: 62.0 Training loss: 54.8476 Explore P: 0.1709\n",
      "Episode: 754 Total reward: 48.0 Training loss: 1.7420 Explore P: 0.1701\n",
      "Episode: 755 Total reward: 99.0 Training loss: 363.3338 Explore P: 0.1686\n",
      "Episode: 756 Total reward: 58.0 Training loss: 0.9604 Explore P: 0.1677\n",
      "Episode: 757 Total reward: 58.0 Training loss: 0.8592 Explore P: 0.1667\n",
      "Episode: 758 Total reward: 36.0 Training loss: 3.6604 Explore P: 0.1662\n",
      "Episode: 759 Total reward: 49.0 Training loss: 1.7767 Explore P: 0.1654\n",
      "Episode: 760 Total reward: 56.0 Training loss: 2.2053 Explore P: 0.1645\n",
      "Episode: 761 Total reward: 28.0 Training loss: 200.0378 Explore P: 0.1641\n",
      "Episode: 762 Total reward: 43.0 Training loss: 126.6259 Explore P: 0.1635\n",
      "Episode: 763 Total reward: 62.0 Training loss: 5.9595 Explore P: 0.1625\n",
      "Episode: 764 Total reward: 31.0 Training loss: 4.2685 Explore P: 0.1620\n",
      "Episode: 765 Total reward: 36.0 Training loss: 4.8309 Explore P: 0.1615\n",
      "Episode: 766 Total reward: 61.0 Training loss: 60.8729 Explore P: 0.1606\n",
      "Episode: 767 Total reward: 56.0 Training loss: 14.9212 Explore P: 0.1597\n",
      "Episode: 768 Total reward: 51.0 Training loss: 2.0420 Explore P: 0.1590\n",
      "Episode: 769 Total reward: 50.0 Training loss: 59.6588 Explore P: 0.1582\n",
      "Episode: 770 Total reward: 40.0 Training loss: 2.8628 Explore P: 0.1576\n",
      "Episode: 771 Total reward: 26.0 Training loss: 2.1876 Explore P: 0.1572\n",
      "Episode: 772 Total reward: 36.0 Training loss: 2.6843 Explore P: 0.1567\n",
      "Episode: 773 Total reward: 38.0 Training loss: 1.9430 Explore P: 0.1562\n",
      "Episode: 774 Total reward: 58.0 Training loss: 11.1358 Explore P: 0.1553\n",
      "Episode: 775 Total reward: 42.0 Training loss: 3.3864 Explore P: 0.1547\n",
      "Episode: 776 Total reward: 38.0 Training loss: 2.6025 Explore P: 0.1542\n",
      "Episode: 777 Total reward: 35.0 Training loss: 2.4224 Explore P: 0.1537\n",
      "Episode: 778 Total reward: 35.0 Training loss: 18.4421 Explore P: 0.1532\n",
      "Episode: 779 Total reward: 37.0 Training loss: 4.6206 Explore P: 0.1526\n",
      "Episode: 780 Total reward: 67.0 Training loss: 2.5203 Explore P: 0.1517\n",
      "Episode: 781 Total reward: 37.0 Training loss: 0.4618 Explore P: 0.1511\n",
      "Episode: 782 Total reward: 54.0 Training loss: 4.2466 Explore P: 0.1504\n",
      "Episode: 783 Total reward: 53.0 Training loss: 3.6517 Explore P: 0.1496\n",
      "Episode: 784 Total reward: 56.0 Training loss: 6.1881 Explore P: 0.1489\n",
      "Episode: 785 Total reward: 44.0 Training loss: 1.7604 Explore P: 0.1483\n",
      "Episode: 786 Total reward: 59.0 Training loss: 1.4898 Explore P: 0.1474\n",
      "Episode: 787 Total reward: 43.0 Training loss: 3.3405 Explore P: 0.1469\n",
      "Episode: 788 Total reward: 27.0 Training loss: 127.9671 Explore P: 0.1465\n",
      "Episode: 789 Total reward: 41.0 Training loss: 2.9552 Explore P: 0.1459\n",
      "Episode: 790 Total reward: 70.0 Training loss: 2.9942 Explore P: 0.1450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 791 Total reward: 42.0 Training loss: 2.8949 Explore P: 0.1444\n",
      "Episode: 792 Total reward: 33.0 Training loss: 5.4970 Explore P: 0.1440\n",
      "Episode: 793 Total reward: 51.0 Training loss: 1.3554 Explore P: 0.1433\n",
      "Episode: 794 Total reward: 43.0 Training loss: 0.7841 Explore P: 0.1427\n",
      "Episode: 795 Total reward: 53.0 Training loss: 1.3484 Explore P: 0.1420\n",
      "Episode: 796 Total reward: 121.0 Training loss: 1.7600 Explore P: 0.1404\n",
      "Episode: 797 Total reward: 86.0 Training loss: 36.7660 Explore P: 0.1393\n",
      "Episode: 798 Total reward: 38.0 Training loss: 1.2794 Explore P: 0.1388\n",
      "Episode: 799 Total reward: 43.0 Training loss: 0.9256 Explore P: 0.1383\n",
      "Episode: 800 Total reward: 92.0 Training loss: 0.5621 Explore P: 0.1371\n",
      "Episode: 801 Total reward: 118.0 Training loss: 0.6442 Explore P: 0.1356\n",
      "Episode: 802 Total reward: 52.0 Training loss: 8.5783 Explore P: 0.1349\n",
      "Episode: 803 Total reward: 63.0 Training loss: 1.4115 Explore P: 0.1342\n",
      "Episode: 804 Total reward: 83.0 Training loss: 1.7019 Explore P: 0.1331\n",
      "Episode: 805 Total reward: 53.0 Training loss: 0.9256 Explore P: 0.1325\n",
      "Episode: 806 Total reward: 28.0 Training loss: 3.2014 Explore P: 0.1321\n",
      "Episode: 807 Total reward: 32.0 Training loss: 297.7047 Explore P: 0.1318\n",
      "Episode: 808 Total reward: 34.0 Training loss: 21.8687 Explore P: 0.1313\n",
      "Episode: 809 Total reward: 48.0 Training loss: 3.6502 Explore P: 0.1308\n",
      "Episode: 810 Total reward: 46.0 Training loss: 0.5735 Explore P: 0.1302\n",
      "Episode: 811 Total reward: 34.0 Training loss: 0.9185 Explore P: 0.1298\n",
      "Episode: 812 Total reward: 58.0 Training loss: 0.5429 Explore P: 0.1291\n",
      "Episode: 813 Total reward: 42.0 Training loss: 34.8559 Explore P: 0.1286\n",
      "Episode: 814 Total reward: 54.0 Training loss: 1.1691 Explore P: 0.1280\n",
      "Episode: 815 Total reward: 52.0 Training loss: 2.8903 Explore P: 0.1274\n",
      "Episode: 816 Total reward: 79.0 Training loss: 1.0637 Explore P: 0.1264\n",
      "Episode: 817 Total reward: 46.0 Training loss: 1.7267 Explore P: 0.1259\n",
      "Episode: 818 Total reward: 92.0 Training loss: 13.8054 Explore P: 0.1248\n",
      "Episode: 819 Total reward: 48.0 Training loss: 1.2360 Explore P: 0.1243\n",
      "Episode: 820 Total reward: 46.0 Training loss: 0.8049 Explore P: 0.1238\n",
      "Episode: 821 Total reward: 43.0 Training loss: 33.1233 Explore P: 0.1233\n",
      "Episode: 822 Total reward: 112.0 Training loss: 0.6822 Explore P: 0.1220\n",
      "Episode: 823 Total reward: 43.0 Training loss: 0.8931 Explore P: 0.1215\n",
      "Episode: 824 Total reward: 43.0 Training loss: 0.7396 Explore P: 0.1211\n",
      "Episode: 825 Total reward: 83.0 Training loss: 0.5648 Explore P: 0.1201\n",
      "Episode: 826 Total reward: 63.0 Training loss: 0.9254 Explore P: 0.1194\n",
      "Episode: 827 Total reward: 34.0 Training loss: 0.6402 Explore P: 0.1191\n",
      "Episode: 828 Total reward: 123.0 Training loss: 1.5834 Explore P: 0.1177\n",
      "Episode: 829 Total reward: 40.0 Training loss: 2.0576 Explore P: 0.1173\n",
      "Episode: 830 Total reward: 127.0 Training loss: 1.6665 Explore P: 0.1160\n",
      "Episode: 831 Total reward: 59.0 Training loss: 0.7740 Explore P: 0.1153\n",
      "Episode: 832 Total reward: 41.0 Training loss: 1.1921 Explore P: 0.1149\n",
      "Episode: 833 Total reward: 83.0 Training loss: 0.4972 Explore P: 0.1140\n",
      "Episode: 834 Total reward: 75.0 Training loss: 1.5284 Explore P: 0.1133\n",
      "Episode: 835 Total reward: 43.0 Training loss: 0.9132 Explore P: 0.1128\n",
      "Episode: 836 Total reward: 40.0 Training loss: 0.5321 Explore P: 0.1124\n",
      "Episode: 837 Total reward: 86.0 Training loss: 0.8238 Explore P: 0.1115\n",
      "Episode: 838 Total reward: 114.0 Training loss: 0.8317 Explore P: 0.1104\n",
      "Episode: 839 Total reward: 57.0 Training loss: 1.8433 Explore P: 0.1098\n",
      "Episode: 840 Total reward: 41.0 Training loss: 566.3483 Explore P: 0.1094\n",
      "Episode: 841 Total reward: 61.0 Training loss: 0.8881 Explore P: 0.1088\n",
      "Episode: 842 Total reward: 70.0 Training loss: 581.5745 Explore P: 0.1081\n",
      "Episode: 843 Total reward: 165.0 Training loss: 0.7405 Explore P: 0.1065\n",
      "Episode: 844 Total reward: 66.0 Training loss: 0.9552 Explore P: 0.1059\n",
      "Episode: 845 Total reward: 59.0 Training loss: 0.9079 Explore P: 0.1053\n",
      "Episode: 846 Total reward: 74.0 Training loss: 0.9050 Explore P: 0.1046\n",
      "Episode: 847 Total reward: 43.0 Training loss: 4.3611 Explore P: 0.1042\n",
      "Episode: 848 Total reward: 49.0 Training loss: 0.6488 Explore P: 0.1037\n",
      "Episode: 849 Total reward: 102.0 Training loss: 0.5066 Explore P: 0.1028\n",
      "Episode: 850 Total reward: 108.0 Training loss: 0.6736 Explore P: 0.1018\n",
      "Episode: 851 Total reward: 56.0 Training loss: 1.5557 Explore P: 0.1013\n",
      "Episode: 852 Total reward: 54.0 Training loss: 2.5033 Explore P: 0.1008\n",
      "Episode: 853 Total reward: 40.0 Training loss: 1.1168 Explore P: 0.1004\n",
      "Episode: 854 Total reward: 51.0 Training loss: 0.8495 Explore P: 0.1000\n",
      "Episode: 855 Total reward: 58.0 Training loss: 1.8349 Explore P: 0.0994\n",
      "Episode: 856 Total reward: 61.0 Training loss: 1.2716 Explore P: 0.0989\n",
      "Episode: 857 Total reward: 66.0 Training loss: 0.8454 Explore P: 0.0983\n",
      "Episode: 858 Total reward: 49.0 Training loss: 0.4934 Explore P: 0.0979\n",
      "Episode: 859 Total reward: 51.0 Training loss: 0.4209 Explore P: 0.0974\n",
      "Episode: 860 Total reward: 110.0 Training loss: 2.2261 Explore P: 0.0965\n",
      "Episode: 861 Total reward: 94.0 Training loss: 3.8160 Explore P: 0.0957\n",
      "Episode: 862 Total reward: 60.0 Training loss: 1.1179 Explore P: 0.0951\n",
      "Episode: 863 Total reward: 43.0 Training loss: 3.4876 Explore P: 0.0948\n",
      "Episode: 864 Total reward: 49.0 Training loss: 1.1089 Explore P: 0.0944\n",
      "Episode: 865 Total reward: 37.0 Training loss: 0.8413 Explore P: 0.0941\n",
      "Episode: 866 Total reward: 120.0 Training loss: 0.4388 Explore P: 0.0931\n",
      "Episode: 867 Total reward: 99.0 Training loss: 932.8121 Explore P: 0.0922\n",
      "Episode: 868 Total reward: 60.0 Training loss: 0.7343 Explore P: 0.0917\n",
      "Episode: 869 Total reward: 86.0 Training loss: 4.4113 Explore P: 0.0910\n",
      "Episode: 870 Total reward: 49.0 Training loss: 1.3641 Explore P: 0.0906\n",
      "Episode: 871 Total reward: 65.0 Training loss: 0.6059 Explore P: 0.0901\n",
      "Episode: 872 Total reward: 82.0 Training loss: 4.2169 Explore P: 0.0895\n",
      "Episode: 873 Total reward: 152.0 Training loss: 1.0234 Explore P: 0.0883\n",
      "Episode: 874 Total reward: 145.0 Training loss: 0.5227 Explore P: 0.0871\n",
      "Episode: 875 Total reward: 58.0 Training loss: 1.0859 Explore P: 0.0867\n",
      "Episode: 876 Total reward: 72.0 Training loss: 3.4329 Explore P: 0.0861\n",
      "Episode: 877 Total reward: 58.0 Training loss: 1.0401 Explore P: 0.0857\n",
      "Episode: 878 Total reward: 46.0 Training loss: 2.3011 Explore P: 0.0854\n",
      "Episode: 879 Total reward: 74.0 Training loss: 0.4199 Explore P: 0.0848\n",
      "Episode: 880 Total reward: 83.0 Training loss: 0.9828 Explore P: 0.0842\n",
      "Episode: 881 Total reward: 72.0 Training loss: 0.2836 Explore P: 0.0837\n",
      "Episode: 882 Total reward: 89.0 Training loss: 0.6194 Explore P: 0.0830\n",
      "Episode: 883 Total reward: 67.0 Training loss: 2.4304 Explore P: 0.0825\n",
      "Episode: 884 Total reward: 65.0 Training loss: 0.6025 Explore P: 0.0820\n",
      "Episode: 885 Total reward: 95.0 Training loss: 1.6653 Explore P: 0.0814\n",
      "Episode: 886 Total reward: 76.0 Training loss: 1.1331 Explore P: 0.0808\n",
      "Episode: 887 Total reward: 83.0 Training loss: 1.2703 Explore P: 0.0802\n",
      "Episode: 888 Total reward: 62.0 Training loss: 0.9843 Explore P: 0.0798\n",
      "Episode: 889 Total reward: 63.0 Training loss: 3.4969 Explore P: 0.0794\n",
      "Episode: 890 Total reward: 108.0 Training loss: 0.6453 Explore P: 0.0786\n",
      "Episode: 891 Total reward: 87.0 Training loss: 0.6568 Explore P: 0.0780\n",
      "Episode: 892 Total reward: 58.0 Training loss: 0.8591 Explore P: 0.0776\n",
      "Episode: 893 Total reward: 62.0 Training loss: 3.3252 Explore P: 0.0772\n",
      "Episode: 894 Total reward: 80.0 Training loss: 0.7019 Explore P: 0.0767\n",
      "Episode: 895 Total reward: 128.0 Training loss: 1.2736 Explore P: 0.0758\n",
      "Episode: 896 Total reward: 58.0 Training loss: 0.7667 Explore P: 0.0755\n",
      "Episode: 897 Total reward: 116.0 Training loss: 0.8452 Explore P: 0.0747\n",
      "Episode: 898 Total reward: 66.0 Training loss: 0.9634 Explore P: 0.0743\n",
      "Episode: 899 Total reward: 67.0 Training loss: 0.5339 Explore P: 0.0738\n",
      "Episode: 900 Total reward: 111.0 Training loss: 0.3876 Explore P: 0.0731\n",
      "Episode: 901 Total reward: 66.0 Training loss: 1.1084 Explore P: 0.0727\n",
      "Episode: 902 Total reward: 69.0 Training loss: 0.7963 Explore P: 0.0723\n",
      "Episode: 903 Total reward: 59.0 Training loss: 0.6543 Explore P: 0.0719\n",
      "Episode: 904 Total reward: 108.0 Training loss: 0.4179 Explore P: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 905 Total reward: 72.0 Training loss: 1.0481 Explore P: 0.0708\n",
      "Episode: 906 Total reward: 74.0 Training loss: 1173.4460 Explore P: 0.0704\n",
      "Episode: 907 Total reward: 80.0 Training loss: 2661.2258 Explore P: 0.0699\n",
      "Episode: 908 Total reward: 66.0 Training loss: 0.9100 Explore P: 0.0695\n",
      "Episode: 909 Total reward: 85.0 Training loss: 0.4980 Explore P: 0.0690\n",
      "Episode: 910 Total reward: 166.0 Training loss: 0.7316 Explore P: 0.0680\n",
      "Episode: 911 Total reward: 68.0 Training loss: 0.8067 Explore P: 0.0676\n",
      "Episode: 912 Total reward: 74.0 Training loss: 0.5365 Explore P: 0.0672\n",
      "Episode: 913 Total reward: 60.0 Training loss: 0.4750 Explore P: 0.0669\n",
      "Episode: 914 Total reward: 168.0 Training loss: 0.5685 Explore P: 0.0659\n",
      "Episode: 915 Total reward: 149.0 Training loss: 0.2931 Explore P: 0.0651\n",
      "Episode: 916 Total reward: 89.0 Training loss: 0.4645 Explore P: 0.0646\n",
      "Episode: 917 Total reward: 93.0 Training loss: 0.5246 Explore P: 0.0641\n",
      "Episode: 918 Total reward: 104.0 Training loss: 1.4856 Explore P: 0.0635\n",
      "Episode: 919 Total reward: 67.0 Training loss: 1.8770 Explore P: 0.0632\n",
      "Episode: 920 Total reward: 71.0 Training loss: 1.2043 Explore P: 0.0628\n",
      "Episode: 921 Total reward: 65.0 Training loss: 1.2087 Explore P: 0.0625\n",
      "Episode: 922 Total reward: 40.0 Training loss: 3.0441 Explore P: 0.0622\n",
      "Episode: 923 Total reward: 54.0 Training loss: 0.4717 Explore P: 0.0620\n",
      "Episode: 924 Total reward: 62.0 Training loss: 2.8642 Explore P: 0.0616\n",
      "Episode: 925 Total reward: 146.0 Training loss: 0.7477 Explore P: 0.0609\n",
      "Episode: 926 Total reward: 164.0 Training loss: 0.4985 Explore P: 0.0601\n",
      "Episode: 927 Total reward: 75.0 Training loss: 2.0526 Explore P: 0.0597\n",
      "Episode: 928 Total reward: 193.0 Training loss: 2.2332 Explore P: 0.0587\n",
      "Episode: 929 Total reward: 88.0 Training loss: 2.8641 Explore P: 0.0583\n",
      "Episode: 930 Total reward: 72.0 Training loss: 5.4780 Explore P: 0.0580\n",
      "Episode: 931 Total reward: 60.0 Training loss: 1.1414 Explore P: 0.0577\n",
      "Episode: 932 Total reward: 66.0 Training loss: 2.1263 Explore P: 0.0574\n",
      "Episode: 933 Total reward: 141.0 Training loss: 1.6948 Explore P: 0.0567\n",
      "Episode: 934 Total reward: 104.0 Training loss: 0.4671 Explore P: 0.0562\n",
      "Episode: 935 Total reward: 64.0 Training loss: 1.0820 Explore P: 0.0559\n",
      "Episode: 936 Total reward: 93.0 Training loss: 1.4454 Explore P: 0.0555\n",
      "Episode: 937 Total reward: 58.0 Training loss: 1.1443 Explore P: 0.0552\n",
      "Episode: 938 Total reward: 91.0 Training loss: 0.7856 Explore P: 0.0548\n",
      "Episode: 939 Total reward: 82.0 Training loss: 1.2169 Explore P: 0.0545\n",
      "Episode: 940 Total reward: 76.0 Training loss: 2.6995 Explore P: 0.0541\n",
      "Episode: 941 Total reward: 59.0 Training loss: 0.6650 Explore P: 0.0539\n",
      "Episode: 942 Total reward: 70.0 Training loss: 0.5730 Explore P: 0.0536\n",
      "Episode: 943 Total reward: 50.0 Training loss: 0.6075 Explore P: 0.0533\n",
      "Episode: 944 Total reward: 77.0 Training loss: 0.8477 Explore P: 0.0530\n",
      "Episode: 945 Total reward: 63.0 Training loss: 1.2773 Explore P: 0.0527\n",
      "Episode: 946 Total reward: 100.0 Training loss: 1.8242 Explore P: 0.0523\n",
      "Episode: 947 Total reward: 97.0 Training loss: 0.4518 Explore P: 0.0519\n",
      "Episode: 948 Total reward: 46.0 Training loss: 0.3361 Explore P: 0.0517\n",
      "Episode: 949 Total reward: 52.0 Training loss: 1.8415 Explore P: 0.0515\n",
      "Episode: 950 Total reward: 62.0 Training loss: 0.4674 Explore P: 0.0512\n",
      "Episode: 951 Total reward: 128.0 Training loss: 0.2724 Explore P: 0.0507\n",
      "Episode: 952 Total reward: 58.0 Training loss: 1.4779 Explore P: 0.0505\n",
      "Episode: 953 Total reward: 62.0 Training loss: 1.0798 Explore P: 0.0502\n",
      "Episode: 954 Total reward: 58.0 Training loss: 0.9669 Explore P: 0.0500\n",
      "Episode: 955 Total reward: 51.0 Training loss: 0.7086 Explore P: 0.0498\n",
      "Episode: 956 Total reward: 82.0 Training loss: 3.8886 Explore P: 0.0495\n",
      "Episode: 957 Total reward: 68.0 Training loss: 0.5903 Explore P: 0.0492\n",
      "Episode: 958 Total reward: 128.0 Training loss: 3.6998 Explore P: 0.0487\n",
      "Episode: 959 Total reward: 47.0 Training loss: 0.9240 Explore P: 0.0485\n",
      "Episode: 960 Total reward: 105.0 Training loss: 249.4460 Explore P: 0.0481\n",
      "Episode: 961 Total reward: 153.0 Training loss: 0.4654 Explore P: 0.0475\n",
      "Episode: 962 Total reward: 58.0 Training loss: 4.7054 Explore P: 0.0473\n",
      "Episode: 963 Total reward: 63.0 Training loss: 0.3346 Explore P: 0.0471\n",
      "Episode: 964 Total reward: 64.0 Training loss: 0.4290 Explore P: 0.0469\n",
      "Episode: 966 Total reward: 11.0 Training loss: 3.4817 Explore P: 0.0461\n",
      "Episode: 967 Total reward: 90.0 Training loss: 0.6088 Explore P: 0.0458\n",
      "Episode: 968 Total reward: 72.0 Training loss: 1.3545 Explore P: 0.0455\n",
      "Episode: 969 Total reward: 96.0 Training loss: 0.9832 Explore P: 0.0452\n",
      "Episode: 970 Total reward: 62.0 Training loss: 0.6248 Explore P: 0.0449\n",
      "Episode: 971 Total reward: 66.0 Training loss: 0.7960 Explore P: 0.0447\n",
      "Episode: 972 Total reward: 46.0 Training loss: 5.8745 Explore P: 0.0446\n",
      "Episode: 973 Total reward: 73.0 Training loss: 1.0479 Explore P: 0.0443\n",
      "Episode: 974 Total reward: 56.0 Training loss: 0.5480 Explore P: 0.0441\n",
      "Episode: 975 Total reward: 59.0 Training loss: 0.6247 Explore P: 0.0439\n",
      "Episode: 976 Total reward: 92.0 Training loss: 1.3324 Explore P: 0.0436\n",
      "Episode: 977 Total reward: 60.0 Training loss: 0.8268 Explore P: 0.0434\n",
      "Episode: 978 Total reward: 64.0 Training loss: 2.1525 Explore P: 0.0432\n",
      "Episode: 979 Total reward: 52.0 Training loss: 0.8312 Explore P: 0.0430\n",
      "Episode: 980 Total reward: 68.0 Training loss: 0.3244 Explore P: 0.0428\n",
      "Episode: 981 Total reward: 50.0 Training loss: 0.9681 Explore P: 0.0426\n",
      "Episode: 982 Total reward: 102.0 Training loss: 1.5673 Explore P: 0.0423\n",
      "Episode: 983 Total reward: 118.0 Training loss: 472.7228 Explore P: 0.0419\n",
      "Episode: 984 Total reward: 51.0 Training loss: 0.5272 Explore P: 0.0418\n",
      "Episode: 985 Total reward: 40.0 Training loss: 4.7630 Explore P: 0.0416\n",
      "Episode: 986 Total reward: 87.0 Training loss: 0.6154 Explore P: 0.0414\n",
      "Episode: 987 Total reward: 72.0 Training loss: 6.6989 Explore P: 0.0411\n",
      "Episode: 988 Total reward: 75.0 Training loss: 4.9717 Explore P: 0.0409\n",
      "Episode: 989 Total reward: 121.0 Training loss: 2.1798 Explore P: 0.0405\n",
      "Episode: 990 Total reward: 46.0 Training loss: 0.7465 Explore P: 0.0404\n",
      "Episode: 991 Total reward: 62.0 Training loss: 0.5556 Explore P: 0.0402\n",
      "Episode: 992 Total reward: 73.0 Training loss: 0.3874 Explore P: 0.0400\n",
      "Episode: 993 Total reward: 51.0 Training loss: 192.2492 Explore P: 0.0398\n",
      "Episode: 994 Total reward: 70.0 Training loss: 1.3114 Explore P: 0.0396\n",
      "Episode: 995 Total reward: 70.0 Training loss: 0.9061 Explore P: 0.0394\n",
      "Episode: 996 Total reward: 57.0 Training loss: 1.4195 Explore P: 0.0392\n",
      "Episode: 997 Total reward: 59.0 Training loss: 0.9880 Explore P: 0.0391\n",
      "Episode: 998 Total reward: 70.0 Training loss: 0.7650 Explore P: 0.0389\n",
      "Episode: 999 Total reward: 83.0 Training loss: 0.9134 Explore P: 0.0386\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below we plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x139888828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews, label='running_mean')\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3, label='rewards_list')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_21_1.png)\n",
    "\n",
    "\n",
    "## Playing Atari Games\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
